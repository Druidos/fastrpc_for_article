/* Generated by Frama-C */


typedef signed char __s8;


typedef unsigned char __u8;


typedef short __s16;


typedef unsigned short __u16;


typedef int __s32;


typedef unsigned int __u32;


typedef long long __s64;


typedef unsigned long long __u64;


typedef __s8 s8;


typedef __u8 u8;


typedef __s16 s16;


typedef __u16 u16;


typedef __s32 s32;


typedef __u32 u32;


typedef __s64 s64;


typedef __u64 u64;


typedef long __kernel_long_t;


typedef unsigned long __kernel_ulong_t;


typedef int __kernel_pid_t;


typedef unsigned int __kernel_uid32_t;


typedef unsigned int __kernel_gid32_t;


typedef __kernel_ulong_t __kernel_size_t;


typedef __kernel_long_t __kernel_ssize_t;


typedef long long __kernel_loff_t;


typedef long long __kernel_time64_t;


typedef __kernel_long_t __kernel_clock_t;


typedef int __kernel_timer_t;


typedef int __kernel_clockid_t;


typedef unsigned int __poll_t;


typedef u32 __kernel_dev_t;


typedef __kernel_dev_t dev_t;


typedef unsigned short umode_t;


typedef __kernel_pid_t pid_t;


typedef __kernel_clockid_t clockid_t;


typedef _Bool bool;


typedef __kernel_uid32_t uid_t;


typedef __kernel_gid32_t gid_t;


typedef unsigned long uintptr_t;


typedef __kernel_loff_t loff_t;


typedef __kernel_size_t size_t;


typedef __kernel_ssize_t ssize_t;


typedef u32 uint32_t;


typedef unsigned long sector_t;


typedef unsigned long blkcnt_t;


typedef u64 dma_addr_t;


typedef unsigned int gfp_t;


typedef unsigned int fmode_t;


typedef u64 phys_addr_t;


typedef phys_addr_t resource_size_t;


struct __anonstruct_atomic_t_6 {
   int counter ;
};


typedef struct __anonstruct_atomic_t_6 atomic_t;


struct __anonstruct_atomic64_t_7 {
   long counter ;
};


typedef struct __anonstruct_atomic64_t_7 atomic64_t;


struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};


struct hlist_node;


struct hlist_head {
   struct hlist_node *first ;
};


struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};


struct callback_head {
   struct callback_head *next ;
   void (*func)(struct callback_head *) ;
};


struct device;


struct module;


struct kernel_symbol {
   int value_offset ;
   int name_offset ;
};


typedef void (*ctor_fn_t)(void);


struct ctl_table;


struct jump_entry;


struct static_key_mod;


union __anonunion_8 {
   unsigned long type ;
   struct jump_entry *entries ;
   struct static_key_mod *next ;
};


struct static_key {
   atomic_t enabled ;
   union __anonunion_8 __anonCompField_static_key_4 ;
};


struct jump_entry {
   s32 code ;
   s32 target ;
   long key ;
};


struct static_key_true {
   struct static_key key ;
};


struct static_key_false {
   struct static_key key ;
};


union __anonunion_key_9 {
   struct static_key_true dd_key_true ;
   struct static_key_false dd_key_false ;
};


struct _ddebug {
   char const *modname ;
   char const *function ;
   char const *filename ;
   char const *format ;
   unsigned int lineno : 18 ;
   unsigned int flags : 8 ;
   union __anonunion_key_9 key ;
};


struct file_operations;


struct completion;


struct pt_regs;


union __anonunion___u_11 {
   struct list_head *__val ;
   char __c[1U] ;
};


union __anonunion___u_13 {
   struct list_head *__val ;
   char __c[1U] ;
};


union __anonunion___u_15 {
   struct list_head *__val ;
   char __c[1U] ;
};


struct bug_entry {
   int bug_addr_disp ;
   int file_disp ;
   unsigned short line ;
   unsigned short flags ;
};


typedef __s64 time64_t;


struct __kernel_timespec {
   __kernel_time64_t tv_sec ;
   long long tv_nsec ;
};


struct timespec64 {
   time64_t tv_sec ;
   long tv_nsec ;
};


struct old_timespec32;


struct pollfd;


enum timespec_type {
    TT_NONE = 0,
    TT_NATIVE = 1,
    TT_COMPAT = 2
};


struct __anonstruct_futex_38 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
   u32 *uaddr2 ;
};


union __anonunion_40 {
   struct __kernel_timespec *rmtp ;
   struct old_timespec32 *compat_rmtp ;
};


struct __anonstruct_nanosleep_39 {
   clockid_t clockid ;
   enum timespec_type type ;
   union __anonunion_40 __anonCompField___anonstruct_nanosleep_39_5 ;
   u64 expires ;
};


struct __anonstruct_poll_41 {
   struct pollfd *ufds ;
   int nfds ;
   int has_timeout ;
   unsigned long tv_sec ;
   unsigned long tv_nsec ;
};


union __anonunion_37 {
   struct __anonstruct_futex_38 futex ;
   struct __anonstruct_nanosleep_39 nanosleep ;
   struct __anonstruct_poll_41 poll ;
};


struct restart_block {
   long (*fn)(struct restart_block *) ;
   union __anonunion_37 __anonCompField_restart_block_6 ;
};


struct task_struct;


struct page;


struct mm_struct;


struct pt_regs {
   unsigned long r15 ;
   unsigned long r14 ;
   unsigned long r13 ;
   unsigned long r12 ;
   unsigned long bp ;
   unsigned long bx ;
   unsigned long r11 ;
   unsigned long r10 ;
   unsigned long r9 ;
   unsigned long r8 ;
   unsigned long ax ;
   unsigned long cx ;
   unsigned long dx ;
   unsigned long si ;
   unsigned long di ;
   unsigned long orig_ax ;
   unsigned long ip ;
   unsigned long cs ;
   unsigned long flags ;
   unsigned long sp ;
   unsigned long ss ;
};


struct desc_struct {
   u16 limit0 ;
   u16 base0 ;
   u16 base1 : 8 ;
   u16 type : 4 ;
   u16 s : 1 ;
   u16 dpl : 2 ;
   u16 p : 1 ;
   u16 limit1 : 4 ;
   u16 avl : 1 ;
   u16 l : 1 ;
   u16 d : 1 ;
   u16 g : 1 ;
   u16 base2 : 8 ;
};


typedef unsigned long pteval_t;


typedef unsigned long pmdval_t;


typedef unsigned long pudval_t;


typedef unsigned long pgdval_t;


typedef unsigned long pgprotval_t;


struct __anonstruct_pte_t_61 {
   pteval_t pte ;
};


typedef struct __anonstruct_pte_t_61 pte_t;


struct pgprot {
   pgprotval_t pgprot ;
};


typedef struct pgprot pgprot_t;


struct __anonstruct_pgd_t_62 {
   pgdval_t pgd ;
};


typedef struct __anonstruct_pgd_t_62 pgd_t;


struct __anonstruct_pud_t_64 {
   pudval_t pud ;
};


typedef struct __anonstruct_pud_t_64 pud_t;


struct __anonstruct_pmd_t_65 {
   pmdval_t pmd ;
};


typedef struct __anonstruct_pmd_t_65 pmd_t;


typedef struct page *pgtable_t;


struct file;


struct thread_struct;


struct cpumask;


struct vm_area_struct;


struct __anonstruct_67 {
   u8 locked ;
   u8 pending ;
};


struct __anonstruct_68 {
   u16 locked_pending ;
   u16 tail ;
};


union __anonunion_66 {
   atomic_t val ;
   struct __anonstruct_67 __anonCompField___anonunion_66_7 ;
   struct __anonstruct_68 __anonCompField___anonunion_66_8 ;
};


struct qspinlock {
   union __anonunion_66 __anonCompField_qspinlock_9 ;
};


typedef struct qspinlock arch_spinlock_t;


struct __anonstruct_70 {
   u8 wlocked ;
   u8 __lstate[3U] ;
};


union __anonunion_69 {
   atomic_t cnts ;
   struct __anonstruct_70 __anonCompField___anonunion_69_10 ;
};


struct qrwlock {
   union __anonunion_69 __anonCompField_qrwlock_11 ;
   arch_spinlock_t wait_lock ;
};


typedef struct qrwlock arch_rwlock_t;


struct math_emu_info {
   long ___orig_eip ;
   struct pt_regs *regs ;
};


struct cpumask {
   unsigned long bits[128U] ;
};


typedef struct cpumask cpumask_t;


union __anonunion___u_79 {
   int __val ;
   char __c[1U] ;
};


typedef atomic64_t atomic_long_t;


struct tracepoint_func {
   void *func ;
   void *data ;
   int prio ;
};


struct tracepoint {
   char const *name ;
   struct static_key key ;
   int (*regfunc)(void) ;
   void (*unregfunc)(void) ;
   struct tracepoint_func *funcs ;
};


typedef int const tracepoint_ptr_t;


struct bpf_raw_event_map {
   struct tracepoint *tp ;
   void *bpf_func ;
   u32 num_args ;
};


struct fregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};


struct __anonstruct_98 {
   u64 rip ;
   u64 rdp ;
};


struct __anonstruct_99 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};


union __anonunion_97 {
   struct __anonstruct_98 __anonCompField___anonunion_97_17 ;
   struct __anonstruct_99 __anonCompField___anonunion_97_18 ;
};


union __anonunion_100 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};


struct fxregs_state {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion_97 __anonCompField_fxregs_state_19 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion_100 __anonCompField_fxregs_state_20 ;
};


struct swregs_state {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct math_emu_info *info ;
   u32 entry_eip ;
};


struct xstate_header {
   u64 xfeatures ;
   u64 xcomp_bv ;
   u64 reserved[6U] ;
};


struct xregs_state {
   struct fxregs_state i387 ;
   struct xstate_header header ;
   u8 extended_state_area[0U] ;
};


union fpregs_state {
   struct fregs_state fsave ;
   struct fxregs_state fxsave ;
   struct swregs_state soft ;
   struct xregs_state xsave ;
   u8 __padding[4096U] ;
};


struct fpu {
   unsigned int last_cpu ;
   unsigned char initialized ;
   unsigned long avx512_timestamp ;
   union fpregs_state state ;
};


struct orc_entry {
   s16 sp_offset ;
   s16 bp_offset ;
   unsigned int sp_reg : 4 ;
   unsigned int bp_reg : 4 ;
   unsigned int type : 2 ;
   unsigned int end : 1 ;
};


struct perf_event;


struct __anonstruct_mm_segment_t_103 {
   unsigned long seg ;
};


typedef struct __anonstruct_mm_segment_t_103 mm_segment_t;


struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
   unsigned short gsindex ;
   unsigned long fsbase ;
   unsigned long gsbase ;
   struct perf_event *ptrace_bps[4U] ;
   unsigned long debugreg6 ;
   unsigned long ptrace_dr7 ;
   unsigned long cr2 ;
   unsigned long trap_nr ;
   unsigned long error_code ;
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
   unsigned int io_bitmap_max ;
   mm_segment_t addr_limit ;
   unsigned int sig_on_uaccess_err : 1 ;
   unsigned int uaccess_err : 1 ;
   struct fpu fpu ;
};


struct thread_info {
   unsigned long flags ;
   u32 status ;
};


struct lockdep_map;


struct stack_trace {
   unsigned int nr_entries ;
   unsigned int max_entries ;
   unsigned long *entries ;
   int skip ;
};


struct lockdep_subclass_key {
   char __one_byte ;
};


union __anonunion_104 {
   struct hlist_node hash_entry ;
   struct lockdep_subclass_key subkeys[8U] ;
};


struct lock_class_key {
   union __anonunion_104 __anonCompField_lock_class_key_23 ;
};


struct lock_class {
   struct hlist_node hash_entry ;
   struct list_head lock_entry ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
   unsigned int dep_gen_id ;
   unsigned long usage_mask ;
   struct stack_trace usage_traces[9U] ;
   int name_version ;
   char const *name ;
   unsigned long contention_point[4U] ;
   unsigned long contending_point[4U] ;
};


struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache[2U] ;
   char const *name ;
   int cpu ;
   unsigned long ip ;
};


struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned int class_idx : 13 ;
   unsigned int irq_context : 2 ;
   unsigned int trylock : 1 ;
   unsigned int read : 2 ;
   unsigned int check : 1 ;
   unsigned int hardirqs_off : 1 ;
   unsigned int references : 12 ;
   unsigned int pin_count ;
};


struct raw_spinlock {
   arch_spinlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};


typedef struct raw_spinlock raw_spinlock_t;


struct __anonstruct_106 {
   u8 __padding[24U] ;
   struct lockdep_map dep_map ;
};


union __anonunion_105 {
   struct raw_spinlock rlock ;
   struct __anonstruct_106 __anonCompField___anonunion_105_24 ;
};


struct spinlock {
   union __anonunion_105 __anonCompField_spinlock_25 ;
};


typedef struct spinlock spinlock_t;


struct __anonstruct_rwlock_t_107 {
   arch_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};


typedef struct __anonstruct_rwlock_t_107 rwlock_t;


struct mutex;


struct refcount_struct {
   atomic_t refs ;
};


typedef struct refcount_struct refcount_t;


struct kref {
   refcount_t refcount ;
};


enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_TGID = 1,
    PIDTYPE_PGID = 2,
    PIDTYPE_SID = 3,
    PIDTYPE_MAX = 4
};


struct pid_namespace;


struct upid {
   int nr ;
   struct pid_namespace *ns ;
};


struct pid {
   atomic_t count ;
   unsigned int level ;
   struct hlist_head tasks[4U] ;
   struct callback_head rcu ;
   struct upid numbers[1U] ;
};


struct user_namespace;


struct __anonstruct_kuid_t_152 {
   uid_t val ;
};


typedef struct __anonstruct_kuid_t_152 kuid_t;


struct __anonstruct_kgid_t_153 {
   gid_t val ;
};


typedef struct __anonstruct_kgid_t_153 kgid_t;


struct optimistic_spin_queue {
   atomic_t tail ;
};


struct ww_acquire_ctx;


struct mutex {
   atomic_long_t owner ;
   spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct list_head wait_list ;
   void *magic ;
   struct lockdep_map dep_map ;
};


struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   struct ww_acquire_ctx *ww_ctx ;
   void *magic ;
};


struct seqcount {
   unsigned int sequence ;
   struct lockdep_map dep_map ;
};


typedef struct seqcount seqcount_t;


typedef s32 old_time32_t;


struct old_timespec32 {
   old_time32_t tv_sec ;
   s32 tv_nsec ;
};


typedef s64 ktime_t;


struct timer_list {
   struct hlist_node entry ;
   unsigned long expires ;
   void (*function)(struct timer_list *) ;
   u32 flags ;
   struct lockdep_map lockdep_map ;
};


struct hrtimer;


enum hrtimer_restart;


struct workqueue_struct;


struct work_struct;


struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct *) ;
   struct lockdep_map lockdep_map ;
};


struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
   struct workqueue_struct *wq ;
   int cpu ;
};


struct sem_undo_list;


struct sysv_sem {
   struct sem_undo_list *undo_list ;
};


struct sysv_shm {
   struct list_head shm_clist ;
};


struct plist_node {
   int prio ;
   struct list_head prio_list ;
   struct list_head node_list ;
};


struct rb_node {
   unsigned long __rb_parent_color ;
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};


struct rb_root {
   struct rb_node *rb_node ;
};


struct rb_root_cached {
   struct rb_root rb_root ;
   struct rb_node *rb_leftmost ;
};


struct llist_node;


struct llist_node {
   struct llist_node *next ;
};


struct __anonstruct_nodemask_t_215 {
   unsigned long bits[16U] ;
};


typedef struct __anonstruct_nodemask_t_215 nodemask_t;


struct rw_semaphore;


struct rw_semaphore {
   atomic_long_t count ;
   struct list_head wait_list ;
   raw_spinlock_t wait_lock ;
   struct optimistic_spin_queue osq ;
   struct task_struct *owner ;
   struct lockdep_map dep_map ;
};


struct ldt_struct;


struct vdso_image;


struct __anonstruct_mm_context_t_216 {
   u64 ctx_id ;
   atomic64_t tlb_gen ;
   struct rw_semaphore ldt_usr_sem ;
   struct ldt_struct *ldt ;
   unsigned short ia32_compat ;
   struct mutex lock ;
   void *vdso ;
   struct vdso_image const *vdso_image ;
   atomic_t perf_rdpmc_allowed ;
   u16 pkey_allocation_map ;
   s16 execute_only_pkey ;
   void *bd_addr ;
};


typedef struct __anonstruct_mm_context_t_216 mm_context_t;


struct fwnode_operations;


struct fwnode_handle {
   struct fwnode_handle *secondary ;
   struct fwnode_operations const *ops ;
};


struct fwnode_endpoint {
   unsigned int port ;
   unsigned int id ;
   struct fwnode_handle const *local_fwnode ;
};


struct fwnode_reference_args {
   struct fwnode_handle *fwnode ;
   unsigned int nargs ;
   u64 args[8U] ;
};


struct fwnode_operations {
   struct fwnode_handle *(*get)(struct fwnode_handle *) ;
   void (*put)(struct fwnode_handle *) ;
   bool (*device_is_available)(struct fwnode_handle const *) ;
   void const *(*device_get_match_data)(struct fwnode_handle const *, struct device const *) ;
   bool (*property_present)(struct fwnode_handle const *, char const *) ;
   int (*property_read_int_array)(struct fwnode_handle const *, char const *, unsigned int , void *, size_t ) ;
   int (*property_read_string_array)(struct fwnode_handle const *, char const *, char const **, size_t ) ;
   struct fwnode_handle *(*get_parent)(struct fwnode_handle const *) ;
   struct fwnode_handle *(*get_next_child_node)(struct fwnode_handle const *, struct fwnode_handle *) ;
   struct fwnode_handle *(*get_named_child_node)(struct fwnode_handle const *, char const *) ;
   int (*get_reference_args)(struct fwnode_handle const *, char const *, char const *, unsigned int , unsigned int , struct fwnode_reference_args *) ;
   struct fwnode_handle *(*graph_get_next_endpoint)(struct fwnode_handle const *, struct fwnode_handle *) ;
   struct fwnode_handle *(*graph_get_remote_endpoint)(struct fwnode_handle const *) ;
   struct fwnode_handle *(*graph_get_port_parent)(struct fwnode_handle *) ;
   int (*graph_parse_endpoint)(struct fwnode_handle const *, struct fwnode_endpoint *) ;
};


struct arch_tlbflush_unmap_batch {
   struct cpumask cpumask ;
};


struct vmacache {
   u64 seqnum ;
   struct vm_area_struct *vmas[4U] ;
};


struct task_rss_stat {
   int events ;
   int count[4U] ;
};


struct mm_rss_stat {
   atomic_long_t count[4U] ;
};


struct page_frag {
   struct page *page ;
   __u32 offset ;
   __u32 size ;
};


struct tlbflush_unmap_batch {
   struct arch_tlbflush_unmap_batch arch ;
   bool flush_required ;
   bool writable ;
};


struct wait_queue_head {
   spinlock_t lock ;
   struct list_head head ;
};


typedef struct wait_queue_head wait_queue_head_t;


struct completion {
   unsigned int done ;
   wait_queue_head_t wait ;
};


struct inode;


struct arch_uprobe_task {
   unsigned long saved_scratch_register ;
   unsigned int saved_trap_nr ;
   unsigned int saved_tf ;
};


enum uprobe_task_state {
    UTASK_RUNNING = 0,
    UTASK_SSTEP = 1,
    UTASK_SSTEP_ACK = 2,
    UTASK_SSTEP_TRAPPED = 3
};


struct __anonstruct_231 {
   struct arch_uprobe_task autask ;
   unsigned long vaddr ;
};


struct __anonstruct_232 {
   struct callback_head dup_xol_work ;
   unsigned long dup_xol_addr ;
};


union __anonunion_230 {
   struct __anonstruct_231 __anonCompField___anonunion_230_28 ;
   struct __anonstruct_232 __anonCompField___anonunion_230_29 ;
};


struct uprobe;


struct return_instance;


struct uprobe_task {
   enum uprobe_task_state state ;
   union __anonunion_230 __anonCompField_uprobe_task_30 ;
   struct uprobe *active_uprobe ;
   unsigned long xol_vaddr ;
   struct return_instance *return_instances ;
   unsigned int depth ;
};


struct return_instance {
   struct uprobe *uprobe ;
   unsigned long func ;
   unsigned long stack ;
   unsigned long orig_ret_vaddr ;
   bool chained ;
   struct return_instance *next ;
};


struct xol_area;


struct uprobes_state {
   struct xol_area *xol_area ;
};


struct address_space;


struct mem_cgroup;


struct hmm;


struct __anonstruct_234 {
   struct list_head lru ;
   struct address_space *mapping ;
   unsigned long index ;
   unsigned long private ;
};


struct __anonstruct_235 {
   dma_addr_t dma_addr ;
};


struct __anonstruct_238 {
   struct page *next ;
   int pages ;
   int pobjects ;
};


union __anonunion_237 {
   struct list_head slab_list ;
   struct __anonstruct_238 __anonCompField___anonunion_237_33 ;
};


struct kmem_cache;


struct __anonstruct_240 {
   unsigned int inuse : 16 ;
   unsigned int objects : 15 ;
   unsigned int frozen : 1 ;
};


union __anonunion_239 {
   void *s_mem ;
   unsigned long counters ;
   struct __anonstruct_240 __anonCompField___anonunion_239_35 ;
};


struct __anonstruct_236 {
   union __anonunion_237 __anonCompField___anonstruct_236_34 ;
   struct kmem_cache *slab_cache ;
   void *freelist ;
   union __anonunion_239 __anonCompField___anonstruct_236_36 ;
};


struct __anonstruct_241 {
   unsigned long compound_head ;
   unsigned char compound_dtor ;
   unsigned char compound_order ;
   atomic_t compound_mapcount ;
};


struct __anonstruct_242 {
   unsigned long _compound_pad_1 ;
   unsigned long _compound_pad_2 ;
   struct list_head deferred_list ;
};


union __anonunion_244 {
   struct mm_struct *pt_mm ;
   atomic_t pt_frag_refcount ;
};


struct __anonstruct_243 {
   unsigned long _pt_pad_1 ;
   pgtable_t pmd_huge_pte ;
   unsigned long _pt_pad_2 ;
   union __anonunion_244 __anonCompField___anonstruct_243_40 ;
   spinlock_t *ptl ;
};


struct dev_pagemap;


struct __anonstruct_245 {
   struct dev_pagemap *pgmap ;
   unsigned long hmm_data ;
   unsigned long _zd_pad_1 ;
};


union __anonunion_233 {
   struct __anonstruct_234 __anonCompField___anonunion_233_31 ;
   struct __anonstruct_235 __anonCompField___anonunion_233_32 ;
   struct __anonstruct_236 __anonCompField___anonunion_233_37 ;
   struct __anonstruct_241 __anonCompField___anonunion_233_38 ;
   struct __anonstruct_242 __anonCompField___anonunion_233_39 ;
   struct __anonstruct_243 __anonCompField___anonunion_233_41 ;
   struct __anonstruct_245 __anonCompField___anonunion_233_42 ;
   struct callback_head callback_head ;
};


union __anonunion_246 {
   atomic_t _mapcount ;
   unsigned int page_type ;
   unsigned int active ;
   int units ;
};


struct page {
   unsigned long flags ;
   union __anonunion_233 __anonCompField_page_43 ;
   union __anonunion_246 __anonCompField_page_44 ;
   atomic_t _refcount ;
   struct mem_cgroup *mem_cgroup ;
};


struct userfaultfd_ctx;


struct vm_userfaultfd_ctx {
   struct userfaultfd_ctx *ctx ;
};


struct __anonstruct_shared_247 {
   struct rb_node rb ;
   unsigned long rb_subtree_last ;
};


struct anon_vma;


struct vm_operations_struct;


struct mempolicy;


struct vm_area_struct {
   unsigned long vm_start ;
   unsigned long vm_end ;
   struct vm_area_struct *vm_next ;
   struct vm_area_struct *vm_prev ;
   struct rb_node vm_rb ;
   unsigned long rb_subtree_gap ;
   struct mm_struct *vm_mm ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
   struct __anonstruct_shared_247 shared ;
   struct list_head anon_vma_chain ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct const *vm_ops ;
   unsigned long vm_pgoff ;
   struct file *vm_file ;
   void *vm_private_data ;
   atomic_long_t swap_readahead_info ;
   struct mempolicy *vm_policy ;
   struct vm_userfaultfd_ctx vm_userfaultfd_ctx ;
};


struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};


struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};


struct kioctx_table;


struct linux_binfmt;


struct mmu_notifier_mm;


struct __anonstruct_248 {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   u64 vmacache_seqnum ;
   unsigned long (*get_unmapped_area)(struct file *, unsigned long , unsigned long , unsigned long , unsigned long ) ;
   unsigned long mmap_base ;
   unsigned long mmap_legacy_base ;
   unsigned long mmap_compat_base ;
   unsigned long mmap_compat_legacy_base ;
   unsigned long task_size ;
   unsigned long highest_vm_end ;
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   atomic_long_t pgtables_bytes ;
   int map_count ;
   spinlock_t page_table_lock ;
   struct rw_semaphore mmap_sem ;
   struct list_head mmlist ;
   unsigned long hiwater_rss ;
   unsigned long hiwater_vm ;
   unsigned long total_vm ;
   unsigned long locked_vm ;
   atomic64_t pinned_vm ;
   unsigned long data_vm ;
   unsigned long exec_vm ;
   unsigned long stack_vm ;
   unsigned long def_flags ;
   spinlock_t arg_lock ;
   unsigned long start_code ;
   unsigned long end_code ;
   unsigned long start_data ;
   unsigned long end_data ;
   unsigned long start_brk ;
   unsigned long brk ;
   unsigned long start_stack ;
   unsigned long arg_start ;
   unsigned long arg_end ;
   unsigned long env_start ;
   unsigned long env_end ;
   unsigned long saved_auxv[46U] ;
   struct mm_rss_stat rss_stat ;
   struct linux_binfmt *binfmt ;
   mm_context_t context ;
   unsigned long flags ;
   struct core_state *core_state ;
   atomic_t membarrier_state ;
   spinlock_t ioctx_lock ;
   struct kioctx_table *ioctx_table ;
   struct task_struct *owner ;
   struct user_namespace *user_ns ;
   struct file *exe_file ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
   unsigned long numa_next_scan ;
   unsigned long numa_scan_offset ;
   int numa_scan_seq ;
   atomic_t tlb_flush_pending ;
   bool tlb_flush_batched ;
   struct uprobes_state uprobes_state ;
   atomic_long_t hugetlb_usage ;
   struct work_struct async_put_work ;
   struct hmm *hmm ;
};


struct mm_struct {
   struct __anonstruct_248 __anonCompField_mm_struct_45 ;
   unsigned long cpu_bitmap[] ;
};


struct vm_fault;


typedef unsigned int vm_fault_t;


struct timerqueue_node {
   struct rb_node node ;
   ktime_t expires ;
};


struct timerqueue_head {
   struct rb_root head ;
   struct timerqueue_node *next ;
};


struct hrtimer_clock_base;


struct hrtimer_cpu_base;


enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
};


struct hrtimer {
   struct timerqueue_node node ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer *) ;
   struct hrtimer_clock_base *base ;
   u8 state ;
   u8 is_rel ;
   u8 is_soft ;
};


struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   unsigned int index ;
   clockid_t clockid ;
   seqcount_t seq ;
   struct hrtimer *running ;
   struct timerqueue_head active ;
   ktime_t (*get_time)(void) ;
   ktime_t offset ;
};


struct hrtimer_cpu_base {
   raw_spinlock_t lock ;
   unsigned int cpu ;
   unsigned int active_bases ;
   unsigned int clock_was_set_seq ;
   unsigned int hres_active : 1 ;
   unsigned int in_hrtirq : 1 ;
   unsigned int hang_detected : 1 ;
   unsigned int softirq_activated : 1 ;
   unsigned int nr_events ;
   unsigned short nr_retries ;
   unsigned short nr_hangs ;
   unsigned int max_hang_time ;
   ktime_t expires_next ;
   struct hrtimer *next_timer ;
   ktime_t softirq_expires_next ;
   struct hrtimer *softirq_next_timer ;
   struct hrtimer_clock_base clock_base[8U] ;
};


struct seccomp_filter;


struct seccomp {
   int mode ;
   struct seccomp_filter *filter ;
};


struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
   unsigned long max ;
};


struct __anonstruct_sigset_t_259 {
   unsigned long sig[1U] ;
};


typedef struct __anonstruct_sigset_t_259 sigset_t;


union sigval {
   int sival_int ;
   void *sival_ptr ;
};


typedef union sigval sigval_t;


struct __anonstruct__kill_260 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
};


struct __anonstruct__timer_261 {
   __kernel_timer_t _tid ;
   int _overrun ;
   sigval_t _sigval ;
   int _sys_private ;
};


struct __anonstruct__rt_262 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   sigval_t _sigval ;
};


struct __anonstruct__sigchld_263 {
   __kernel_pid_t _pid ;
   __kernel_uid32_t _uid ;
   int _status ;
   __kernel_clock_t _utime ;
   __kernel_clock_t _stime ;
};


struct __anonstruct__addr_bnd_266 {
   char _dummy_bnd[8U] ;
   void *_lower ;
   void *_upper ;
};


struct __anonstruct__addr_pkey_267 {
   char _dummy_pkey[8U] ;
   __u32 _pkey ;
};


union __anonunion_265 {
   short _addr_lsb ;
   struct __anonstruct__addr_bnd_266 _addr_bnd ;
   struct __anonstruct__addr_pkey_267 _addr_pkey ;
};


struct __anonstruct__sigfault_264 {
   void *_addr ;
   union __anonunion_265 __anonCompField___anonstruct__sigfault_264_46 ;
};


struct __anonstruct__sigpoll_268 {
   long _band ;
   int _fd ;
};


struct __anonstruct__sigsys_269 {
   void *_call_addr ;
   int _syscall ;
   unsigned int _arch ;
};


union __sifields {
   struct __anonstruct__kill_260 _kill ;
   struct __anonstruct__timer_261 _timer ;
   struct __anonstruct__rt_262 _rt ;
   struct __anonstruct__sigchld_263 _sigchld ;
   struct __anonstruct__sigfault_264 _sigfault ;
   struct __anonstruct__sigpoll_268 _sigpoll ;
   struct __anonstruct__sigsys_269 _sigsys ;
};


struct __anonstruct_274 {
   int si_signo ;
   int si_errno ;
   int si_code ;
   union __sifields _sifields ;
};


struct kernel_siginfo {
   struct __anonstruct_274 __anonCompField_kernel_siginfo_49 ;
};


typedef struct kernel_siginfo kernel_siginfo_t;


struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};


struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};


union __anonunion_rseq_cs_275 {
   __u64 ptr64 ;
   __u64 ptr ;
};


struct rseq {
   __u32 cpu_id_start ;
   __u32 cpu_id ;
   union __anonunion_rseq_cs_275 rseq_cs ;
   __u32 flags ;
};


struct audit_context;


struct backing_dev_info;


struct bio_list;


struct blk_plug;


struct cfs_rq;


struct fs_struct;


struct futex_pi_state;


struct io_context;


struct nameidata;


struct nsproxy;


struct perf_event_context;


struct pipe_inode_info;


struct reclaim_state;


struct capture_control;


struct robust_list_head;


struct sighand_struct;


struct signal_struct;


struct task_delay_info;


struct task_group;


struct prev_cputime {
   u64 utime ;
   u64 stime ;
   raw_spinlock_t lock ;
};


struct task_cputime {
   u64 utime ;
   u64 stime ;
   unsigned long long sum_exec_runtime ;
};


struct sched_info {
   unsigned long pcount ;
   unsigned long long run_delay ;
   unsigned long long last_arrival ;
   unsigned long long last_queued ;
};


struct load_weight {
   unsigned long weight ;
   u32 inv_weight ;
};


struct util_est {
   unsigned int enqueued ;
   unsigned int ewma ;
};


struct sched_avg {
   u64 last_update_time ;
   u64 load_sum ;
   u64 runnable_load_sum ;
   u32 util_sum ;
   u32 period_contrib ;
   unsigned long load_avg ;
   unsigned long runnable_load_avg ;
   unsigned long util_avg ;
   struct util_est util_est ;
};


struct sched_statistics {
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 iowait_count ;
   u64 iowait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
};


struct sched_entity {
   struct load_weight load ;
   unsigned long runnable_weight ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 nr_migrations ;
   struct sched_statistics statistics ;
   int depth ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
   struct sched_avg avg ;
};


struct rt_rq;


struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
   unsigned long watchdog_stamp ;
   unsigned int time_slice ;
   unsigned short on_rq ;
   unsigned short on_list ;
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};


struct sched_dl_entity {
   struct rb_node rb_node ;
   u64 dl_runtime ;
   u64 dl_deadline ;
   u64 dl_period ;
   u64 dl_bw ;
   u64 dl_density ;
   s64 runtime ;
   u64 deadline ;
   unsigned int flags ;
   unsigned int dl_throttled : 1 ;
   unsigned int dl_boosted : 1 ;
   unsigned int dl_yielded : 1 ;
   unsigned int dl_non_contending : 1 ;
   unsigned int dl_overrun : 1 ;
   struct hrtimer dl_timer ;
   struct hrtimer inactive_timer ;
};


struct wake_q_node {
   struct wake_q_node *next ;
};


struct sched_class;


struct files_struct;


struct rt_mutex_waiter;


struct compat_robust_list_head;


struct numa_group;


struct ftrace_ret_stack;


struct kcov;


struct request_queue;


struct task_struct {
   struct thread_info thread_info ;
   long volatile state ;
   void *stack ;
   refcount_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
   struct llist_node wake_entry ;
   int on_cpu ;
   unsigned int cpu ;
   unsigned int wakee_flips ;
   unsigned long wakee_flip_decay_ts ;
   struct task_struct *last_wakee ;
   int recent_used_cpu ;
   int wake_cpu ;
   int on_rq ;
   int prio ;
   int static_prio ;
   int normal_prio ;
   unsigned int rt_priority ;
   struct sched_class const *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct task_group *sched_task_group ;
   struct sched_dl_entity dl ;
   struct hlist_head preempt_notifiers ;
   unsigned int btrace_seq ;
   unsigned int policy ;
   int nr_cpus_allowed ;
   cpumask_t cpus_allowed ;
   unsigned long rcu_tasks_nvcsw ;
   u8 rcu_tasks_holdout ;
   u8 rcu_tasks_idx ;
   int rcu_tasks_idle_cpu ;
   struct list_head rcu_tasks_holdout_list ;
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct plist_node pushable_tasks ;
   struct rb_node pushable_dl_tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   struct vmacache vmacache ;
   struct task_rss_stat rss_stat ;
   int exit_state ;
   int exit_code ;
   int exit_signal ;
   int pdeath_signal ;
   unsigned long jobctl ;
   unsigned int personality ;
   unsigned int sched_reset_on_fork : 1 ;
   unsigned int sched_contributes_to_load : 1 ;
   unsigned int sched_migrated : 1 ;
   unsigned int sched_remote_wakeup : 1 ;
   unsigned int sched_psi_wake_requeue : 1 ;
   unsigned int  ;
   unsigned int in_execve : 1 ;
   unsigned int in_iowait : 1 ;
   unsigned int restore_sigmask : 1 ;
   unsigned int in_user_fault : 1 ;
   unsigned int brk_randomized : 1 ;
   unsigned int no_cgroup_migration : 1 ;
   unsigned int use_memdelay : 1 ;
   unsigned long atomic_flags ;
   struct restart_block restart_block ;
   pid_t pid ;
   pid_t tgid ;
   unsigned long stack_canary ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid *thread_pid ;
   struct hlist_node pid_links[4U] ;
   struct list_head thread_group ;
   struct list_head thread_node ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   u64 utime ;
   u64 stime ;
   u64 gtime ;
   struct prev_cputime prev_cputime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   u64 start_time ;
   u64 real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   struct cred const *ptracer_cred ;
   struct cred const *real_cred ;
   struct cred const *cred ;
   char comm[16U] ;
   struct nameidata *nameidata ;
   struct sysv_sem sysvsem ;
   struct sysv_shm sysvshm ;
   unsigned long last_switch_count ;
   unsigned long last_switch_time ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
   size_t sas_ss_size ;
   unsigned int sas_ss_flags ;
   struct callback_head *task_works ;
   struct audit_context *audit_context ;
   kuid_t loginuid ;
   unsigned int sessionid ;
   struct seccomp seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   raw_spinlock_t pi_lock ;
   struct wake_q_node wake_q ;
   struct rb_root_cached pi_waiters ;
   struct task_struct *pi_top_task ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
   unsigned long hardirq_enable_ip ;
   unsigned long hardirq_disable_ip ;
   unsigned int hardirq_enable_event ;
   unsigned int hardirq_disable_event ;
   int hardirqs_enabled ;
   int hardirq_context ;
   unsigned long softirq_disable_ip ;
   unsigned long softirq_enable_ip ;
   unsigned int softirq_disable_event ;
   unsigned int softirq_enable_event ;
   int softirqs_enabled ;
   int softirq_context ;
   u64 curr_chain_key ;
   int lockdep_depth ;
   unsigned int lockdep_recursion ;
   struct held_lock held_locks[48U] ;
   unsigned int in_ubsan ;
   void *journal_info ;
   struct bio_list *bio_list ;
   struct blk_plug *plug ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   struct capture_control *capture_control ;
   unsigned long ptrace_message ;
   kernel_siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   unsigned int psi_flags ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   u64 acct_timexpd ;
   nodemask_t mems_allowed ;
   seqcount_t mems_allowed_seq ;
   int cpuset_mem_spread_rotor ;
   int cpuset_slab_spread_rotor ;
   struct css_set *cgroups ;
   struct list_head cg_list ;
   u32 closid ;
   u32 rmid ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct perf_event_context *perf_event_ctxp[2U] ;
   struct mutex perf_event_mutex ;
   struct list_head perf_event_list ;
   struct mempolicy *mempolicy ;
   short il_prev ;
   short pref_node_fork ;
   int numa_scan_seq ;
   unsigned int numa_scan_period ;
   unsigned int numa_scan_period_max ;
   int numa_preferred_nid ;
   unsigned long numa_migrate_retry ;
   u64 node_stamp ;
   u64 last_task_numa_placement ;
   u64 last_sum_exec_runtime ;
   struct callback_head numa_work ;
   struct numa_group *numa_group ;
   unsigned long *numa_faults ;
   unsigned long total_numa_faults ;
   unsigned long numa_faults_locality[3U] ;
   unsigned long numa_pages_migrated ;
   struct rseq *rseq ;
   u32 rseq_len ;
   u32 rseq_sig ;
   unsigned long rseq_event_mask ;
   struct tlbflush_unmap_batch tlb_ubc ;
   struct callback_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct page_frag task_frag ;
   struct task_delay_info *delays ;
   int make_it_fail ;
   unsigned int fail_nth ;
   int nr_dirtied ;
   int nr_dirtied_pause ;
   unsigned long dirty_paused_when ;
   int latency_record_count ;
   struct latency_record latency_record[32U] ;
   u64 timer_slack_ns ;
   u64 default_timer_slack_ns ;
   unsigned int kasan_depth ;
   int curr_ret_stack ;
   int curr_ret_depth ;
   struct ftrace_ret_stack *ret_stack ;
   unsigned long long ftrace_timestamp ;
   atomic_t trace_overrun ;
   atomic_t tracing_graph_pause ;
   unsigned long trace ;
   unsigned long trace_recursion ;
   unsigned int kcov_mode ;
   unsigned int kcov_size ;
   void *kcov_area ;
   struct kcov *kcov ;
   struct mem_cgroup *memcg_in_oom ;
   gfp_t memcg_oom_gfp_mask ;
   int memcg_oom_order ;
   unsigned int memcg_nr_pages_over_high ;
   struct mem_cgroup *active_memcg ;
   struct request_queue *throttle_queue ;
   struct uprobe_task *utask ;
   unsigned int sequential_io ;
   unsigned int sequential_io_avg ;
   unsigned long task_state_change ;
   int pagefault_disabled ;
   struct task_struct *oom_reaper_list ;
   refcount_t stack_refcount ;
   int patch_state ;
   void *security ;
   struct thread_struct thread ;
};


struct mnt_namespace;


struct uts_namespace;


struct ipc_namespace;


struct net;


struct nsproxy {
   atomic_t count ;
   struct uts_namespace *uts_ns ;
   struct ipc_namespace *ipc_ns ;
   struct mnt_namespace *mnt_ns ;
   struct pid_namespace *pid_ns_for_children ;
   struct net *net_ns ;
   struct cgroup_namespace *cgroup_ns ;
};


struct proc_ns_operations;


struct ns_common {
   atomic_long_t stashed ;
   struct proc_ns_operations const *ops ;
   unsigned int inum ;
};


struct ctl_table_root;


struct ctl_table_header;


struct ctl_dir;


typedef int proc_handler(struct ctl_table *, int , void *, size_t *, loff_t *);


struct ctl_table_poll {
   atomic_t event ;
   wait_queue_head_t wait ;
};


struct ctl_table {
   char const *procname ;
   void *data ;
   int maxlen ;
   umode_t mode ;
   struct ctl_table *child ;
   proc_handler *proc_handler ;
   struct ctl_table_poll *poll ;
   void *extra1 ;
   void *extra2 ;
};


struct ctl_node {
   struct rb_node node ;
   struct ctl_table_header *header ;
};


struct __anonstruct_284 {
   struct ctl_table *ctl_table ;
   int used ;
   int count ;
   int nreg ;
};


union __anonunion_283 {
   struct __anonstruct_284 __anonCompField___anonunion_283_50 ;
   struct callback_head rcu ;
};


struct ctl_table_set;


struct ctl_table_header {
   union __anonunion_283 __anonCompField_ctl_table_header_51 ;
   struct completion *unregistering ;
   struct ctl_table *ctl_table_arg ;
   struct ctl_table_root *root ;
   struct ctl_table_set *set ;
   struct ctl_dir *parent ;
   struct ctl_node *node ;
   struct hlist_head inodes ;
};


struct ctl_dir {
   struct ctl_table_header header ;
   struct rb_root root ;
};


struct ctl_table_set {
   int (*is_seen)(struct ctl_table_set *) ;
   struct ctl_dir dir ;
};


struct ctl_table_root {
   struct ctl_table_set default_set ;
   struct ctl_table_set *(*lookup)(struct ctl_table_root *) ;
   void (*set_ownership)(struct ctl_table_header *, struct ctl_table *, kuid_t *, kgid_t *) ;
   int (*permissions)(struct ctl_table_header *, struct ctl_table *) ;
};


struct uid_gid_extent {
   u32 first ;
   u32 lower_first ;
   u32 count ;
};


struct __anonstruct_286 {
   struct uid_gid_extent *forward ;
   struct uid_gid_extent *reverse ;
};


union __anonunion_285 {
   struct uid_gid_extent extent[5U] ;
   struct __anonstruct_286 __anonCompField___anonunion_285_52 ;
};


struct uid_gid_map {
   u32 nr_extents ;
   union __anonunion_285 __anonCompField_uid_gid_map_53 ;
};


struct ucounts;


struct user_namespace {
   struct uid_gid_map uid_map ;
   struct uid_gid_map gid_map ;
   struct uid_gid_map projid_map ;
   atomic_t count ;
   struct user_namespace *parent ;
   int level ;
   kuid_t owner ;
   kgid_t group ;
   struct ns_common ns ;
   unsigned long flags ;
   struct key *persistent_keyring_register ;
   struct rw_semaphore persistent_keyring_register_sem ;
   struct work_struct work ;
   struct ctl_table_set set ;
   struct ctl_table_header *sysctls ;
   struct ucounts *ucounts ;
   int ucount_max[9U] ;
};


struct ucounts {
   struct hlist_node node ;
   struct user_namespace *ns ;
   kuid_t uid ;
   int count ;
   atomic_t ucount[9U] ;
};


struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const *name ;
   unsigned long flags ;
   unsigned long desc ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};


typedef unsigned int isolate_mode_t;


struct vmem_altmap;


struct xarray {
   spinlock_t xa_lock ;
   gfp_t xa_flags ;
   void *xa_head ;
};


struct idr {
   struct xarray idr_rt ;
   unsigned int idr_base ;
   unsigned int idr_next ;
};


struct dentry;


struct iattr;


struct super_block;


struct file_system_type;


struct poll_table_struct;


struct fs_context;


struct kernfs_open_node;


struct kernfs_iattrs;


struct kernfs_root;


struct kernfs_elem_dir {
   unsigned long subdirs ;
   struct rb_root children ;
   struct kernfs_root *root ;
};


struct kernfs_node;


struct kernfs_elem_symlink {
   struct kernfs_node *target_kn ;
};


struct kernfs_ops;


struct kernfs_elem_attr {
   struct kernfs_ops const *ops ;
   struct kernfs_open_node *open ;
   loff_t size ;
   struct kernfs_node *notify_next ;
};


struct __anonstruct_313 {
   u32 ino ;
   u32 generation ;
};


union kernfs_node_id {
   struct __anonstruct_313 __anonCompField_kernfs_node_id_56 ;
   u64 id ;
};


union __anonunion_314 {
   struct kernfs_elem_dir dir ;
   struct kernfs_elem_symlink symlink ;
   struct kernfs_elem_attr attr ;
};


struct kernfs_node {
   atomic_t count ;
   atomic_t active ;
   struct lockdep_map dep_map ;
   struct kernfs_node *parent ;
   char const *name ;
   struct rb_node rb ;
   void const *ns ;
   unsigned int hash ;
   union __anonunion_314 __anonCompField_kernfs_node_57 ;
   void *priv ;
   union kernfs_node_id id ;
   unsigned short flags ;
   umode_t mode ;
   struct kernfs_iattrs *iattr ;
};


struct kernfs_syscall_ops {
   int (*show_options)(struct seq_file *, struct kernfs_root *) ;
   int (*mkdir)(struct kernfs_node *, char const *, umode_t ) ;
   int (*rmdir)(struct kernfs_node *) ;
   int (*rename)(struct kernfs_node *, struct kernfs_node *, char const *) ;
   int (*show_path)(struct seq_file *, struct kernfs_node *, struct kernfs_root *) ;
};


struct kernfs_root {
   struct kernfs_node *kn ;
   unsigned int flags ;
   struct idr ino_idr ;
   u32 next_generation ;
   struct kernfs_syscall_ops *syscall_ops ;
   struct list_head supers ;
   wait_queue_head_t deactivate_waitq ;
};


struct kernfs_open_file {
   struct kernfs_node *kn ;
   struct file *file ;
   struct seq_file *seq_file ;
   void *priv ;
   struct mutex mutex ;
   struct mutex prealloc_mutex ;
   int event ;
   struct list_head list ;
   char *prealloc_buf ;
   size_t atomic_write_len ;
   bool mmapped : 1 ;
   bool released : 1 ;
   struct vm_operations_struct const *vm_ops ;
};


struct kernfs_ops {
   int (*open)(struct kernfs_open_file *) ;
   void (*release)(struct kernfs_open_file *) ;
   int (*seq_show)(struct seq_file *, void *) ;
   void *(*seq_start)(struct seq_file *, loff_t *) ;
   void *(*seq_next)(struct seq_file *, void *, loff_t *) ;
   void (*seq_stop)(struct seq_file *, void *) ;
   ssize_t (*read)(struct kernfs_open_file *, char *, size_t , loff_t ) ;
   size_t atomic_write_len ;
   bool prealloc ;
   ssize_t (*write)(struct kernfs_open_file *, char *, size_t , loff_t ) ;
   __poll_t (*poll)(struct kernfs_open_file *, struct poll_table_struct *) ;
   int (*mmap)(struct kernfs_open_file *, struct vm_area_struct *) ;
   struct lock_class_key lockdep_key ;
};


struct sock;


struct kobject;


enum kobj_ns_type {
    KOBJ_NS_TYPE_NONE = 0,
    KOBJ_NS_TYPE_NET = 1,
    KOBJ_NS_TYPES = 2
};


struct kobj_ns_type_operations {
   enum kobj_ns_type type ;
   bool (*current_may_mount)(void) ;
   void *(*grab_current_ns)(void) ;
   void const *(*netlink_ns)(struct sock *) ;
   void const *(*initial_ns)(void) ;
   void (*drop_ns)(void *) ;
};


struct kstat {
   u32 result_mask ;
   umode_t mode ;
   unsigned int nlink ;
   uint32_t blksize ;
   u64 attributes ;
   u64 attributes_mask ;
   u64 ino ;
   dev_t dev ;
   dev_t rdev ;
   kuid_t uid ;
   kgid_t gid ;
   loff_t size ;
   struct timespec64 atime ;
   struct timespec64 mtime ;
   struct timespec64 ctime ;
   struct timespec64 btime ;
   u64 blocks ;
};


struct bin_attribute;


struct attribute {
   char const *name ;
   umode_t mode ;
   bool ignore_lockdep : 1 ;
   struct lock_class_key *key ;
   struct lock_class_key skey ;
};


struct attribute_group {
   char const *name ;
   umode_t (*is_visible)(struct kobject *, struct attribute *, int ) ;
   umode_t (*is_bin_visible)(struct kobject *, struct bin_attribute *, int ) ;
   struct attribute **attrs ;
   struct bin_attribute **bin_attrs ;
};


struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct file *, struct kobject *, struct bin_attribute *, char *, loff_t , size_t ) ;
   ssize_t (*write)(struct file *, struct kobject *, struct bin_attribute *, char *, loff_t , size_t ) ;
   int (*mmap)(struct file *, struct kobject *, struct bin_attribute *, struct vm_area_struct *) ;
};


struct sysfs_ops {
   ssize_t (*show)(struct kobject *, struct attribute *, char *) ;
   ssize_t (*store)(struct kobject *, struct attribute *, char const *, size_t ) ;
};


struct kset;


struct kobj_type;


struct kobject {
   char const *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct kernfs_node *sd ;
   struct kref kref ;
   struct delayed_work release ;
   unsigned int state_initialized : 1 ;
   unsigned int state_in_sysfs : 1 ;
   unsigned int state_add_uevent_sent : 1 ;
   unsigned int state_remove_uevent_sent : 1 ;
   unsigned int uevent_suppress : 1 ;
};


struct kobj_type {
   void (*release)(struct kobject *) ;
   struct sysfs_ops const *sysfs_ops ;
   struct attribute **default_attrs ;
   struct kobj_ns_type_operations const *(*child_ns_type)(struct kobject *) ;
   void const *(*namespace)(struct kobject *) ;
   void (*get_ownership)(struct kobject *, kuid_t *, kgid_t *) ;
};


struct kobj_uevent_env {
   char *argv[3U] ;
   char *envp[32U] ;
   int envp_idx ;
   char buf[2048U] ;
   int buflen ;
};


struct kset_uevent_ops {
   int (* const filter)(struct kset *, struct kobject *) ;
   char const *(* const name)(struct kset *, struct kobject *) ;
   int (* const uevent)(struct kset *, struct kobject *, struct kobj_uevent_env *) ;
};


struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops const *uevent_ops ;
};


struct pm_message {
   int event ;
};


typedef struct pm_message pm_message_t;


struct dev_pm_ops {
   int (*prepare)(struct device *) ;
   void (*complete)(struct device *) ;
   int (*suspend)(struct device *) ;
   int (*resume)(struct device *) ;
   int (*freeze)(struct device *) ;
   int (*thaw)(struct device *) ;
   int (*poweroff)(struct device *) ;
   int (*restore)(struct device *) ;
   int (*suspend_late)(struct device *) ;
   int (*resume_early)(struct device *) ;
   int (*freeze_late)(struct device *) ;
   int (*thaw_early)(struct device *) ;
   int (*poweroff_late)(struct device *) ;
   int (*restore_early)(struct device *) ;
   int (*suspend_noirq)(struct device *) ;
   int (*resume_noirq)(struct device *) ;
   int (*freeze_noirq)(struct device *) ;
   int (*thaw_noirq)(struct device *) ;
   int (*poweroff_noirq)(struct device *) ;
   int (*restore_noirq)(struct device *) ;
   int (*runtime_suspend)(struct device *) ;
   int (*runtime_resume)(struct device *) ;
   int (*runtime_idle)(struct device *) ;
};


enum rpm_status {
    RPM_ACTIVE = 0,
    RPM_RESUMING = 1,
    RPM_SUSPENDED = 2,
    RPM_SUSPENDING = 3
};


enum rpm_request {
    RPM_REQ_NONE = 0,
    RPM_REQ_IDLE = 1,
    RPM_REQ_SUSPEND = 2,
    RPM_REQ_AUTOSUSPEND = 3,
    RPM_REQ_RESUME = 4
};


struct wakeup_source;


struct wake_irq;


struct pm_domain_data;


struct pm_subsys_data {
   spinlock_t lock ;
   unsigned int refcount ;
   struct list_head clock_list ;
   struct pm_domain_data *domain_data ;
};


struct dev_pm_qos;


struct dev_pm_info {
   pm_message_t power_state ;
   unsigned int can_wakeup : 1 ;
   unsigned int async_suspend : 1 ;
   bool in_dpm_list : 1 ;
   bool is_prepared : 1 ;
   bool is_suspended : 1 ;
   bool is_noirq_suspended : 1 ;
   bool is_late_suspended : 1 ;
   bool no_pm : 1 ;
   bool early_init : 1 ;
   bool direct_complete : 1 ;
   u32 driver_flags ;
   spinlock_t lock ;
   struct list_head entry ;
   struct completion completion ;
   struct wakeup_source *wakeup ;
   bool wakeup_path : 1 ;
   bool syscore : 1 ;
   bool no_pm_callbacks : 1 ;
   unsigned int must_resume : 1 ;
   unsigned int may_skip_resume : 1 ;
   struct hrtimer suspend_timer ;
   unsigned long timer_expires ;
   struct work_struct work ;
   wait_queue_head_t wait_queue ;
   struct wake_irq *wakeirq ;
   atomic_t usage_count ;
   atomic_t child_count ;
   unsigned int disable_depth : 3 ;
   unsigned int idle_notification : 1 ;
   unsigned int request_pending : 1 ;
   unsigned int deferred_resume : 1 ;
   unsigned int runtime_auto : 1 ;
   bool ignore_children : 1 ;
   unsigned int no_callbacks : 1 ;
   unsigned int irq_safe : 1 ;
   unsigned int use_autosuspend : 1 ;
   unsigned int timer_autosuspends : 1 ;
   unsigned int memalloc_noio : 1 ;
   unsigned int links_count ;
   enum rpm_request request ;
   enum rpm_status runtime_status ;
   int runtime_error ;
   int autosuspend_delay ;
   u64 last_busy ;
   u64 active_time ;
   u64 suspended_time ;
   u64 accounting_timestamp ;
   struct pm_subsys_data *subsys_data ;
   void (*set_latency_tolerance)(struct device *, s32 ) ;
   struct dev_pm_qos *qos ;
};


struct dev_pm_domain {
   struct dev_pm_ops ops ;
   void (*detach)(struct device *, bool ) ;
   int (*activate)(struct device *) ;
   void (*sync)(struct device *) ;
   void (*dismiss)(struct device *) ;
};


struct dev_archdata {
   void *iommu ;
};


struct dma_map_ops;


struct pdev_archdata {
   
};


struct device_driver;


struct driver_private;


struct class;


struct subsys_private;


struct bus_type;


struct device_node;


struct iommu_ops;


struct iommu_group;


struct iommu_fwspec;


struct dev_pin_info;


struct bus_type {
   char const *name ;
   char const *dev_name ;
   struct device *dev_root ;
   struct attribute_group const **bus_groups ;
   struct attribute_group const **dev_groups ;
   struct attribute_group const **drv_groups ;
   int (*match)(struct device *, struct device_driver *) ;
   int (*uevent)(struct device *, struct kobj_uevent_env *) ;
   int (*probe)(struct device *) ;
   int (*remove)(struct device *) ;
   void (*shutdown)(struct device *) ;
   int (*online)(struct device *) ;
   int (*offline)(struct device *) ;
   int (*suspend)(struct device *, pm_message_t ) ;
   int (*resume)(struct device *) ;
   int (*num_vf)(struct device *) ;
   int (*dma_configure)(struct device *) ;
   struct dev_pm_ops const *pm ;
   struct iommu_ops const *iommu_ops ;
   struct subsys_private *p ;
   struct lock_class_key lock_key ;
   bool need_parent_lock ;
};


struct device_type;


enum probe_type {
    PROBE_DEFAULT_STRATEGY = 0,
    PROBE_PREFER_ASYNCHRONOUS = 1,
    PROBE_FORCE_SYNCHRONOUS = 2
};


struct of_device_id;


struct acpi_device_id;


struct device_driver {
   char const *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const *mod_name ;
   bool suppress_bind_attrs ;
   enum probe_type probe_type ;
   struct of_device_id const *of_match_table ;
   struct acpi_device_id const *acpi_match_table ;
   int (*probe)(struct device *) ;
   int (*remove)(struct device *) ;
   void (*shutdown)(struct device *) ;
   int (*suspend)(struct device *, pm_message_t ) ;
   int (*resume)(struct device *) ;
   struct attribute_group const **groups ;
   struct dev_pm_ops const *pm ;
   void (*coredump)(struct device *) ;
   struct driver_private *p ;
};


struct class {
   char const *name ;
   struct module *owner ;
   struct attribute_group const **class_groups ;
   struct attribute_group const **dev_groups ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device *, struct kobj_uevent_env *) ;
   char *(*devnode)(struct device *, umode_t *) ;
   void (*class_release)(struct class *) ;
   void (*dev_release)(struct device *) ;
   int (*shutdown_pre)(struct device *) ;
   struct kobj_ns_type_operations const *ns_type ;
   void const *(*namespace)(struct device *) ;
   void (*get_ownership)(struct device *, kuid_t *, kgid_t *) ;
   struct dev_pm_ops const *pm ;
   struct subsys_private *p ;
};


struct device_type {
   char const *name ;
   struct attribute_group const **groups ;
   int (*uevent)(struct device *, struct kobj_uevent_env *) ;
   char *(*devnode)(struct device *, umode_t *, kuid_t *, kgid_t *) ;
   void (*release)(struct device *) ;
   struct dev_pm_ops const *pm ;
};


struct device_dma_parameters {
   unsigned int max_segment_size ;
   unsigned long segment_boundary_mask ;
};


enum dl_dev_state {
    DL_DEV_NO_DRIVER = 0,
    DL_DEV_PROBING = 1,
    DL_DEV_DRIVER_BOUND = 2,
    DL_DEV_UNBINDING = 3
};


struct dev_links_info {
   struct list_head suppliers ;
   struct list_head consumers ;
   enum dl_dev_state status ;
};


struct dma_coherent_mem;


struct cma;


struct device {
   struct device *parent ;
   struct device_private *p ;
   struct kobject kobj ;
   char const *init_name ;
   struct device_type const *type ;
   struct mutex mutex ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *platform_data ;
   void *driver_data ;
   struct dev_links_info links ;
   struct dev_pm_info power ;
   struct dev_pm_domain *pm_domain ;
   struct irq_domain *msi_domain ;
   struct dev_pin_info *pins ;
   struct list_head msi_list ;
   int numa_node ;
   struct dma_map_ops const *dma_ops ;
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   u64 bus_dma_mask ;
   unsigned long dma_pfn_offset ;
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct cma *cma_area ;
   struct dev_archdata archdata ;
   struct device_node *of_node ;
   struct fwnode_handle *fwnode ;
   dev_t devt ;
   u32 id ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct class *class ;
   struct attribute_group const **groups ;
   void (*release)(struct device *) ;
   struct iommu_group *iommu_group ;
   struct iommu_fwspec *iommu_fwspec ;
   bool offline_disabled : 1 ;
   bool offline : 1 ;
   bool of_node_reused : 1 ;
};


struct wakeup_source {
   char const *name ;
   struct list_head entry ;
   spinlock_t lock ;
   struct wake_irq *wakeirq ;
   struct timer_list timer ;
   unsigned long timer_expires ;
   ktime_t total_time ;
   ktime_t max_time ;
   ktime_t last_time ;
   ktime_t start_prevent_time ;
   ktime_t prevent_sleep_time ;
   unsigned long event_count ;
   unsigned long active_count ;
   unsigned long relax_count ;
   unsigned long expire_count ;
   unsigned long wakeup_count ;
   bool active : 1 ;
   bool autosleep_enabled : 1 ;
};


struct vfsmount;


struct path;


struct percpu_ref;


typedef void percpu_ref_func_t(struct percpu_ref *);


struct percpu_ref {
   atomic_long_t count ;
   unsigned long percpu_count_ptr ;
   percpu_ref_func_t *release ;
   percpu_ref_func_t *confirm_switch ;
   bool force_atomic : 1 ;
   struct callback_head rcu ;
};


struct shrink_control {
   gfp_t gfp_mask ;
   int nid ;
   unsigned long nr_to_scan ;
   unsigned long nr_scanned ;
   struct mem_cgroup *memcg ;
};


struct shrinker {
   unsigned long (*count_objects)(struct shrinker *, struct shrink_control *) ;
   unsigned long (*scan_objects)(struct shrinker *, struct shrink_control *) ;
   long batch ;
   int seeks ;
   unsigned int flags ;
   struct list_head list ;
   int id ;
   atomic_long_t *nr_deferred ;
};


struct vmem_altmap {
   unsigned long const base_pfn ;
   unsigned long const reserve ;
   unsigned long free ;
   unsigned long align ;
   unsigned long alloc ;
};


enum memory_type {
    MEMORY_DEVICE_PRIVATE = 1,
    MEMORY_DEVICE_PUBLIC = 2,
    MEMORY_DEVICE_FS_DAX = 3,
    MEMORY_DEVICE_PCI_P2PDMA = 4
};


struct dev_pagemap {
   void (*page_free)(struct page *, void *) ;
   struct vmem_altmap altmap ;
   bool altmap_valid ;
   struct resource res ;
   struct percpu_ref *ref ;
   void (*kill)(struct percpu_ref *) ;
   struct device *dev ;
   void *data ;
   enum memory_type type ;
   u64 pci_p2pdma_bus_offset ;
};


struct file_ra_state;


struct writeback_control;


struct bdi_writeback;


struct vm_fault {
   struct vm_area_struct *vma ;
   unsigned int flags ;
   gfp_t gfp_mask ;
   unsigned long pgoff ;
   unsigned long address ;
   pmd_t *pmd ;
   pud_t *pud ;
   pte_t orig_pte ;
   struct page *cow_page ;
   struct mem_cgroup *memcg ;
   struct page *page ;
   pte_t *pte ;
   spinlock_t *ptl ;
   pgtable_t prealloc_pte ;
};


enum page_entry_size {
    PE_SIZE_PTE = 0,
    PE_SIZE_PMD = 1,
    PE_SIZE_PUD = 2
};


struct vm_operations_struct {
   void (*open)(struct vm_area_struct *) ;
   void (*close)(struct vm_area_struct *) ;
   int (*split)(struct vm_area_struct *, unsigned long ) ;
   int (*mremap)(struct vm_area_struct *) ;
   vm_fault_t (*fault)(struct vm_fault *) ;
   vm_fault_t (*huge_fault)(struct vm_fault *, enum page_entry_size ) ;
   void (*map_pages)(struct vm_fault *, unsigned long , unsigned long ) ;
   unsigned long (*pagesize)(struct vm_area_struct *) ;
   vm_fault_t (*page_mkwrite)(struct vm_fault *) ;
   vm_fault_t (*pfn_mkwrite)(struct vm_fault *) ;
   int (*access)(struct vm_area_struct *, unsigned long , void *, int , int ) ;
   char const *(*name)(struct vm_area_struct *) ;
   int (*set_policy)(struct vm_area_struct *, struct mempolicy *) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct *, unsigned long ) ;
   struct page *(*find_special_page)(struct vm_area_struct *, unsigned long ) ;
};


struct hlist_bl_node;


struct hlist_bl_head {
   struct hlist_bl_node *first ;
};


struct hlist_bl_node {
   struct hlist_bl_node *next ;
   struct hlist_bl_node **pprev ;
};


struct __anonstruct_404 {
   spinlock_t lock ;
   int count ;
};


union __anonunion_403 {
   struct __anonstruct_404 __anonCompField___anonunion_403_58 ;
};


struct lockref {
   union __anonunion_403 __anonCompField_lockref_59 ;
};


struct __anonstruct_406 {
   u32 hash ;
   u32 len ;
};


union __anonunion_405 {
   struct __anonstruct_406 __anonCompField___anonunion_405_60 ;
   u64 hash_len ;
};


struct qstr {
   union __anonunion_405 __anonCompField_qstr_61 ;
   unsigned char const *name ;
};


struct dentry_operations;


union __anonunion_407 {
   struct list_head d_lru ;
   wait_queue_head_t *d_wait ;
};


union __anonunion_d_u_408 {
   struct hlist_node d_alias ;
   struct hlist_bl_node d_in_lookup_hash ;
   struct callback_head d_rcu ;
};


struct dentry {
   unsigned int d_flags ;
   seqcount_t d_seq ;
   struct hlist_bl_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct inode *d_inode ;
   unsigned char d_iname[32U] ;
   struct lockref d_lockref ;
   struct dentry_operations const *d_op ;
   struct super_block *d_sb ;
   unsigned long d_time ;
   void *d_fsdata ;
   union __anonunion_407 __anonCompField_dentry_62 ;
   struct list_head d_child ;
   struct list_head d_subdirs ;
   union __anonunion_d_u_408 d_u ;
};


struct dentry_operations {
   int (*d_revalidate)(struct dentry *, unsigned int ) ;
   int (*d_weak_revalidate)(struct dentry *, unsigned int ) ;
   int (*d_hash)(struct dentry const *, struct qstr *) ;
   int (*d_compare)(struct dentry const *, unsigned int , char const *, struct qstr const *) ;
   int (*d_delete)(struct dentry const *) ;
   int (*d_init)(struct dentry *) ;
   void (*d_release)(struct dentry *) ;
   void (*d_prune)(struct dentry *) ;
   void (*d_iput)(struct dentry *, struct inode *) ;
   char *(*d_dname)(struct dentry *, char *, int ) ;
   struct vfsmount *(*d_automount)(struct path *) ;
   int (*d_manage)(struct path const *, bool ) ;
   struct dentry *(*d_real)(struct dentry *, struct inode const *) ;
};


struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};


struct list_lru_one {
   struct list_head list ;
   long nr_items ;
};


struct list_lru_memcg {
   struct callback_head rcu ;
   struct list_lru_one *lru[0U] ;
};


struct list_lru_node {
   spinlock_t lock ;
   struct list_lru_one lru ;
   struct list_lru_memcg *memcg_lrus ;
   long nr_items ;
};


struct list_lru {
   struct list_lru_node *node ;
   struct list_head list ;
   int shrinker_id ;
};


struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};


enum migrate_mode {
    MIGRATE_ASYNC = 0,
    MIGRATE_SYNC_LIGHT = 1,
    MIGRATE_SYNC = 2,
    MIGRATE_SYNC_NO_COPY = 3
};


struct rcuwait {
   struct task_struct *task ;
};


enum rcu_sync_type {
    RCU_SYNC = 0,
    RCU_SCHED_SYNC = 1,
    RCU_BH_SYNC = 2
};


struct rcu_sync {
   int gp_state ;
   int gp_count ;
   wait_queue_head_t gp_wait ;
   int cb_state ;
   struct callback_head cb_head ;
   enum rcu_sync_type gp_type ;
};


struct percpu_rw_semaphore {
   struct rcu_sync rss ;
   unsigned int *read_count ;
   struct rw_semaphore rw_sem ;
   struct rcuwait writer ;
   int readers_block ;
};


struct delayed_call {
   void (*fn)(void *) ;
   void *arg ;
};


struct __anonstruct_uuid_t_414 {
   __u8 b[16U] ;
};


typedef struct __anonstruct_uuid_t_414 uuid_t;


typedef u32 errseq_t;


union __anonunion_415 {
   struct list_head q_node ;
   struct kmem_cache *__rcu_icq_cache ;
};


union __anonunion_416 {
   struct hlist_node ioc_node ;
   struct callback_head __rcu_head ;
};


struct io_cq {
   struct request_queue *q ;
   struct io_context *ioc ;
   union __anonunion_415 __anonCompField_io_cq_63 ;
   union __anonunion_416 __anonCompField_io_cq_64 ;
   unsigned int flags ;
};


struct io_context {
   atomic_long_t refcount ;
   atomic_t active_ref ;
   atomic_t nr_tasks ;
   spinlock_t lock ;
   unsigned short ioprio ;
   int nr_batch_requests ;
   unsigned long last_waited ;
   struct xarray icq_tree ;
   struct io_cq *icq_hint ;
   struct hlist_head icq_list ;
   struct work_struct release_work ;
};


struct export_operations;


struct kiocb;


struct kstatfs;


struct swap_info_struct;


struct iov_iter;


struct fscrypt_info;


struct fscrypt_operations;


struct fs_parameter_description;


struct iattr {
   unsigned int ia_valid ;
   umode_t ia_mode ;
   kuid_t ia_uid ;
   kgid_t ia_gid ;
   loff_t ia_size ;
   struct timespec64 ia_atime ;
   struct timespec64 ia_mtime ;
   struct timespec64 ia_ctime ;
   struct file *ia_file ;
};


struct dquot;


struct kqid;


typedef __kernel_uid32_t projid_t;


struct __anonstruct_kprojid_t_417 {
   projid_t val ;
};


typedef struct __anonstruct_kprojid_t_417 kprojid_t;


enum quota_type {
    USRQUOTA = 0,
    GRPQUOTA = 1,
    PRJQUOTA = 2
};


typedef long long qsize_t;


union __anonunion_418 {
   kuid_t uid ;
   kgid_t gid ;
   kprojid_t projid ;
};


struct kqid {
   union __anonunion_418 __anonCompField_kqid_65 ;
   enum quota_type type ;
};


struct mem_dqblk {
   qsize_t dqb_bhardlimit ;
   qsize_t dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   qsize_t dqb_rsvspace ;
   qsize_t dqb_ihardlimit ;
   qsize_t dqb_isoftlimit ;
   qsize_t dqb_curinodes ;
   time64_t dqb_btime ;
   time64_t dqb_itime ;
};


struct quota_format_type;


struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
   unsigned int dqi_bgrace ;
   unsigned int dqi_igrace ;
   qsize_t dqi_max_spc_limit ;
   qsize_t dqi_max_ino_limit ;
   void *dqi_priv ;
};


struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   spinlock_t dq_dqb_lock ;
   atomic_t dq_count ;
   struct super_block *dq_sb ;
   struct kqid dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
   struct mem_dqblk dq_dqb ;
};


struct quota_format_ops {
   int (*check_quota_file)(struct super_block *, int ) ;
   int (*read_file_info)(struct super_block *, int ) ;
   int (*write_file_info)(struct super_block *, int ) ;
   int (*free_file_info)(struct super_block *, int ) ;
   int (*read_dqblk)(struct dquot *) ;
   int (*commit_dqblk)(struct dquot *) ;
   int (*release_dqblk)(struct dquot *) ;
   int (*get_next_id)(struct super_block *, struct kqid *) ;
};


struct dquot_operations {
   int (*write_dquot)(struct dquot *) ;
   struct dquot *(*alloc_dquot)(struct super_block *, int ) ;
   void (*destroy_dquot)(struct dquot *) ;
   int (*acquire_dquot)(struct dquot *) ;
   int (*release_dquot)(struct dquot *) ;
   int (*mark_dirty)(struct dquot *) ;
   int (*write_info)(struct super_block *, int ) ;
   qsize_t *(*get_reserved_space)(struct inode *) ;
   int (*get_projid)(struct inode *, kprojid_t *) ;
   int (*get_inode_usage)(struct inode *, qsize_t *) ;
   int (*get_next_id)(struct super_block *, struct kqid *) ;
};


struct qc_dqblk {
   int d_fieldmask ;
   u64 d_spc_hardlimit ;
   u64 d_spc_softlimit ;
   u64 d_ino_hardlimit ;
   u64 d_ino_softlimit ;
   u64 d_space ;
   u64 d_ino_count ;
   s64 d_ino_timer ;
   s64 d_spc_timer ;
   int d_ino_warns ;
   int d_spc_warns ;
   u64 d_rt_spc_hardlimit ;
   u64 d_rt_spc_softlimit ;
   u64 d_rt_space ;
   s64 d_rt_spc_timer ;
   int d_rt_spc_warns ;
};


struct qc_type_state {
   unsigned int flags ;
   unsigned int spc_timelimit ;
   unsigned int ino_timelimit ;
   unsigned int rt_spc_timelimit ;
   unsigned int spc_warnlimit ;
   unsigned int ino_warnlimit ;
   unsigned int rt_spc_warnlimit ;
   unsigned long long ino ;
   blkcnt_t blocks ;
   blkcnt_t nextents ;
};


struct qc_state {
   unsigned int s_incoredqs ;
   struct qc_type_state s_state[3U] ;
};


struct qc_info {
   int i_fieldmask ;
   unsigned int i_flags ;
   unsigned int i_spc_timelimit ;
   unsigned int i_ino_timelimit ;
   unsigned int i_rt_spc_timelimit ;
   unsigned int i_spc_warnlimit ;
   unsigned int i_ino_warnlimit ;
   unsigned int i_rt_spc_warnlimit ;
};


struct quotactl_ops {
   int (*quota_on)(struct super_block *, int , int , struct path const *) ;
   int (*quota_off)(struct super_block *, int ) ;
   int (*quota_enable)(struct super_block *, unsigned int ) ;
   int (*quota_disable)(struct super_block *, unsigned int ) ;
   int (*quota_sync)(struct super_block *, int ) ;
   int (*set_info)(struct super_block *, int , struct qc_info *) ;
   int (*get_dqblk)(struct super_block *, struct kqid , struct qc_dqblk *) ;
   int (*get_nextdqblk)(struct super_block *, struct kqid *, struct qc_dqblk *) ;
   int (*set_dqblk)(struct super_block *, struct kqid , struct qc_dqblk *) ;
   int (*get_state)(struct super_block *, struct qc_state *) ;
   int (*rm_xquota)(struct super_block *, unsigned int ) ;
};


struct quota_format_type {
   int qf_fmt_id ;
   struct quota_format_ops const *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};


struct quota_info {
   unsigned int flags ;
   struct rw_semaphore dqio_sem ;
   struct inode *files[3U] ;
   struct mem_dqinfo info[3U] ;
   struct quota_format_ops const *ops[3U] ;
};


enum rw_hint {
    WRITE_LIFE_NOT_SET = 0,
    WRITE_LIFE_NONE = 1,
    WRITE_LIFE_SHORT = 2,
    WRITE_LIFE_MEDIUM = 3,
    WRITE_LIFE_LONG = 4,
    WRITE_LIFE_EXTREME = 5
};


struct kiocb {
   struct file *ki_filp ;
   loff_t ki_pos ;
   void (*ki_complete)(struct kiocb *, long , long ) ;
   void *private ;
   int ki_flags ;
   u16 ki_hint ;
   u16 ki_ioprio ;
   unsigned int ki_cookie ;
};


struct address_space_operations {
   int (*writepage)(struct page *, struct writeback_control *) ;
   int (*readpage)(struct file *, struct page *) ;
   int (*writepages)(struct address_space *, struct writeback_control *) ;
   int (*set_page_dirty)(struct page *) ;
   int (*readpages)(struct file *, struct address_space *, struct list_head *, unsigned int ) ;
   int (*write_begin)(struct file *, struct address_space *, loff_t , unsigned int , unsigned int , struct page **, void **) ;
   int (*write_end)(struct file *, struct address_space *, loff_t , unsigned int , unsigned int , struct page *, void *) ;
   sector_t (*bmap)(struct address_space *, sector_t ) ;
   void (*invalidatepage)(struct page *, unsigned int , unsigned int ) ;
   int (*releasepage)(struct page *, gfp_t ) ;
   void (*freepage)(struct page *) ;
   ssize_t (*direct_IO)(struct kiocb *, struct iov_iter *) ;
   int (*migratepage)(struct address_space *, struct page *, struct page *, enum migrate_mode ) ;
   bool (*isolate_page)(struct page *, isolate_mode_t ) ;
   void (*putback_page)(struct page *) ;
   int (*launder_page)(struct page *) ;
   int (*is_partially_uptodate)(struct page *, unsigned long , unsigned long ) ;
   void (*is_dirty_writeback)(struct page *, bool *, bool *) ;
   int (*error_remove_page)(struct address_space *, struct page *) ;
   int (*swap_activate)(struct swap_info_struct *, struct file *, sector_t *) ;
   void (*swap_deactivate)(struct file *) ;
};


struct address_space {
   struct inode *host ;
   struct xarray i_pages ;
   gfp_t gfp_mask ;
   atomic_t i_mmap_writable ;
   struct rb_root_cached i_mmap ;
   struct rw_semaphore i_mmap_rwsem ;
   unsigned long nrpages ;
   unsigned long nrexceptional ;
   unsigned long writeback_index ;
   struct address_space_operations const *a_ops ;
   unsigned long flags ;
   errseq_t wb_err ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   void *private_data ;
};


struct hd_struct;


struct gendisk;


struct block_device {
   dev_t bd_dev ;
   int bd_openers ;
   struct inode *bd_inode ;
   struct super_block *bd_super ;
   struct mutex bd_mutex ;
   void *bd_claiming ;
   void *bd_holder ;
   int bd_holders ;
   bool bd_write_holder ;
   struct list_head bd_holder_disks ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
   u8 bd_partno ;
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
   int bd_invalidated ;
   struct gendisk *bd_disk ;
   struct request_queue *bd_queue ;
   struct backing_dev_info *bd_bdi ;
   struct list_head bd_list ;
   unsigned long bd_private ;
   int bd_fsfreeze_count ;
   struct mutex bd_fsfreeze_mutex ;
};


struct posix_acl;


struct fsnotify_mark_connector;


struct inode_operations;


union __anonunion_423 {
   unsigned int const i_nlink ;
   unsigned int __i_nlink ;
};


union __anonunion_424 {
   struct hlist_head i_dentry ;
   struct callback_head i_rcu ;
};


struct file_lock_context;


struct cdev;


union __anonunion_425 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
   char *i_link ;
   unsigned int i_dir_seq ;
};


struct inode {
   umode_t i_mode ;
   unsigned short i_opflags ;
   kuid_t i_uid ;
   kgid_t i_gid ;
   unsigned int i_flags ;
   struct posix_acl *i_acl ;
   struct posix_acl *i_default_acl ;
   struct inode_operations const *i_op ;
   struct super_block *i_sb ;
   struct address_space *i_mapping ;
   void *i_security ;
   unsigned long i_ino ;
   union __anonunion_423 __anonCompField_inode_66 ;
   dev_t i_rdev ;
   loff_t i_size ;
   struct timespec64 i_atime ;
   struct timespec64 i_mtime ;
   struct timespec64 i_ctime ;
   spinlock_t i_lock ;
   unsigned short i_bytes ;
   u8 i_blkbits ;
   u8 i_write_hint ;
   blkcnt_t i_blocks ;
   unsigned long i_state ;
   struct rw_semaphore i_rwsem ;
   unsigned long dirtied_when ;
   unsigned long dirtied_time_when ;
   struct hlist_node i_hash ;
   struct list_head i_io_list ;
   struct bdi_writeback *i_wb ;
   int i_wb_frn_winner ;
   u16 i_wb_frn_avg_time ;
   u16 i_wb_frn_history ;
   struct list_head i_lru ;
   struct list_head i_sb_list ;
   struct list_head i_wb_list ;
   union __anonunion_424 __anonCompField_inode_67 ;
   atomic64_t i_version ;
   atomic_t i_count ;
   atomic_t i_dio_count ;
   atomic_t i_writecount ;
   atomic_t i_readcount ;
   struct file_operations const *i_fop ;
   struct file_lock_context *i_flctx ;
   struct address_space i_data ;
   struct list_head i_devices ;
   union __anonunion_425 __anonCompField_inode_68 ;
   __u32 i_generation ;
   __u32 i_fsnotify_mask ;
   struct fsnotify_mark_connector *i_fsnotify_marks ;
   struct fscrypt_info *i_crypt_info ;
   void *i_private ;
};


struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   kuid_t uid ;
   kuid_t euid ;
   int signum ;
};


struct file_ra_state {
   unsigned long start ;
   unsigned int size ;
   unsigned int async_size ;
   unsigned int ra_pages ;
   unsigned int mmap_miss ;
   loff_t prev_pos ;
};


union __anonunion_f_u_426 {
   struct llist_node fu_llist ;
   struct callback_head fu_rcuhead ;
};


struct file {
   union __anonunion_f_u_426 f_u ;
   struct path f_path ;
   struct inode *f_inode ;
   struct file_operations const *f_op ;
   spinlock_t f_lock ;
   enum rw_hint f_write_hint ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
   fmode_t f_mode ;
   struct mutex f_pos_lock ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   struct cred const *f_cred ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   struct list_head f_tfile_llink ;
   struct address_space *f_mapping ;
   errseq_t f_wb_err ;
};


typedef void *fl_owner_t;


struct file_lock;


struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock *, struct file_lock *) ;
   void (*fl_release_private)(struct file_lock *) ;
};


struct lock_manager_operations {
   int (*lm_compare_owner)(struct file_lock *, struct file_lock *) ;
   unsigned long (*lm_owner_key)(struct file_lock *) ;
   fl_owner_t (*lm_get_owner)(fl_owner_t ) ;
   void (*lm_put_owner)(fl_owner_t ) ;
   void (*lm_notify)(struct file_lock *) ;
   int (*lm_grant)(struct file_lock *, int ) ;
   bool (*lm_break)(struct file_lock *) ;
   int (*lm_change)(struct file_lock *, int , struct list_head *) ;
   void (*lm_setup)(struct file_lock *, void **) ;
};


struct nlm_lockowner;


struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};


struct nfs4_lock_state;


struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};


struct fasync_struct;


struct __anonstruct_afs_428 {
   struct list_head link ;
   int state ;
};


union __anonunion_fl_u_427 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_428 afs ;
};


struct file_lock {
   struct file_lock *fl_blocker ;
   struct list_head fl_list ;
   struct hlist_node fl_link ;
   struct list_head fl_blocked_requests ;
   struct list_head fl_blocked_member ;
   fl_owner_t fl_owner ;
   unsigned int fl_flags ;
   unsigned char fl_type ;
   unsigned int fl_pid ;
   int fl_link_cpu ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
   unsigned long fl_downgrade_time ;
   struct file_lock_operations const *fl_ops ;
   struct lock_manager_operations const *fl_lmops ;
   union __anonunion_fl_u_427 fl_u ;
};


struct file_lock_context {
   spinlock_t flc_lock ;
   struct list_head flc_flock ;
   struct list_head flc_posix ;
   struct list_head flc_lease ;
};


struct fasync_struct {
   rwlock_t fa_lock ;
   int magic ;
   int fa_fd ;
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
   struct callback_head fa_rcu ;
};


struct sb_writers {
   int frozen ;
   wait_queue_head_t wait_unfrozen ;
   struct percpu_rw_semaphore rw_sem[3U] ;
};


struct super_operations;


struct xattr_handler;


struct mtd_info;


struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned char s_blocksize_bits ;
   unsigned long s_blocksize ;
   loff_t s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations const *s_op ;
   struct dquot_operations const *dq_op ;
   struct quotactl_ops const *s_qcop ;
   struct export_operations const *s_export_op ;
   unsigned long s_flags ;
   unsigned long s_iflags ;
   unsigned long s_magic ;
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   int s_count ;
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler const **s_xattr ;
   struct fscrypt_operations const *s_cop ;
   struct hlist_bl_head s_roots ;
   struct list_head s_mounts ;
   struct block_device *s_bdev ;
   struct backing_dev_info *s_bdi ;
   struct mtd_info *s_mtd ;
   struct hlist_node s_instances ;
   unsigned int s_quota_types ;
   struct quota_info s_dquot ;
   struct sb_writers s_writers ;
   void *s_fs_info ;
   u32 s_time_gran ;
   __u32 s_fsnotify_mask ;
   struct fsnotify_mark_connector *s_fsnotify_marks ;
   char s_id[32U] ;
   uuid_t s_uuid ;
   unsigned int s_max_links ;
   fmode_t s_mode ;
   struct mutex s_vfs_rename_mutex ;
   char const *s_subtype ;
   struct dentry_operations const *s_d_op ;
   int cleancache_poolid ;
   struct shrinker s_shrink ;
   atomic_long_t s_remove_count ;
   atomic_long_t s_fsnotify_inode_refs ;
   int s_readonly_remount ;
   struct workqueue_struct *s_dio_done_wq ;
   struct hlist_head s_pins ;
   struct user_namespace *s_user_ns ;
   struct list_lru s_dentry_lru ;
   struct list_lru s_inode_lru ;
   struct callback_head rcu ;
   struct work_struct destroy_work ;
   struct mutex s_sync_lock ;
   int s_stack_depth ;
   spinlock_t s_inode_list_lock ;
   struct list_head s_inodes ;
   spinlock_t s_inode_wblist_lock ;
   struct list_head s_inodes_wb ;
};


struct fiemap_extent_info {
   unsigned int fi_flags ;
   unsigned int fi_extents_mapped ;
   unsigned int fi_extents_max ;
   struct fiemap_extent *fi_extents_start ;
};


struct dir_context;


struct dir_context {
   int (*actor)(struct dir_context *, char const *, int , loff_t , u64 , unsigned int ) ;
   loff_t pos ;
};


struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file *, loff_t , int ) ;
   ssize_t (*read)(struct file *, char *, size_t , loff_t *) ;
   ssize_t (*write)(struct file *, char const *, size_t , loff_t *) ;
   ssize_t (*read_iter)(struct kiocb *, struct iov_iter *) ;
   ssize_t (*write_iter)(struct kiocb *, struct iov_iter *) ;
   int (*iopoll)(struct kiocb *, bool ) ;
   int (*iterate)(struct file *, struct dir_context *) ;
   int (*iterate_shared)(struct file *, struct dir_context *) ;
   __poll_t (*poll)(struct file *, struct poll_table_struct *) ;
   long (*unlocked_ioctl)(struct file *, unsigned int , unsigned long ) ;
   long (*compat_ioctl)(struct file *, unsigned int , unsigned long ) ;
   int (*mmap)(struct file *, struct vm_area_struct *) ;
   unsigned long mmap_supported_flags ;
   int (*open)(struct inode *, struct file *) ;
   int (*flush)(struct file *, fl_owner_t ) ;
   int (*release)(struct inode *, struct file *) ;
   int (*fsync)(struct file *, loff_t , loff_t , int ) ;
   int (*fasync)(int , struct file *, int ) ;
   int (*lock)(struct file *, int , struct file_lock *) ;
   ssize_t (*sendpage)(struct file *, struct page *, int , size_t , loff_t *, int ) ;
   unsigned long (*get_unmapped_area)(struct file *, unsigned long , unsigned long , unsigned long , unsigned long ) ;
   int (*check_flags)(int ) ;
   int (*flock)(struct file *, int , struct file_lock *) ;
   ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t , unsigned int ) ;
   ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t , unsigned int ) ;
   int (*setlease)(struct file *, long , struct file_lock **, void **) ;
   long (*fallocate)(struct file *, int , loff_t , loff_t ) ;
   void (*show_fdinfo)(struct seq_file *, struct file *) ;
   ssize_t (*copy_file_range)(struct file *, loff_t , struct file *, loff_t , size_t , unsigned int ) ;
   loff_t (*remap_file_range)(struct file *, loff_t , struct file *, loff_t , loff_t , unsigned int ) ;
   int (*fadvise)(struct file *, loff_t , loff_t , int ) ;
};


struct inode_operations {
   struct dentry *(*lookup)(struct inode *, struct dentry *, unsigned int ) ;
   char const *(*get_link)(struct dentry *, struct inode *, struct delayed_call *) ;
   int (*permission)(struct inode *, int ) ;
   struct posix_acl *(*get_acl)(struct inode *, int ) ;
   int (*readlink)(struct dentry *, char *, int ) ;
   int (*create)(struct inode *, struct dentry *, umode_t , bool ) ;
   int (*link)(struct dentry *, struct inode *, struct dentry *) ;
   int (*unlink)(struct inode *, struct dentry *) ;
   int (*symlink)(struct inode *, struct dentry *, char const *) ;
   int (*mkdir)(struct inode *, struct dentry *, umode_t ) ;
   int (*rmdir)(struct inode *, struct dentry *) ;
   int (*mknod)(struct inode *, struct dentry *, umode_t , dev_t ) ;
   int (*rename)(struct inode *, struct dentry *, struct inode *, struct dentry *, unsigned int ) ;
   int (*setattr)(struct dentry *, struct iattr *) ;
   int (*getattr)(struct path const *, struct kstat *, u32 , unsigned int ) ;
   ssize_t (*listxattr)(struct dentry *, char *, size_t ) ;
   int (*fiemap)(struct inode *, struct fiemap_extent_info *, u64 , u64 ) ;
   int (*update_time)(struct inode *, struct timespec64 *, int ) ;
   int (*atomic_open)(struct inode *, struct dentry *, struct file *, unsigned int , umode_t ) ;
   int (*tmpfile)(struct inode *, struct dentry *, umode_t ) ;
   int (*set_acl)(struct inode *, struct posix_acl *, int ) ;
};


struct super_operations {
   struct inode *(*alloc_inode)(struct super_block *) ;
   void (*destroy_inode)(struct inode *) ;
   void (*dirty_inode)(struct inode *, int ) ;
   int (*write_inode)(struct inode *, struct writeback_control *) ;
   int (*drop_inode)(struct inode *) ;
   void (*evict_inode)(struct inode *) ;
   void (*put_super)(struct super_block *) ;
   int (*sync_fs)(struct super_block *, int ) ;
   int (*freeze_super)(struct super_block *) ;
   int (*freeze_fs)(struct super_block *) ;
   int (*thaw_super)(struct super_block *) ;
   int (*unfreeze_fs)(struct super_block *) ;
   int (*statfs)(struct dentry *, struct kstatfs *) ;
   int (*remount_fs)(struct super_block *, int *, char *) ;
   void (*umount_begin)(struct super_block *) ;
   int (*show_options)(struct seq_file *, struct dentry *) ;
   int (*show_devname)(struct seq_file *, struct dentry *) ;
   int (*show_path)(struct seq_file *, struct dentry *) ;
   int (*show_stats)(struct seq_file *, struct dentry *) ;
   ssize_t (*quota_read)(struct super_block *, int , char *, size_t , loff_t ) ;
   ssize_t (*quota_write)(struct super_block *, int , char const *, size_t , loff_t ) ;
   struct dquot **(*get_dquots)(struct inode *) ;
   int (*bdev_try_to_free_page)(struct super_block *, struct page *, gfp_t ) ;
   long (*nr_cached_objects)(struct super_block *, struct shrink_control *) ;
   long (*free_cached_objects)(struct super_block *, struct shrink_control *) ;
};


struct file_system_type {
   char const *name ;
   int fs_flags ;
   int (*init_fs_context)(struct fs_context *) ;
   struct fs_parameter_description const *parameters ;
   struct dentry *(*mount)(struct file_system_type *, int , char const *, void *) ;
   void (*kill_sb)(struct super_block *) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct hlist_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key s_vfs_rename_key ;
   struct lock_class_key s_writers_key[3U] ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
};


struct scatterlist {
   unsigned long page_link ;
   unsigned int offset ;
   unsigned int length ;
   dma_addr_t dma_address ;
   unsigned int dma_length ;
};


struct sg_table {
   struct scatterlist *sgl ;
   unsigned int nents ;
   unsigned int orig_nents ;
};


enum dma_data_direction {
    DMA_BIDIRECTIONAL = 0,
    DMA_TO_DEVICE = 1,
    DMA_FROM_DEVICE = 2,
    DMA_NONE = 3
};


struct dma_map_ops {
   void *(*alloc)(struct device *, size_t , dma_addr_t *, gfp_t , unsigned long ) ;
   void (*free)(struct device *, size_t , void *, dma_addr_t , unsigned long ) ;
   int (*mmap)(struct device *, struct vm_area_struct *, void *, dma_addr_t , size_t , unsigned long ) ;
   int (*get_sgtable)(struct device *, struct sg_table *, void *, dma_addr_t , size_t , unsigned long ) ;
   dma_addr_t (*map_page)(struct device *, struct page *, unsigned long , size_t , enum dma_data_direction , unsigned long ) ;
   void (*unmap_page)(struct device *, dma_addr_t , size_t , enum dma_data_direction , unsigned long ) ;
   int (*map_sg)(struct device *, struct scatterlist *, int , enum dma_data_direction , unsigned long ) ;
   void (*unmap_sg)(struct device *, struct scatterlist *, int , enum dma_data_direction , unsigned long ) ;
   dma_addr_t (*map_resource)(struct device *, phys_addr_t , size_t , enum dma_data_direction , unsigned long ) ;
   void (*unmap_resource)(struct device *, dma_addr_t , size_t , enum dma_data_direction , unsigned long ) ;
   void (*sync_single_for_cpu)(struct device *, dma_addr_t , size_t , enum dma_data_direction ) ;
   void (*sync_single_for_device)(struct device *, dma_addr_t , size_t , enum dma_data_direction ) ;
   void (*sync_sg_for_cpu)(struct device *, struct scatterlist *, int , enum dma_data_direction ) ;
   void (*sync_sg_for_device)(struct device *, struct scatterlist *, int , enum dma_data_direction ) ;
   void (*cache_sync)(struct device *, void *, size_t , enum dma_data_direction ) ;
   int (*dma_supported)(struct device *, u64 ) ;
   u64 (*get_required_mask)(struct device *) ;
   size_t (*max_mapping_size)(struct device *) ;
};


struct dma_fence;


struct dma_fence_ops;


struct dma_fence_cb;


struct dma_fence {
   struct kref refcount ;
   struct dma_fence_ops const *ops ;
   struct callback_head rcu ;
   struct list_head cb_list ;
   spinlock_t *lock ;
   u64 context ;
   u64 seqno ;
   unsigned long flags ;
   ktime_t timestamp ;
   int error ;
};


struct dma_fence_cb {
   struct list_head node ;
   void (*func)(struct dma_fence *, struct dma_fence_cb *) ;
};


struct dma_fence_ops {
   char const *(*get_driver_name)(struct dma_fence *) ;
   char const *(*get_timeline_name)(struct dma_fence *) ;
   bool (*enable_signaling)(struct dma_fence *) ;
   bool (*signaled)(struct dma_fence *) ;
   long (*wait)(struct dma_fence *, bool , long ) ;
   void (*release)(struct dma_fence *) ;
   void (*fence_value_str)(struct dma_fence *, char *, int ) ;
   void (*timeline_value_str)(struct dma_fence *, char *, int ) ;
};


struct dma_buf;


struct dma_buf_attachment;


struct dma_buf_ops {
   int (*attach)(struct dma_buf *, struct dma_buf_attachment *) ;
   void (*detach)(struct dma_buf *, struct dma_buf_attachment *) ;
   struct sg_table *(*map_dma_buf)(struct dma_buf_attachment *, enum dma_data_direction ) ;
   void (*unmap_dma_buf)(struct dma_buf_attachment *, struct sg_table *, enum dma_data_direction ) ;
   void (*release)(struct dma_buf *) ;
   int (*begin_cpu_access)(struct dma_buf *, enum dma_data_direction ) ;
   int (*end_cpu_access)(struct dma_buf *, enum dma_data_direction ) ;
   void *(*map)(struct dma_buf *, unsigned long ) ;
   void (*unmap)(struct dma_buf *, unsigned long , void *) ;
   int (*mmap)(struct dma_buf *, struct vm_area_struct *) ;
   void *(*vmap)(struct dma_buf *) ;
   void (*vunmap)(struct dma_buf *, void *) ;
};


struct dma_buf_poll_cb_t {
   struct dma_fence_cb cb ;
   wait_queue_head_t *poll ;
   __poll_t active ;
};


struct reservation_object;


struct dma_buf {
   size_t size ;
   struct file *file ;
   struct list_head attachments ;
   struct dma_buf_ops const *ops ;
   struct mutex lock ;
   unsigned int vmapping_counter ;
   void *vmap_ptr ;
   char const *exp_name ;
   struct module *owner ;
   struct list_head list_node ;
   void *priv ;
   struct reservation_object *resv ;
   wait_queue_head_t poll ;
   struct dma_buf_poll_cb_t cb_excl ;
   struct dma_buf_poll_cb_t cb_shared ;
};


struct dma_buf_attachment {
   struct dma_buf *dmabuf ;
   struct device *dev ;
   struct list_head node ;
   void *priv ;
};


struct dma_buf_export_info {
   char const *exp_name ;
   struct module *owner ;
   struct dma_buf_ops const *ops ;
   size_t size ;
   int flags ;
   struct reservation_object *resv ;
   void *priv ;
};


struct miscdevice {
   int minor ;
   char const *name ;
   struct file_operations const *fops ;
   struct list_head list ;
   struct device *parent ;
   struct device *this_device ;
   struct attribute_group const **groups ;
   char const *nodename ;
   umode_t mode ;
};


struct vdso_image {
   void *data ;
   unsigned long size ;
   unsigned long alt ;
   unsigned long alt_len ;
   long sym_vvar_start ;
   long sym_vvar_page ;
   long sym_hpet_page ;
   long sym_pvclock_page ;
   long sym_hvclock_page ;
   long sym_VDSO32_NOTE_MASK ;
   long sym___kernel_sigreturn ;
   long sym___kernel_rt_sigreturn ;
   long sym___kernel_vsyscall ;
   long sym_int80_landing_pad ;
};


typedef __u64 Elf64_Addr;


typedef __u16 Elf64_Half;


typedef __u64 Elf64_Off;


typedef __u32 Elf64_Word;


typedef __u64 Elf64_Xword;


struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
   unsigned char st_other ;
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};


typedef struct elf64_sym Elf64_Sym;


struct elf64_hdr {
   unsigned char e_ident[16U] ;
   Elf64_Half e_type ;
   Elf64_Half e_machine ;
   Elf64_Word e_version ;
   Elf64_Addr e_entry ;
   Elf64_Off e_phoff ;
   Elf64_Off e_shoff ;
   Elf64_Word e_flags ;
   Elf64_Half e_ehsize ;
   Elf64_Half e_phentsize ;
   Elf64_Half e_phnum ;
   Elf64_Half e_shentsize ;
   Elf64_Half e_shnum ;
   Elf64_Half e_shstrndx ;
};


typedef struct elf64_hdr Elf64_Ehdr;


struct elf64_shdr {
   Elf64_Word sh_name ;
   Elf64_Word sh_type ;
   Elf64_Xword sh_flags ;
   Elf64_Addr sh_addr ;
   Elf64_Off sh_offset ;
   Elf64_Xword sh_size ;
   Elf64_Word sh_link ;
   Elf64_Word sh_info ;
   Elf64_Xword sh_addralign ;
   Elf64_Xword sh_entsize ;
};


typedef struct elf64_shdr Elf64_Shdr;


struct kernel_param;


struct kernel_param_ops {
   unsigned int flags ;
   int (*set)(char const *, struct kernel_param const *) ;
   int (*get)(char *, struct kernel_param const *) ;
   void (*free)(void *) ;
};


struct kparam_string;


struct kparam_array;


union __anonunion_447 {
   void *arg ;
   struct kparam_string const *str ;
   struct kparam_array const *arr ;
};


struct kernel_param {
   char const *name ;
   struct module *mod ;
   struct kernel_param_ops const *ops ;
   u16 const perm ;
   s8 level ;
   u8 flags ;
   union __anonunion_447 __anonCompField_kernel_param_69 ;
};


struct kparam_string {
   unsigned int maxlen ;
   char *string ;
};


struct kparam_array {
   unsigned int max ;
   unsigned int elemsize ;
   unsigned int *num ;
   struct kernel_param_ops const *ops ;
   void *elem ;
};


struct latch_tree_node {
   struct rb_node node[2U] ;
};


struct error_injection_entry {
   unsigned long addr ;
   int etype ;
};


struct mod_arch_specific {
   unsigned int num_orcs ;
   int *orc_unwind_ip ;
   struct orc_entry *orc_unwind ;
};


struct exception_table_entry;


struct module_param_attrs;


struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
   struct completion *kobj_completion ;
};


struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute *, struct module_kobject *, char *) ;
   ssize_t (*store)(struct module_attribute *, struct module_kobject *, char const *, size_t ) ;
   void (*setup)(struct module *, char const *) ;
   int (*test)(struct module *) ;
   void (*free)(struct module *) ;
};


enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2,
    MODULE_STATE_UNFORMED = 3
};


struct mod_tree_node {
   struct module *mod ;
   struct latch_tree_node node ;
};


struct module_layout {
   void *base ;
   unsigned int size ;
   unsigned int text_size ;
   unsigned int ro_size ;
   unsigned int ro_after_init_size ;
   struct mod_tree_node mtn ;
};


struct mod_kallsyms {
   Elf64_Sym *symtab ;
   unsigned int num_symtab ;
   char *strtab ;
};


struct klp_modinfo {
   Elf64_Ehdr hdr ;
   Elf64_Shdr *sechdrs ;
   char *secstrings ;
   unsigned int symndx ;
};


struct module_sect_attrs;


struct module_notes_attrs;


struct trace_event_call;


struct trace_eval_map;


struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const *version ;
   char const *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol const *syms ;
   s32 const *crcs ;
   unsigned int num_syms ;
   struct mutex param_lock ;
   struct kernel_param *kp ;
   unsigned int num_kp ;
   unsigned int num_gpl_syms ;
   struct kernel_symbol const *gpl_syms ;
   s32 const *gpl_crcs ;
   struct kernel_symbol const *unused_syms ;
   s32 const *unused_crcs ;
   unsigned int num_unused_syms ;
   unsigned int num_unused_gpl_syms ;
   struct kernel_symbol const *unused_gpl_syms ;
   s32 const *unused_gpl_crcs ;
   bool sig_ok ;
   bool async_probe_requested ;
   struct kernel_symbol const *gpl_future_syms ;
   s32 const *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
   unsigned int num_exentries ;
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   struct module_layout core_layout ;
   struct module_layout init_layout ;
   struct mod_arch_specific arch ;
   unsigned long taints ;
   unsigned int num_bugs ;
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   struct mod_kallsyms *kallsyms ;
   struct mod_kallsyms core_kallsyms ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   char *args ;
   void *percpu ;
   unsigned int percpu_size ;
   unsigned int num_tracepoints ;
   tracepoint_ptr_t const *tracepoints_ptrs ;
   unsigned int num_bpf_raw_events ;
   struct bpf_raw_event_map *bpf_raw_events ;
   struct jump_entry *jump_entries ;
   unsigned int num_jump_entries ;
   unsigned int num_trace_bprintk_fmt ;
   char const **trace_bprintk_fmt_start ;
   struct trace_event_call **trace_events ;
   unsigned int num_trace_events ;
   struct trace_eval_map **trace_evals ;
   unsigned int num_trace_evals ;
   unsigned int num_ftrace_callsites ;
   unsigned long *ftrace_callsites ;
   bool klp ;
   bool klp_alive ;
   struct klp_modinfo *klp_info ;
   struct list_head source_list ;
   struct list_head target_list ;
   void (*exit)(void) ;
   atomic_t refcnt ;
   ctor_fn_t *ctors ;
   unsigned int num_ctors ;
   struct error_injection_entry *ei_funcs ;
   unsigned int num_ei_funcs ;
};


typedef unsigned long kernel_ulong_t;


struct acpi_device_id {
   __u8 id[9U] ;
   kernel_ulong_t driver_data ;
   __u32 cls ;
   __u32 cls_msk ;
};


struct of_device_id {
   char name[32U] ;
   char type[32U] ;
   char compatible[128U] ;
   void const *data ;
};


struct rpmsg_device_id {
   char name[32U] ;
};


struct platform_device_id {
   char name[20U] ;
   kernel_ulong_t driver_data ;
};


typedef u32 phandle;


struct property {
   char *name ;
   int length ;
   void *value ;
   struct property *next ;
   unsigned long _flags ;
   struct bin_attribute attr ;
};


struct device_node {
   char const *name ;
   phandle phandle ;
   char const *full_name ;
   struct fwnode_handle fwnode ;
   struct property *properties ;
   struct property *deadprops ;
   struct device_node *parent ;
   struct device_node *child ;
   struct device_node *sibling ;
   struct kobject kobj ;
   unsigned long _flags ;
   void *data ;
};


struct mfd_cell;


struct platform_device {
   char const *name ;
   int id ;
   bool id_auto ;
   struct device dev ;
   u32 num_resources ;
   struct resource *resource ;
   struct platform_device_id const *id_entry ;
   char *driver_override ;
   struct mfd_cell *mfd_cell ;
   struct pdev_archdata archdata ;
};


struct platform_driver {
   int (*probe)(struct platform_device *) ;
   int (*remove)(struct platform_device *) ;
   void (*shutdown)(struct platform_device *) ;
   int (*suspend)(struct platform_device *, pm_message_t ) ;
   int (*resume)(struct platform_device *) ;
   struct device_driver driver ;
   struct platform_device_id const *id_table ;
   bool prevent_deferred_probe ;
};


struct of_dev_auxdata {
   char *compatible ;
   resource_size_t phys_addr ;
   char *name ;
   void *platform_data ;
};


struct exception_table_entry {
   int insn ;
   int fixup ;
   int handler ;
};


struct pollfd {
   int fd ;
   short events ;
   short revents ;
};


struct poll_table_struct {
   void (*_qproc)(struct file *, wait_queue_head_t *, struct poll_table_struct *) ;
   __poll_t _key ;
};


struct rpmsg_device;


struct rpmsg_endpoint;


struct rpmsg_device_ops;


struct rpmsg_endpoint_ops;


struct rpmsg_device {
   struct device dev ;
   struct rpmsg_device_id id ;
   char *driver_override ;
   u32 src ;
   u32 dst ;
   struct rpmsg_endpoint *ept ;
   bool announce ;
   struct rpmsg_device_ops const *ops ;
};


struct rpmsg_endpoint {
   struct rpmsg_device *rpdev ;
   struct kref refcount ;
   int (*cb)(struct rpmsg_device *, void *, int , void *, u32 ) ;
   struct mutex cb_lock ;
   u32 addr ;
   void *priv ;
   struct rpmsg_endpoint_ops const *ops ;
};


struct rpmsg_driver {
   struct device_driver drv ;
   struct rpmsg_device_id const *id_table ;
   int (*probe)(struct rpmsg_device *) ;
   void (*remove)(struct rpmsg_device *) ;
   int (*callback)(struct rpmsg_device *, void *, int , void *, u32 ) ;
};


struct fastrpc_invoke_args {
   __u64 ptr ;
   __u64 length ;
   __s32 fd ;
   __u32 reserved ;
};


struct fastrpc_invoke {
   __u32 handle ;
   __u32 sc ;
   __u64 args ;
};


struct fastrpc_init_create {
   __u32 filelen ;
   __s32 filefd ;
   __u32 attrs ;
   __u32 siglen ;
   __u64 file ;
};


struct fastrpc_alloc_dma_buf {
   __s32 fd ;
   __u32 flags ;
   __u64 size ;
};


struct fastrpc_phy_page {
   u64 addr ;
   u64 size ;
};


struct fastrpc_invoke_buf {
   u32 num ;
   u32 pgidx ;
};


struct fastrpc_remote_arg {
   u64 pv ;
   u64 len ;
};


struct fastrpc_msg {
   int pid ;
   int tid ;
   u64 ctx ;
   u32 handle ;
   u32 sc ;
   u64 addr ;
   u64 size ;
};


struct fastrpc_invoke_rsp {
   u64 ctx ;
   int retval ;
};


struct fastrpc_user;


struct fastrpc_buf {
   struct fastrpc_user *fl ;
   struct dma_buf *dmabuf ;
   struct device *dev ;
   void *virt ;
   u64 phys ;
   u64 size ;
   struct mutex lock ;
   struct list_head attachments ;
};


struct fastrpc_dma_buf_attachment {
   struct device *dev ;
   struct sg_table sgt ;
   struct list_head node ;
};


struct fastrpc_map {
   struct list_head node ;
   struct fastrpc_user *fl ;
   int fd ;
   struct dma_buf *buf ;
   struct sg_table *table ;
   struct dma_buf_attachment *attach ;
   u64 phys ;
   u64 size ;
   void *va ;
   u64 len ;
   struct kref refcount ;
};


struct fastrpc_channel_ctx;


struct fastrpc_invoke_ctx {
   int nscalars ;
   int nbufs ;
   int retval ;
   int pid ;
   int tgid ;
   u32 sc ;
   u32 *crc ;
   u64 ctxid ;
   u64 msg_sz ;
   struct kref refcount ;
   struct list_head node ;
   struct completion work ;
   struct fastrpc_msg msg ;
   struct fastrpc_user *fl ;
   struct fastrpc_remote_arg *rpra ;
   struct fastrpc_map **maps ;
   struct fastrpc_buf *buf ;
   struct fastrpc_invoke_args *args ;
   struct fastrpc_channel_ctx *cctx ;
};


struct fastrpc_session_ctx {
   struct device *dev ;
   int sid ;
   bool used ;
   bool valid ;
};


struct fastrpc_channel_ctx {
   int domain_id ;
   int sesscount ;
   struct rpmsg_device *rpdev ;
   struct fastrpc_session_ctx session[9U] ;
   spinlock_t lock ;
   struct idr ctx_idr ;
   struct list_head users ;
   struct miscdevice miscdev ;
};


struct fastrpc_user {
   struct list_head user ;
   struct list_head maps ;
   struct list_head pending ;
   struct fastrpc_channel_ctx *cctx ;
   struct fastrpc_session_ctx *sctx ;
   struct fastrpc_buf *init_mem ;
   int tgid ;
   int pd ;
   spinlock_t lock ;
   struct mutex mutex ;
};


struct __anonstruct_inbuf_463 {
   int pgid ;
   u32 namelen ;
   u32 filelen ;
   u32 pageslen ;
   u32 attrs ;
   u32 siglen ;
};


struct ldv_list_element {
   void *data ;
   struct ldv_list_element *next ;
};


typedef struct ldv_list_element *ldv_list_ptr;


struct device_private {
   void *driver_data ;
};


typedef s32 int32_t;


typedef u8 uint8_t;


struct seq_operations;


struct rcu_work {
   struct work_struct work ;
   struct callback_head rcu ;
   struct workqueue_struct *wq ;
};


struct user_struct;


struct psi_group_cpu {
   seqcount_t seq ;
   unsigned int tasks[3U] ;
   u32 times[6U] ;
   u64 state_start ;
   u32 times_prev[6U] ;
};


struct psi_group {
   struct mutex stat_lock ;
   struct psi_group_cpu *pcpu ;
   u64 total_prev[5U] ;
   u64 last_update ;
   u64 next_update ;
   struct delayed_work clock_work ;
   u64 total[5U] ;
   unsigned long avg[5U][3U] ;
};


struct ratelimit_state {
   raw_spinlock_t lock ;
   int interval ;
   int burst ;
   int printed ;
   int missed ;
   unsigned long begin ;
   unsigned long flags ;
};


struct kernel_cap_struct {
   __u32 cap[2U] ;
};


typedef struct kernel_cap_struct kernel_cap_t;


struct assoc_array_ptr;


struct assoc_array {
   struct assoc_array_ptr *root ;
   unsigned long nr_leaves_on_tree ;
};


typedef int32_t key_serial_t;


typedef uint32_t key_perm_t;


struct key_type;


struct keyring_index_key {
   struct key_type *type ;
   char const *description ;
   size_t desc_len ;
};


union key_payload {
   void *rcu_data0 ;
   void *data[4U] ;
};


struct key_restriction {
   int (*check)(struct key *, struct key_type const *, union key_payload const *, struct key *) ;
   struct key *key ;
   struct key_type *keytype ;
};


union __anonunion_1204 {
   struct list_head graveyard_link ;
   struct rb_node serial_node ;
};


struct key_user;


union __anonunion_1205 {
   time64_t expiry ;
   time64_t revoked_at ;
};


struct __anonstruct_1207 {
   struct key_type *type ;
   char *description ;
};


union __anonunion_1206 {
   struct keyring_index_key index_key ;
   struct __anonstruct_1207 __anonCompField___anonunion_1206_73 ;
};


struct __anonstruct_1209 {
   struct list_head name_link ;
   struct assoc_array keys ;
};


union __anonunion_1208 {
   union key_payload payload ;
   struct __anonstruct_1209 __anonCompField___anonunion_1208_75 ;
};


struct key {
   refcount_t usage ;
   key_serial_t serial ;
   union __anonunion_1204 __anonCompField_key_71 ;
   struct rw_semaphore sem ;
   struct key_user *user ;
   void *security ;
   union __anonunion_1205 __anonCompField_key_72 ;
   time64_t last_used_at ;
   kuid_t uid ;
   kgid_t gid ;
   key_perm_t perm ;
   unsigned short quotalen ;
   unsigned short datalen ;
   short state ;
   unsigned long flags ;
   union __anonunion_1206 __anonCompField_key_74 ;
   union __anonunion_1208 __anonCompField_key_76 ;
   struct key_restriction *restrict_link ;
};


struct user_struct {
   refcount_t __count ;
   atomic_t processes ;
   atomic_t sigpending ;
   atomic_t fanotify_listeners ;
   atomic_long_t epoll_watches ;
   unsigned long mq_bytes ;
   unsigned long locked_shm ;
   unsigned long unix_inflight ;
   atomic_long_t pipe_bufs ;
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   kuid_t uid ;
   atomic_long_t locked_vm ;
   struct ratelimit_state ratelimit ;
};


struct group_info {
   atomic_t usage ;
   int ngroups ;
   kgid_t gid[0U] ;
};


struct cred {
   atomic_t usage ;
   atomic_t subscribers ;
   void *put_addr ;
   unsigned int magic ;
   kuid_t uid ;
   kgid_t gid ;
   kuid_t suid ;
   kgid_t sgid ;
   kuid_t euid ;
   kgid_t egid ;
   kuid_t fsuid ;
   kgid_t fsgid ;
   unsigned int securebits ;
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_bset ;
   kernel_cap_t cap_ambient ;
   unsigned char jit_keyring ;
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct key *thread_keyring ;
   struct key *request_key_auth ;
   void *security ;
   struct user_struct *user ;
   struct user_namespace *user_ns ;
   struct group_info *group_info ;
   struct callback_head rcu ;
};


struct seq_file {
   char *buf ;
   size_t size ;
   size_t from ;
   size_t count ;
   size_t pad_until ;
   loff_t index ;
   loff_t read_pos ;
   u64 version ;
   struct mutex lock ;
   struct seq_operations const *op ;
   int poll_event ;
   struct file const *file ;
   void *private ;
};


struct seq_operations {
   void *(*start)(struct seq_file *, loff_t *) ;
   void (*stop)(struct seq_file *, void *) ;
   void *(*next)(struct seq_file *, void *, loff_t *) ;
   int (*show)(struct seq_file *, void *) ;
};


struct u64_stats_sync {
   
};


struct bpf_cgroup_storage_key {
   __u64 cgroup_inode_id ;
   __u32 attach_type ;
};


struct bpf_prog;


struct bpf_cgroup_storage;


struct bpf_prog_array_item {
   struct bpf_prog *prog ;
   struct bpf_cgroup_storage *cgroup_storage[2U] ;
};


struct bpf_prog_array {
   struct callback_head rcu ;
   struct bpf_prog_array_item items[0U] ;
};


struct cgroup;


struct bpf_cgroup_storage_map;


struct bpf_storage_buffer {
   struct callback_head rcu ;
   char data[0U] ;
};


union __anonunion_1257 {
   struct bpf_storage_buffer *buf ;
   void *percpu_buf ;
};


struct bpf_cgroup_storage {
   union __anonunion_1257 __anonCompField_bpf_cgroup_storage_107 ;
   struct bpf_cgroup_storage_map *map ;
   struct bpf_cgroup_storage_key key ;
   struct list_head list ;
   struct rb_node node ;
   struct callback_head rcu ;
};


struct cgroup_bpf {
   struct bpf_prog_array *effective[18U] ;
   struct list_head progs[18U] ;
   u32 flags[18U] ;
   struct bpf_prog_array *inactive ;
};


struct cgroup_root;


struct cgroup_subsys;


struct cgroup_taskset;


struct cgroup_file {
   struct kernfs_node *kn ;
   unsigned long notified_at ;
   struct timer_list notify_timer ;
};


struct cgroup_subsys_state {
   struct cgroup *cgroup ;
   struct cgroup_subsys *ss ;
   struct percpu_ref refcnt ;
   struct list_head sibling ;
   struct list_head children ;
   struct list_head rstat_css_node ;
   int id ;
   unsigned int flags ;
   u64 serial_nr ;
   atomic_t online_cnt ;
   struct work_struct destroy_work ;
   struct rcu_work destroy_rwork ;
   struct cgroup_subsys_state *parent ;
};


struct css_set {
   struct cgroup_subsys_state *subsys[14U] ;
   refcount_t refcount ;
   struct css_set *dom_cset ;
   struct cgroup *dfl_cgrp ;
   int nr_tasks ;
   struct list_head tasks ;
   struct list_head mg_tasks ;
   struct list_head task_iters ;
   struct list_head e_cset_node[14U] ;
   struct list_head threaded_csets ;
   struct list_head threaded_csets_node ;
   struct hlist_node hlist ;
   struct list_head cgrp_links ;
   struct list_head mg_preload_node ;
   struct list_head mg_node ;
   struct cgroup *mg_src_cgrp ;
   struct cgroup *mg_dst_cgrp ;
   struct css_set *mg_dst_cset ;
   bool dead ;
   struct callback_head callback_head ;
};


struct cgroup_base_stat {
   struct task_cputime cputime ;
};


struct cgroup_rstat_cpu {
   struct u64_stats_sync bsync ;
   struct cgroup_base_stat bstat ;
   struct cgroup_base_stat last_bstat ;
   struct cgroup *updated_children ;
   struct cgroup *updated_next ;
};


struct cgroup {
   struct cgroup_subsys_state self ;
   unsigned long flags ;
   int id ;
   int level ;
   int max_depth ;
   int nr_descendants ;
   int nr_dying_descendants ;
   int max_descendants ;
   int nr_populated_csets ;
   int nr_populated_domain_children ;
   int nr_populated_threaded_children ;
   int nr_threaded_children ;
   struct kernfs_node *kn ;
   struct cgroup_file procs_file ;
   struct cgroup_file events_file ;
   u16 subtree_control ;
   u16 subtree_ss_mask ;
   u16 old_subtree_control ;
   u16 old_subtree_ss_mask ;
   struct cgroup_subsys_state *subsys[14U] ;
   struct cgroup_root *root ;
   struct list_head cset_links ;
   struct list_head e_csets[14U] ;
   struct cgroup *dom_cgrp ;
   struct cgroup *old_dom_cgrp ;
   struct cgroup_rstat_cpu *rstat_cpu ;
   struct list_head rstat_css_list ;
   struct cgroup_base_stat pending_bstat ;
   struct cgroup_base_stat bstat ;
   struct prev_cputime prev_cputime ;
   struct list_head pidlists ;
   struct mutex pidlist_mutex ;
   wait_queue_head_t offline_waitq ;
   struct work_struct release_agent_work ;
   struct psi_group psi ;
   struct cgroup_bpf bpf ;
   atomic_t congestion_count ;
   int ancestor_ids[] ;
};


struct cgroup_root {
   struct kernfs_root *kf_root ;
   unsigned int subsys_mask ;
   int hierarchy_id ;
   struct cgroup cgrp ;
   int cgrp_ancestor_id_storage ;
   atomic_t nr_cgrps ;
   struct list_head root_list ;
   unsigned int flags ;
   struct idr cgroup_idr ;
   char release_agent_path[4096U] ;
   char name[64U] ;
};


struct cftype {
   char name[64U] ;
   unsigned long private ;
   size_t max_write_len ;
   unsigned int flags ;
   unsigned int file_offset ;
   struct cgroup_subsys *ss ;
   struct list_head node ;
   struct kernfs_ops *kf_ops ;
   int (*open)(struct kernfs_open_file *) ;
   void (*release)(struct kernfs_open_file *) ;
   u64 (*read_u64)(struct cgroup_subsys_state *, struct cftype *) ;
   s64 (*read_s64)(struct cgroup_subsys_state *, struct cftype *) ;
   int (*seq_show)(struct seq_file *, void *) ;
   void *(*seq_start)(struct seq_file *, loff_t *) ;
   void *(*seq_next)(struct seq_file *, void *, loff_t *) ;
   void (*seq_stop)(struct seq_file *, void *) ;
   int (*write_u64)(struct cgroup_subsys_state *, struct cftype *, u64 ) ;
   int (*write_s64)(struct cgroup_subsys_state *, struct cftype *, s64 ) ;
   ssize_t (*write)(struct kernfs_open_file *, char *, size_t , loff_t ) ;
   __poll_t (*poll)(struct kernfs_open_file *, struct poll_table_struct *) ;
   struct lock_class_key lockdep_key ;
};


struct cgroup_subsys {
   struct cgroup_subsys_state *(*css_alloc)(struct cgroup_subsys_state *) ;
   int (*css_online)(struct cgroup_subsys_state *) ;
   void (*css_offline)(struct cgroup_subsys_state *) ;
   void (*css_released)(struct cgroup_subsys_state *) ;
   void (*css_free)(struct cgroup_subsys_state *) ;
   void (*css_reset)(struct cgroup_subsys_state *) ;
   void (*css_rstat_flush)(struct cgroup_subsys_state *, int ) ;
   int (*css_extra_stat_show)(struct seq_file *, struct cgroup_subsys_state *) ;
   int (*can_attach)(struct cgroup_taskset *) ;
   void (*cancel_attach)(struct cgroup_taskset *) ;
   void (*attach)(struct cgroup_taskset *) ;
   void (*post_attach)(void) ;
   int (*can_fork)(struct task_struct *) ;
   void (*cancel_fork)(struct task_struct *) ;
   void (*fork)(struct task_struct *) ;
   void (*exit)(struct task_struct *) ;
   void (*release)(struct task_struct *) ;
   void (*bind)(struct cgroup_subsys_state *) ;
   bool early_init : 1 ;
   bool implicit_on_dfl : 1 ;
   bool threaded : 1 ;
   bool broken_hierarchy : 1 ;
   bool warned_broken_hierarchy : 1 ;
   int id ;
   char const *name ;
   char const *legacy_name ;
   struct cgroup_root *root ;
   struct idr css_idr ;
   struct list_head cfts ;
   struct cftype *dfl_cftypes ;
   struct cftype *legacy_cftypes ;
   unsigned int depends_on ;
};


struct cgroup_namespace {
   refcount_t count ;
   struct ns_common ns ;
   struct user_namespace *user_ns ;
   struct ucounts *ucounts ;
   struct css_set *root_cset ;
};


struct kthread_work;


struct kthread_worker {
   unsigned int flags ;
   raw_spinlock_t lock ;
   struct list_head work_list ;
   struct list_head delayed_work_list ;
   struct task_struct *task ;
   struct kthread_work *current_work ;
};


struct kthread_work {
   struct list_head node ;
   void (*func)(struct kthread_work *) ;
   struct kthread_worker *worker ;
   int canceling ;
};


struct gpio_desc;


struct dma_chan;


struct spi_controller;


struct spi_transfer;


struct spi_controller_mem_ops;


struct spi_statistics {
   spinlock_t lock ;
   unsigned long messages ;
   unsigned long transfers ;
   unsigned long errors ;
   unsigned long timedout ;
   unsigned long spi_sync ;
   unsigned long spi_sync_immediate ;
   unsigned long spi_async ;
   unsigned long long bytes ;
   unsigned long long bytes_rx ;
   unsigned long long bytes_tx ;
   unsigned long transfer_bytes_histo[17U] ;
   unsigned long transfers_split_maxsize ;
};


struct spi_device {
   struct device dev ;
   struct spi_controller *controller ;
   struct spi_controller *master ;
   u32 max_speed_hz ;
   u8 chip_select ;
   u8 bits_per_word ;
   u16 mode ;
   int irq ;
   void *controller_state ;
   void *controller_data ;
   char modalias[32U] ;
   char const *driver_override ;
   int cs_gpio ;
   struct gpio_desc *cs_gpiod ;
   uint8_t word_delay_usecs ;
   struct spi_statistics statistics ;
};


struct spi_message;


struct spi_controller {
   struct device dev ;
   struct list_head list ;
   s16 bus_num ;
   u16 num_chipselect ;
   u16 dma_alignment ;
   u16 mode_bits ;
   u32 bits_per_word_mask ;
   u32 min_speed_hz ;
   u32 max_speed_hz ;
   u16 flags ;
   bool slave ;
   size_t (*max_transfer_size)(struct spi_device *) ;
   size_t (*max_message_size)(struct spi_device *) ;
   struct mutex io_mutex ;
   spinlock_t bus_lock_spinlock ;
   struct mutex bus_lock_mutex ;
   bool bus_lock_flag ;
   int (*setup)(struct spi_device *) ;
   int (*transfer)(struct spi_device *, struct spi_message *) ;
   void (*cleanup)(struct spi_device *) ;
   bool (*can_dma)(struct spi_controller *, struct spi_device *, struct spi_transfer *) ;
   bool queued ;
   struct kthread_worker kworker ;
   struct task_struct *kworker_task ;
   struct kthread_work pump_messages ;
   spinlock_t queue_lock ;
   struct list_head queue ;
   struct spi_message *cur_msg ;
   bool idling ;
   bool busy ;
   bool running ;
   bool rt ;
   bool auto_runtime_pm ;
   bool cur_msg_prepared ;
   bool cur_msg_mapped ;
   struct completion xfer_completion ;
   size_t max_dma_len ;
   int (*prepare_transfer_hardware)(struct spi_controller *) ;
   int (*transfer_one_message)(struct spi_controller *, struct spi_message *) ;
   int (*unprepare_transfer_hardware)(struct spi_controller *) ;
   int (*prepare_message)(struct spi_controller *, struct spi_message *) ;
   int (*unprepare_message)(struct spi_controller *, struct spi_message *) ;
   int (*slave_abort)(struct spi_controller *) ;
   void (*set_cs)(struct spi_device *, bool ) ;
   int (*transfer_one)(struct spi_controller *, struct spi_device *, struct spi_transfer *) ;
   void (*handle_err)(struct spi_controller *, struct spi_message *) ;
   struct spi_controller_mem_ops const *mem_ops ;
   int *cs_gpios ;
   struct gpio_desc **cs_gpiods ;
   bool use_gpio_descriptors ;
   struct spi_statistics statistics ;
   struct dma_chan *dma_tx ;
   struct dma_chan *dma_rx ;
   void *dummy_rx ;
   void *dummy_tx ;
   int (*fw_translate_cs)(struct spi_controller *, unsigned int ) ;
};


struct spi_transfer {
   void const *tx_buf ;
   void *rx_buf ;
   unsigned int len ;
   dma_addr_t tx_dma ;
   dma_addr_t rx_dma ;
   struct sg_table tx_sg ;
   struct sg_table rx_sg ;
   unsigned int cs_change : 1 ;
   unsigned int tx_nbits : 3 ;
   unsigned int rx_nbits : 3 ;
   u8 bits_per_word ;
   u8 word_delay_usecs ;
   u16 delay_usecs ;
   u32 speed_hz ;
   u16 word_delay ;
   struct list_head transfer_list ;
};


struct spi_message {
   struct list_head transfers ;
   struct spi_device *spi ;
   unsigned int is_dma_mapped : 1 ;
   void (*complete)(void *) ;
   void *context ;
   unsigned int frame_length ;
   unsigned int actual_length ;
   int status ;
   struct list_head queue ;
   void *state ;
   struct list_head resources ;
};


typedef unsigned long irq_hw_number_t;


struct notifier_block;


struct notifier_block {
   int (*notifier_call)(struct notifier_block *, unsigned long , void *) ;
   struct notifier_block *next ;
   int priority ;
};


struct irq_data;


struct irq_fwspec {
   struct fwnode_handle *fwnode ;
   int param_count ;
   u32 param[16U] ;
};


enum irq_domain_bus_token {
    DOMAIN_BUS_ANY = 0,
    DOMAIN_BUS_WIRED = 1,
    DOMAIN_BUS_GENERIC_MSI = 2,
    DOMAIN_BUS_PCI_MSI = 3,
    DOMAIN_BUS_PLATFORM_MSI = 4,
    DOMAIN_BUS_NEXUS = 5,
    DOMAIN_BUS_IPI = 6,
    DOMAIN_BUS_FSL_MC_MSI = 7
};


struct irq_domain_ops {
   int (*match)(struct irq_domain *, struct device_node *, enum irq_domain_bus_token ) ;
   int (*select)(struct irq_domain *, struct irq_fwspec *, enum irq_domain_bus_token ) ;
   int (*map)(struct irq_domain *, unsigned int , irq_hw_number_t ) ;
   void (*unmap)(struct irq_domain *, unsigned int ) ;
   int (*xlate)(struct irq_domain *, struct device_node *, u32 const *, unsigned int , unsigned long *, unsigned int *) ;
   int (*alloc)(struct irq_domain *, unsigned int , unsigned int , void *) ;
   void (*free)(struct irq_domain *, unsigned int , unsigned int ) ;
   int (*activate)(struct irq_domain *, struct irq_data *, bool ) ;
   void (*deactivate)(struct irq_domain *, struct irq_data *) ;
   int (*translate)(struct irq_domain *, struct irq_fwspec *, unsigned long *, unsigned int *) ;
   void (*debug_show)(struct seq_file *, struct irq_domain *, struct irq_data *, int ) ;
};


struct irq_domain_chip_generic;


struct irq_domain {
   struct list_head link ;
   char const *name ;
   struct irq_domain_ops const *ops ;
   void *host_data ;
   unsigned int flags ;
   unsigned int mapcount ;
   struct fwnode_handle *fwnode ;
   enum irq_domain_bus_token bus_token ;
   struct irq_domain_chip_generic *gc ;
   struct irq_domain *parent ;
   struct dentry *debugfs_file ;
   irq_hw_number_t hwirq_max ;
   unsigned int revmap_direct_max_irq ;
   unsigned int revmap_size ;
   struct xarray revmap_tree ;
   struct mutex revmap_tree_mutex ;
   unsigned int linear_revmap[] ;
};


struct fb_fix_screeninfo {
   char id[16U] ;
   unsigned long smem_start ;
   __u32 smem_len ;
   __u32 type ;
   __u32 type_aux ;
   __u32 visual ;
   __u16 xpanstep ;
   __u16 ypanstep ;
   __u16 ywrapstep ;
   __u32 line_length ;
   unsigned long mmio_start ;
   __u32 mmio_len ;
   __u32 accel ;
   __u16 capabilities ;
   __u16 reserved[2U] ;
};


struct fb_bitfield {
   __u32 offset ;
   __u32 length ;
   __u32 msb_right ;
};


struct fb_var_screeninfo {
   __u32 xres ;
   __u32 yres ;
   __u32 xres_virtual ;
   __u32 yres_virtual ;
   __u32 xoffset ;
   __u32 yoffset ;
   __u32 bits_per_pixel ;
   __u32 grayscale ;
   struct fb_bitfield red ;
   struct fb_bitfield green ;
   struct fb_bitfield blue ;
   struct fb_bitfield transp ;
   __u32 nonstd ;
   __u32 activate ;
   __u32 height ;
   __u32 width ;
   __u32 accel_flags ;
   __u32 pixclock ;
   __u32 left_margin ;
   __u32 right_margin ;
   __u32 upper_margin ;
   __u32 lower_margin ;
   __u32 hsync_len ;
   __u32 vsync_len ;
   __u32 sync ;
   __u32 vmode ;
   __u32 rotate ;
   __u32 colorspace ;
   __u32 reserved[4U] ;
};


struct fb_cmap {
   __u32 start ;
   __u32 len ;
   __u16 *red ;
   __u16 *green ;
   __u16 *blue ;
   __u16 *transp ;
};


struct fb_copyarea {
   __u32 dx ;
   __u32 dy ;
   __u32 width ;
   __u32 height ;
   __u32 sx ;
   __u32 sy ;
};


struct fb_fillrect {
   __u32 dx ;
   __u32 dy ;
   __u32 width ;
   __u32 height ;
   __u32 color ;
   __u32 rop ;
};


struct fb_image {
   __u32 dx ;
   __u32 dy ;
   __u32 width ;
   __u32 height ;
   __u32 fg_color ;
   __u32 bg_color ;
   __u8 depth ;
   char const *data ;
   struct fb_cmap cmap ;
};


struct fbcurpos {
   __u16 x ;
   __u16 y ;
};


struct fb_cursor {
   __u16 set ;
   __u16 enable ;
   __u16 rop ;
   char const *mask ;
   struct fbcurpos hot ;
   struct fb_image image ;
};


enum backlight_type {
    BACKLIGHT_RAW = 1,
    BACKLIGHT_PLATFORM = 2,
    BACKLIGHT_FIRMWARE = 3,
    BACKLIGHT_TYPE_MAX = 4
};


struct backlight_device;


struct fb_info;


struct backlight_ops {
   unsigned int options ;
   int (*update_status)(struct backlight_device *) ;
   int (*get_brightness)(struct backlight_device *) ;
   int (*check_fb)(struct backlight_device *, struct fb_info *) ;
};


struct backlight_properties {
   int brightness ;
   int max_brightness ;
   int power ;
   int fb_blank ;
   enum backlight_type type ;
   unsigned int state ;
};


struct backlight_device {
   struct backlight_properties props ;
   struct mutex update_lock ;
   struct mutex ops_lock ;
   struct backlight_ops const *ops ;
   struct notifier_block fb_notif ;
   struct list_head entry ;
   struct device dev ;
   bool fb_bl_on[32U] ;
   int use_count ;
};


struct fb_chroma {
   __u32 redx ;
   __u32 greenx ;
   __u32 bluex ;
   __u32 whitex ;
   __u32 redy ;
   __u32 greeny ;
   __u32 bluey ;
   __u32 whitey ;
};


struct fb_videomode;


struct fb_monspecs {
   struct fb_chroma chroma ;
   struct fb_videomode *modedb ;
   __u8 manufacturer[4U] ;
   __u8 monitor[14U] ;
   __u8 serial_no[14U] ;
   __u8 ascii[14U] ;
   __u32 modedb_len ;
   __u32 model ;
   __u32 serial ;
   __u32 year ;
   __u32 week ;
   __u32 hfmin ;
   __u32 hfmax ;
   __u32 dclkmin ;
   __u32 dclkmax ;
   __u16 input ;
   __u16 dpms ;
   __u16 signal ;
   __u16 vfmin ;
   __u16 vfmax ;
   __u16 gamma ;
   __u16 gtf : 1 ;
   __u16 misc ;
   __u8 version ;
   __u8 revision ;
   __u8 max_x ;
   __u8 max_y ;
};


struct fb_blit_caps {
   u32 x ;
   u32 y ;
   u32 len ;
   u32 flags ;
};


struct fb_pixmap {
   u8 *addr ;
   u32 size ;
   u32 offset ;
   u32 buf_align ;
   u32 scan_align ;
   u32 access_align ;
   u32 flags ;
   u32 blit_x ;
   u32 blit_y ;
   void (*writeio)(struct fb_info *, void *, void *, unsigned int ) ;
   void (*readio)(struct fb_info *, void *, void *, unsigned int ) ;
};


struct fb_deferred_io {
   unsigned long delay ;
   struct mutex lock ;
   struct list_head pagelist ;
   void (*first_io)(struct fb_info *) ;
   void (*deferred_io)(struct fb_info *, struct list_head *) ;
};


struct fb_ops {
   struct module *owner ;
   int (*fb_open)(struct fb_info *, int ) ;
   int (*fb_release)(struct fb_info *, int ) ;
   ssize_t (*fb_read)(struct fb_info *, char *, size_t , loff_t *) ;
   ssize_t (*fb_write)(struct fb_info *, char const *, size_t , loff_t *) ;
   int (*fb_check_var)(struct fb_var_screeninfo *, struct fb_info *) ;
   int (*fb_set_par)(struct fb_info *) ;
   int (*fb_setcolreg)(unsigned int , unsigned int , unsigned int , unsigned int , unsigned int , struct fb_info *) ;
   int (*fb_setcmap)(struct fb_cmap *, struct fb_info *) ;
   int (*fb_blank)(int , struct fb_info *) ;
   int (*fb_pan_display)(struct fb_var_screeninfo *, struct fb_info *) ;
   void (*fb_fillrect)(struct fb_info *, struct fb_fillrect const *) ;
   void (*fb_copyarea)(struct fb_info *, struct fb_copyarea const *) ;
   void (*fb_imageblit)(struct fb_info *, struct fb_image const *) ;
   int (*fb_cursor)(struct fb_info *, struct fb_cursor *) ;
   int (*fb_sync)(struct fb_info *) ;
   int (*fb_ioctl)(struct fb_info *, unsigned int , unsigned long ) ;
   int (*fb_compat_ioctl)(struct fb_info *, unsigned int , unsigned long ) ;
   int (*fb_mmap)(struct fb_info *, struct vm_area_struct *) ;
   void (*fb_get_caps)(struct fb_info *, struct fb_blit_caps *, struct fb_var_screeninfo *) ;
   void (*fb_destroy)(struct fb_info *) ;
   int (*fb_debug_enter)(struct fb_info *) ;
   int (*fb_debug_leave)(struct fb_info *) ;
};


struct fb_tilemap {
   __u32 width ;
   __u32 height ;
   __u32 depth ;
   __u32 length ;
   __u8 const *data ;
};


struct fb_tilerect {
   __u32 sx ;
   __u32 sy ;
   __u32 width ;
   __u32 height ;
   __u32 index ;
   __u32 fg ;
   __u32 bg ;
   __u32 rop ;
};


struct fb_tilearea {
   __u32 sx ;
   __u32 sy ;
   __u32 dx ;
   __u32 dy ;
   __u32 width ;
   __u32 height ;
};


struct fb_tileblit {
   __u32 sx ;
   __u32 sy ;
   __u32 width ;
   __u32 height ;
   __u32 fg ;
   __u32 bg ;
   __u32 length ;
   __u32 *indices ;
};


struct fb_tilecursor {
   __u32 sx ;
   __u32 sy ;
   __u32 mode ;
   __u32 shape ;
   __u32 fg ;
   __u32 bg ;
};


struct fb_tile_ops {
   void (*fb_settile)(struct fb_info *, struct fb_tilemap *) ;
   void (*fb_tilecopy)(struct fb_info *, struct fb_tilearea *) ;
   void (*fb_tilefill)(struct fb_info *, struct fb_tilerect *) ;
   void (*fb_tileblit)(struct fb_info *, struct fb_tileblit *) ;
   void (*fb_tilecursor)(struct fb_info *, struct fb_tilecursor *) ;
   int (*fb_get_tilemax)(struct fb_info *) ;
};


struct aperture {
   resource_size_t base ;
   resource_size_t size ;
};


struct apertures_struct {
   unsigned int count ;
   struct aperture ranges[0U] ;
};


union __anonunion_1729 {
   char *screen_base ;
   char *screen_buffer ;
};


struct fb_info {
   atomic_t count ;
   int node ;
   int flags ;
   int fbcon_rotate_hint ;
   struct mutex lock ;
   struct mutex mm_lock ;
   struct fb_var_screeninfo var ;
   struct fb_fix_screeninfo fix ;
   struct fb_monspecs monspecs ;
   struct work_struct queue ;
   struct fb_pixmap pixmap ;
   struct fb_pixmap sprite ;
   struct fb_cmap cmap ;
   struct list_head modelist ;
   struct fb_videomode *mode ;
   struct backlight_device *bl_dev ;
   struct mutex bl_curve_mutex ;
   u8 bl_curve[128U] ;
   struct delayed_work deferred_work ;
   struct fb_deferred_io *fbdefio ;
   struct fb_ops *fbops ;
   struct device *device ;
   struct device *dev ;
   int class_flag ;
   struct fb_tile_ops *tileops ;
   union __anonunion_1729 __anonCompField_fb_info_70 ;
   unsigned long screen_size ;
   void *pseudo_palette ;
   u32 state ;
   void *fbcon_par ;
   void *par ;
   struct apertures_struct *apertures ;
   bool skip_vt_switch ;
};


struct fb_videomode {
   char const *name ;
   u32 refresh ;
   u32 xres ;
   u32 yres ;
   u32 pixclock ;
   u32 left_margin ;
   u32 right_margin ;
   u32 upper_margin ;
   u32 lower_margin ;
   u32 hsync_len ;
   u32 vsync_len ;
   u32 sync ;
   u32 vmode ;
   u32 flag ;
};
/* compiler builtin: 
   void *__builtin_memcpy(void *, void const *, unsigned long);   */
/* compiler builtin: 
   void *__builtin_memset(void *, int, int);   */
/* compiler builtin: 
   unsigned long __builtin_object_size(void *, int);   */
/* compiler builtin: 
   char *__builtin_strcpy(char *, char const *);   */
/* compiler builtin: 
   char *__builtin_strncat(char *, char const *, unsigned long);   */
/* compiler builtin: 
   char *__builtin_strncpy(char *, char const *, unsigned long);   */
/* compiler builtin: 
   void __builtin_unreachable(void);   */
/* compiler builtin: 
   void __builtin_va_start(__builtin_va_list);   */


void ldv_inline_asm(void);



long ldv_is_err(void const *ptr);



long ldv_is_err_or_null(void const *ptr);



void *ldv_err_ptr(long error);



long ldv_ptr_err(void const *ptr);



void ldv_check_alloc_flags(gfp_t);



void ldv_free(void *s);



void *ldv_malloc_unknown_size(void);



void *ldv_calloc_unknown_size(void);



void ldv_after_alloc(void *res);



void *ldv_alloc_macro(gfp_t flags)
{
  

  ldv_check_alloc_flags(flags);
  

  
  

  return ldv_malloc_unknown_size();
}



void *ldv_kzalloc(size_t size, gfp_t flags);



void *ldv_kcalloc(size_t n, size_t size, gfp_t flags);



extern struct module __this_module;



__inline static void __write_once_size(void volatile *p, void *res, int size)
{
  

  switch (size) {
    case 1: 

    ;
    

    *((__u8 volatile *)p) = *((__u8 *)res);
    

    goto ldv_1540;
    case 2: 

    ;
    

    *((__u16 volatile *)p) = *((__u16 *)res);
    

    goto ldv_1540;
    case 4: 

    ;
    

    *((__u32 volatile *)p) = *((__u32 *)res);
    

    goto ldv_1540;
    case 8: 

    ;
    

    *((__u64 volatile *)p) = *((__u64 *)res);
    

    goto ldv_1540;
    default: 

    ;
    

    ldv_inline_asm();
    

    __builtin_memcpy((void *)p,(void const *)res,(unsigned long)size);
    

    ldv_inline_asm();
  }
  ldv_1540: 

  ;
  

  return;
}



void kasan_check_write(void const volatile *, unsigned int);



int printk(char const * , ...);



__inline static bool arch_static_branch(struct static_key *key, bool branch)
{
  

  ldv_inline_asm();
  

  ldv_inline_asm();
  

  return (_Bool)0;
  l_yes: 

  ;
  

  return (_Bool)1;
}



void __dynamic_dev_dbg(struct _ddebug *, struct device const *, char const * , ...);



static char *cif_kasprintf(gfp_t ldv_func_arg1, char const *ldv_func_arg2 , ...);



__inline static void INIT_LIST_HEAD(struct list_head *list)
{
  

  list->prev = list;
  

  return;
}



bool __list_add_valid(struct list_head *, struct list_head *, struct list_head *);



bool __list_del_entry_valid(struct list_head *);



__inline static void __list_add(struct list_head *new, struct list_head *prev, struct list_head *next)
{
  

  
  
 

  next->prev = new;
  

  new->next = next;
  

  new->prev = prev;
  

  return;
}



__inline static void list_add(struct list_head *new, struct list_head *head)
{
  

  __list_add(new,head,head->next);
  

  return;
}



__inline static void list_add_tail(struct list_head *new, struct list_head *head)
{
  

  __list_add(new,head->prev,head);
  

  return;
}



__inline static void __list_del(struct list_head *prev, struct list_head *next)
{
  

  next->prev = prev;
  

  return;
}



__inline static void __list_del_entry(struct list_head *entry)
{
  


  __list_del(entry->prev,entry->next);
  

  return;
}



__inline static void list_del(struct list_head *entry)
{
  

  __list_del_entry(entry);
  

  entry->next = (struct list_head *)(-2401263026318606080);
  

  entry->prev = (struct list_head *)(-2401263026318605824);
  

  return;
}



void __bad_percpu_size(void);



void __warn_printk(char const * , ...);



__inline static struct task_struct *get_current(void)
{
  struct task_struct *pfo_ret__;
  

  switch (8UL) {
    case (unsigned long)1: 

    ;
    

    ldv_inline_asm();
    

    goto ldv_3207;
    case (unsigned long)2: 

    ;
    

    ldv_inline_asm();
    

    goto ldv_3207;
    case (unsigned long)4: 

    ;
    

    ldv_inline_asm();
    

    goto ldv_3207;
    case (unsigned long)8: 

    ;
    

    ldv_inline_asm();
    

    goto ldv_3207;
    default: 

    ;
    

    __bad_percpu_size();
  }
  ldv_3207: 

  ;
  

  
  

  return pfo_ret__;
}



extern unsigned long page_offset_base;



extern unsigned long vmemmap_base;



void *memcpy(void *p, void const *q, unsigned long size);



void *memset(void *p, int c, unsigned long size);



void *memmove(void *p, void const *q, unsigned long size);



int memcmp(void const *p, void const *q, unsigned long size);



size_t strlen(char const *p);



char *strcpy(char *p, char const *q);



char *strcat(char *p, char const *q);



int strcmp(char const *, char const *);



char *strncpy(char *p, char const *q, __kernel_size_t size);



size_t strlcpy(char *p, char const *q, size_t size);



char *strncat(char *p, char const *q, __kernel_size_t count);



size_t strlcat(char *, char const *, __kernel_size_t);



__kernel_size_t strnlen(char const *p, __kernel_size_t maxlen);



void *memscan(void *p, int c, __kernel_size_t size);



void *memchr(void const *p, int c, __kernel_size_t size);



void *memchr_inv(void const *p, int c, size_t size);



void *kmemdup(void const *p, size_t size, gfp_t gfp);



void fortify_panic(char const *);



void __read_overflow(void);



void __read_overflow2(void);



void __write_overflow(void);



char *strncpy(char *p, char const *q, __kernel_size_t size)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (0 != 0 && p_size < size) 

                               __write_overflow();
  

  if (p_size < size) 

                     fortify_panic("strncpy");
  

  
  

  return __builtin_strncpy(p,q,size);
}



extern int ( /* missing proto */ __builtin_strcat)(char *x_0, char const *x_1);



char *strcat(char *p, char const *q)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (p_size == 18446744073709551615UL) {
    

    
    

    return (char *)__builtin_strcat(p,q);
  }
  

  
  

  ;
  

  if (strlcat(p,q,p_size) >= p_size) 

                                     fortify_panic("strcat");
  

  return p;
}



extern int ( /* missing proto */ __builtin_strlen)(char const *x_0);



size_t strlen(char const *p)
{
  __kernel_size_t ret;
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (p_size == 18446744073709551615UL || (0 != 0 && (int)*(p + (p_size + 18446744073709551615U)) == 0)) {
    

    
    

    return (unsigned long)__builtin_strlen(p);
  }
  

  ret = strnlen(p,p_size);
  

  if (p_size <= ret) 

                     fortify_panic("strlen");
  

  return ret;
}



__kernel_size_t __real_strnlen(char const *, __kernel_size_t);



__kernel_size_t strnlen(char const *p, __kernel_size_t maxlen)
{
  __kernel_size_t tmp_0;
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (maxlen < p_size) 

                       tmp_0 = maxlen; else 

                                            tmp_0 = p_size;
  

  ;
  

  
  

  __kernel_size_t ret = __real_strnlen(p,tmp_0);
  

  if (p_size <= ret && maxlen != ret) 

                                      fortify_panic("strnlen");
  

  return ret;
}



size_t __real_strlcpy(char *, char const *, size_t);



size_t strlcpy(char *p, char const *q, size_t size)
{
  size_t ret;
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  size_t q_size = __builtin_object_size((void *)((void const *)q),0);
  

  if (p_size == 18446744073709551615UL && q_size == 18446744073709551615UL) {
    

    
    

    return __real_strlcpy(p,q,size);
  }
  

  ret = strlen(q);
  

  if (size != 0UL) {
    size_t tmp_2;
    

    if (ret >= size) 

                     tmp_2 = size + 18446744073709551615UL; else 

                                                                 tmp_2 = ret;
    

    size_t len = tmp_2;
    

    if (0 != 0 && len >= p_size) 

                                 __write_overflow();
    

    if (len >= p_size) 

                       fortify_panic("strlcpy");
    

    __builtin_memcpy((void *)p,(void const *)q,len);
    

    *(p + len) = (char)0;
  }
  

  return ret;
}



char *strncat(char *p, char const *q, __kernel_size_t count)
{
  size_t p_len;
  size_t copy_len;
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  size_t q_size = __builtin_object_size((void *)((void const *)q),0);
  

  if (p_size == 18446744073709551615UL && q_size == 18446744073709551615UL) {
    

    
    

    return __builtin_strncat(p,q,count);
  }
  

  p_len = strlen((char const *)p);
  

  copy_len = strnlen(q,count);
  

  if ((p_len + copy_len) + 1UL > p_size) 

                                         fortify_panic("strncat");
  

  __builtin_memcpy((void *)(p + p_len),(void const *)q,copy_len);
  

  *(p + (p_len + copy_len)) = (char)0;
  

  return p;
}



void *memset(void *p, int c, unsigned long size)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (0 != 0 && p_size < size) 

                               __write_overflow();
  

  if (p_size < size) 

                     fortify_panic("memset");
  

  
  

  return __builtin_memset(p,c,(int)size);
}



void *memcpy(void *p, void const *q, unsigned long size)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  size_t q_size = __builtin_object_size((void *)q,0);
  

  if (0 != 0) {
    

    if (p_size < size) 

                       __write_overflow();
    

    if (q_size < size) 

                       __read_overflow2();
  }
  

  if (p_size < size || q_size < size) 

                                      fortify_panic("memcpy");
  

  
  

  return __builtin_memcpy(p,q,size);
}



extern int ( /* missing proto */ __builtin_memmove)(void *x_0, void const *x_1, unsigned long x_2);



void *memmove(void *p, void const *q, unsigned long size)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  size_t q_size = __builtin_object_size((void *)q,0);
  

  if (0 != 0) {
    

    if (p_size < size) 

                       __write_overflow();
    

    if (q_size < size) 

                       __read_overflow2();
  }
  

  if (p_size < size || q_size < size) 

                                      fortify_panic("memmove");
  

  
  

  return (void *)__builtin_memmove(p,q,size);
}



void *__real_memscan(void *, int, __kernel_size_t);



void *memscan(void *p, int c, __kernel_size_t size)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  if (0 != 0 && p_size < size) 

                               __read_overflow();
  

  if (p_size < size) 

                     fortify_panic("memscan");
  

  
  

  return __real_memscan(p,c,size);
}



extern int ( /* missing proto */ __builtin_memcmp)(void const *x_0, void const *x_1, unsigned long x_2);



int memcmp(void const *p, void const *q, unsigned long size)
{
  

  size_t p_size = __builtin_object_size((void *)p,0);
  

  size_t q_size = __builtin_object_size((void *)q,0);
  

  if (0 != 0) {
    

    if (p_size < size) 

                       __read_overflow();
    

    if (q_size < size) 

                       __read_overflow2();
  }
  

  if (p_size < size || q_size < size) 

                                      fortify_panic("memcmp");
  

  
  

  return __builtin_memcmp(p,q,size);
}



extern int ( /* missing proto */ __builtin_memchr)(void const *x_0, int x_1, unsigned long x_2);



void *memchr(void const *p, int c, __kernel_size_t size)
{
  

  size_t p_size = __builtin_object_size((void *)p,0);
  

  if (0 != 0 && p_size < size) 

                               __read_overflow();
  

  if (p_size < size) 

                     fortify_panic("memchr");
  

  
  

  return (void *)__builtin_memchr(p,c,size);
}



void *__real_memchr_inv(void const *, int, size_t);



void *memchr_inv(void const *p, int c, size_t size)
{
  

  size_t p_size = __builtin_object_size((void *)p,0);
  

  if (0 != 0 && p_size < size) 

                               __read_overflow();
  

  if (p_size < size) 

                     fortify_panic("memchr_inv");
  

  
  

  return __real_memchr_inv(p,c,size);
}



void *__real_kmemdup(void const *, size_t, gfp_t);



void *kmemdup(void const *p, size_t size, gfp_t gfp)
{
  

  size_t p_size = __builtin_object_size((void *)p,0);
  

  if (0 != 0 && p_size < size) 

                               __read_overflow();
  

  if (p_size < size) 

                     fortify_panic("kmemdup");
  

  
  

  return __real_kmemdup(p,size,gfp);
}



char *strcpy(char *p, char const *q)
{
  

  size_t p_size = __builtin_object_size((void *)((void const *)p),0);
  

  size_t q_size = __builtin_object_size((void *)((void const *)q),0);
  

  if (p_size == 18446744073709551615UL && q_size == 18446744073709551615UL) {
    

    
    

    return __builtin_strcpy(p,q);
  }
  

  
  

  ;
  

  ;
  

  memcpy((void *)p,(void const *)q,strlen(q) + 1UL);
  

  return p;
}



__inline static void arch_atomic_set(atomic_t *v, int i)
{
  

  union __anonunion___u_79 __u = {.__val = i};
  

  __write_once_size((void volatile *)(& v->counter),(void *)(& __u.__c),4);
  

  int tmp = __u.__val;
  

  return;
}



__inline static void arch_atomic64_inc(atomic64_t *v)
{
  

  ldv_inline_asm();
  

  return;
}



__inline static void atomic_set(atomic_t *v, int i)
{
  

  kasan_check_write((void const volatile *)v,4U);
  

  arch_atomic_set(v,i);
  

  return;
}



__inline static void atomic64_inc(atomic64_t *v)
{
  

  kasan_check_write((void const volatile *)v,8U);
  

  arch_atomic64_inc(v);
  

  return;
}



__inline static void atomic_long_inc(atomic_long_t *v)
{
  

  atomic64_inc(v);
  

  return;
}



static void *ERR_PTR(long error);



static long PTR_ERR(void const *ptr);



static bool IS_ERR(void const *ptr);



static bool IS_ERR_OR_NULL(void const *ptr);



unsigned long native_save_fl(void);



unsigned long native_save_fl(void)
{
  unsigned long flags;
  

  ldv_inline_asm();
  

  return flags;
}



void native_restore_fl(unsigned long flags);



void native_restore_fl(unsigned long flags)
{
  

  ldv_inline_asm();
  

  return;
}



void __check_object_size(void const *, unsigned long, bool);



__inline static void check_object_size(void const *ptr, unsigned long n, bool to_user)
{
  

  if (0 == 0) 

              __check_object_size(ptr,n,(_Bool)((bool)((int)to_user) != 0));
  

  return;
}



void __bad_copy_from(void);



void __bad_copy_to(void);



__inline static void copy_overflow(int size, unsigned long count)
{
  

  int __ret_warn_on = 1;
  

  if ((long)(__ret_warn_on != 0) != 0L) {
    

    __warn_printk("Buffer overflow detected (%d < %lu)!\n",size,count);
    

    ldv_inline_asm();
    

    ldv_inline_asm();
  }
  

  long tmp = (long)(__ret_warn_on != 0);
  

  return;
}



__inline static bool check_copy_size(void const *addr, size_t bytes, bool is_source)
{
  

  
  

  int sz = (int)__builtin_object_size((void *)addr,0);
  

  if ((long)(sz >= 0) != 0L && (long)((unsigned long)sz < bytes) != 0L) {
    

    if (0 == 0) 

                copy_overflow(sz,bytes);
    else 
      

      if ((int)is_source != 0) 

                               __bad_copy_from(); else 

                                                       __bad_copy_to();
    

    return (_Bool)0;
  }
  

  check_object_size(addr,bytes,(_Bool)((bool)((int)is_source) != 0));
  

  return (_Bool)1;
}



void __raw_spin_lock_init(raw_spinlock_t *, char const *, struct lock_class_key *);



void _raw_spin_lock(raw_spinlock_t *);



unsigned long _raw_spin_lock_irqsave(raw_spinlock_t *);



void _raw_spin_unlock(raw_spinlock_t *);



void _raw_spin_unlock_irqrestore(raw_spinlock_t *, unsigned long);



__inline static raw_spinlock_t *spinlock_check(spinlock_t *lock)
{
  

  return & lock->__anonCompField_spinlock_25.rlock;
}



__inline static void spin_lock(spinlock_t *lock)
{
  

  _raw_spin_lock(& lock->__anonCompField_spinlock_25.rlock);
  

  return;
}



__inline static void spin_unlock(spinlock_t *lock)
{
  

  _raw_spin_unlock(& lock->__anonCompField_spinlock_25.rlock);
  

  return;
}



__inline static void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags)
{
  {
    unsigned long __dummy;
    unsigned long __dummy2;
    
  }
  

  _raw_spin_unlock_irqrestore(& lock->__anonCompField_spinlock_25.rlock,flags);
  

  return;
}



__inline static void refcount_set(refcount_t *r, unsigned int n)
{
  

  atomic_set(& r->refs,(int)n);
  

  return;
}



void refcount_inc_checked(refcount_t *);



bool refcount_dec_and_test_checked(refcount_t *);



__inline static void kref_init(struct kref *kref)
{
  

  kref->refcount.refs.counter=1U;
  

  return;
}



__inline static void kref_get(struct kref *kref)
{
  

  kref->refcount.refs.counter = kref->refcount.refs.counter + 1;
  

  return;
}



__inline static int kref_put(struct kref *kref, void (*release)(struct kref *))
{
  

  
  kref->refcount.refs.counter = kref->refcount.refs.counter - 1;

  if (kref->refcount.refs.counter == 0) {
    

    (*release)(kref);
    

    return 1;
  }
  

  return 0;
}



void mutex_destroy(struct mutex *);



void __mutex_init(struct mutex *, char const *, struct lock_class_key *);



void mutex_lock_nested(struct mutex *, unsigned int);



void mutex_unlock(struct mutex *);



void __init_waitqueue_head(struct wait_queue_head *, char const *, struct lock_class_key *);



__inline static void __init_completion(struct completion *x)
{
  

  x->done = 0U;
  {
    struct lock_class_key __key;
    

    __init_waitqueue_head(& x->wait,"&x->wait",& __key);
  }
  

  return;
}



int wait_for_completion_interruptible(struct completion *);



void complete(struct completion *);



__inline static void xa_init_flags(struct xarray *xa, gfp_t flags)
{
  

  spinlock_check(& xa->xa_lock);
  {
    struct lock_class_key __key;
    

    __raw_spin_lock_init(& xa->xa_lock.__anonCompField_spinlock_25.rlock,"&(&xa->xa_lock)->rlock",& __key);
  }
  

  xa->xa_flags = flags;
  

  xa->xa_head = (void *)0;
  

  return;
}



int idr_alloc_cyclic(struct idr *, void *, int, int, gfp_t);



void *idr_remove(struct idr *, unsigned long);



void *idr_find(struct idr const *, unsigned long);



__inline static void idr_init_base(struct idr *idr, int base)
{
  

  xa_init_flags(& idr->idr_rt,16777220U);
  

  idr->idr_base = (unsigned int)base;
  

  idr->idr_next = 0U;
  

  return;
}



__inline static void idr_init(struct idr *idr)
{
  

  idr_init_base(idr,0);
  

  return;
}



static void *cif_devm_kzalloc(struct device *dev, size_t size, gfp_t gfp);



__inline static void *dev_get_drvdata(struct device const *dev)
{
  

  return dev->driver_data;
}



__inline static void dev_set_drvdata(struct device *dev, void *data)
{
  

  dev->driver_data = data;
  

  return;
}



void _dev_err(struct device const *, char const * , ...);



void _dev_info(struct device const *, char const * , ...);



__inline static struct file *get_file(struct file *f)
{
  

  atomic_long_inc(& f->f_count);
  

  return f;
}



__inline static void *lowmem_page_address(struct page const *page)
{
  

  return (void *)((unsigned long)((unsigned long long)(((long)page - (long)vmemmap_base) / 64L) << 12) + page_offset_base);
}



__inline static struct page *sg_page(struct scatterlist *sg)
{
  

  if ((long)((sg->page_link & 1UL) != 0UL) != 0L) {
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ;
  }
  

  return (struct page *)(sg->page_link & 18446744073709551612UL);
}



__inline static void *sg_virt(struct scatterlist *sg)
{
  

  
  

  
  

  ;
  

  return lowmem_page_address((struct page const *)sg_page(sg)) + sg->offset;
}



void debug_dma_map_sg(struct device *, struct scatterlist *, int, int, int);



void debug_dma_unmap_sg(struct device *, struct scatterlist *, int, int);



__inline static int valid_dma_direction(int dma_direction)
{
  

  return (unsigned int)dma_direction <= 2U;
}



__inline static bool dma_is_direct(struct dma_map_ops const *ops)
{
  

  return (_Bool)((long)(ops == (struct dma_map_ops const *)0) != 0L);
}



int dma_direct_map_sg(struct device *, struct scatterlist *, int, enum dma_data_direction, unsigned long);



void dma_direct_unmap_sg(struct device *, struct scatterlist *, int, enum dma_data_direction, unsigned long);



extern struct dma_map_ops const *dma_ops;



__inline static struct dma_map_ops const *get_arch_dma_ops(struct bus_type *bus)
{
  

  return dma_ops;
}



__inline static struct dma_map_ops const *get_dma_ops(struct device *dev)
{
  struct bus_type *tmp;
  

  if (dev != (struct device *)0 && dev->dma_ops != (struct dma_map_ops const *)0) 
    

    return dev->dma_ops;
  

  if (dev != (struct device *)0) 

                                 tmp = dev->bus; else 

                                                      tmp = (struct bus_type *)0;
  

  
  

  return get_arch_dma_ops(tmp);
}



__inline static int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg, int nents, enum dma_data_direction dir, unsigned long attrs)
{
  int ents;
  

  struct dma_map_ops const *ops = get_dma_ops(dev);
  

  
  

  if ((long)(valid_dma_direction((int)dir) == 0) != 0L) {
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ;
  }
  

  
  

  if ((int)dma_is_direct(ops) != 0) 

                                    ents = dma_direct_map_sg(dev,sg,nents,dir,attrs); else 
                                                                    

                                                                    ents = (*(ops->map_sg))(dev,sg,nents,dir,attrs);
  

  if ((long)(ents < 0) != 0L) {
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ;
  }
  

  debug_dma_map_sg(dev,sg,nents,ents,(int)dir);
  

  return ents;
}



__inline static void dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sg, int nents, enum dma_data_direction dir, unsigned long attrs)
{
  

  struct dma_map_ops const *ops = get_dma_ops(dev);
  

  
  

  if ((long)(valid_dma_direction((int)dir) == 0) != 0L) {
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ldv_inline_asm();
    

    ;
  }
  

  debug_dma_unmap_sg(dev,sg,nents,(int)dir);
  

  
  

  if ((int)dma_is_direct(ops) != 0) 

                                    dma_direct_unmap_sg(dev,sg,nents,dir,attrs);
  else 
    

    if (ops->unmap_sg != (void (*)(struct device *, struct scatterlist *, int , enum dma_data_direction , unsigned long ))0) 
      

      (*(ops->unmap_sg))(dev,sg,nents,dir,attrs);
  

  return;
}



void dma_free_attrs(struct device *, size_t, void *, dma_addr_t, unsigned long);



int dma_get_sgtable_attrs(struct device *, struct sg_table *, void *, dma_addr_t, size_t, unsigned long);



int dma_mmap_attrs(struct device *, struct vm_area_struct *, void *, dma_addr_t, size_t, unsigned long);



int dma_set_mask(struct device *, u64);



int dma_set_coherent_mask(struct device *, u64);



static void *dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flags);



__inline static void dma_free_coherent(struct device *dev, size_t size, void *cpu_addr, dma_addr_t dma_handle)
{
  

  dma_free_attrs(dev,size,cpu_addr,dma_handle,0UL);
  

  return;
}



__inline static int dma_set_mask_and_coherent(struct device *dev, u64 mask)
{
  

  int rc = dma_set_mask(dev,mask);
  

  if (rc == 0) 

               dma_set_coherent_mask(dev,mask);
  

  return rc;
}



__inline static void get_dma_buf(struct dma_buf *dmabuf)
{
  

  get_file(dmabuf->file);
  

  return;
}



struct dma_buf_attachment *dma_buf_attach(struct dma_buf *, struct device *);



void dma_buf_detach(struct dma_buf *, struct dma_buf_attachment *);



struct dma_buf *dma_buf_export(struct dma_buf_export_info const *);



int dma_buf_fd(struct dma_buf *, int);



struct dma_buf *dma_buf_get(int);



void dma_buf_put(struct dma_buf *);



struct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *, enum dma_data_direction);



void dma_buf_unmap_attachment(struct dma_buf_attachment *, struct sg_table *, enum dma_data_direction);



int misc_register(struct miscdevice *);



void misc_deregister(struct miscdevice *);



int of_property_read_variable_u32_array(struct device_node const *, char const *, u32 *, size_t, size_t);



int of_property_read_string(struct device_node const *, char const *, char const **);



__inline static int of_property_read_u32_array(struct device_node const *np, char const *propname, u32 *out_values, size_t sz)
{
  

  int ret = of_property_read_variable_u32_array(np,propname,out_values,sz,0UL);
  

  if (ret >= 0) 

                return 0; else 

                               return ret;
}



__inline static int of_property_read_u32(struct device_node const *np, char const *propname, u32 *out_value)
{
  

  
  

  return of_property_read_u32_array(np,propname,out_value,1UL);
}



int __platform_driver_register(struct platform_driver *, struct module *);



void platform_driver_unregister(struct platform_driver *);



int of_platform_populate(struct device_node *, struct of_device_id const *, struct of_dev_auxdata const *, struct device *);



void of_platform_depopulate(struct device *);



unsigned long _copy_from_user(void *, void const *, unsigned long);



unsigned long _copy_to_user(void *, void const *, unsigned long);



__inline static unsigned long copy_from_user(void *to, void const *from, unsigned long n)
{
  

  
  

  if ((long)((int)check_copy_size((void const *)to,n,(_Bool)0) != 0) != 0L) 
    

    n = _copy_from_user(to,from,n);
  

  return n;
}



__inline static unsigned long copy_to_user(void *to, void const *from, unsigned long n)
{
  

  
  

  if ((long)((int)check_copy_size(from,n,(_Bool)1) != 0) != 0L) 

                                                                n = _copy_to_user(to,from,n);
  

  return n;
}



int __register_rpmsg_driver(struct rpmsg_driver *, struct module *);



void unregister_rpmsg_driver(struct rpmsg_driver *);



int rpmsg_send(struct rpmsg_endpoint *, void *, int);



static void cif_kfree(void const *ldv_func_arg1);



static void *kcalloc(size_t n, size_t size, gfp_t flags);



static void *kzalloc(size_t size, gfp_t flags);



static char const *domains[4U] = {"adsp", "mdsp", "sdsp", "cdsp"};


static void fastrpc_free_map(struct kref *ref)
{
  void *__mptr;
  struct fastrpc_map *map;
  

  __mptr = (void *)ref;
  

  
  

  map = ((struct fastrpc_map *)(__mptr + 18446744073709551528U));
  

  if (map->table != (struct sg_table *)0) {
    

    dma_buf_unmap_attachment(map->attach,map->table,(enum dma_data_direction)DMA_BIDIRECTIONAL);
    

    dma_buf_detach(map->buf,map->attach);
    

    dma_buf_put(map->buf);
  }
  

  cif_kfree((void const *)map);
  

  return;
}



static void fastrpc_map_put(struct fastrpc_map *map)
{
  

  if (map != (struct fastrpc_map *)0) 

                                      kref_put(& map->refcount,& fastrpc_free_map);
  

  return;
}



static void fastrpc_map_get(struct fastrpc_map *map)
{
  

  if (map != (struct fastrpc_map *)0) 

                                      kref_get(& map->refcount);
  

  return;
}



static int fastrpc_map_find(struct fastrpc_user *fl, int fd, struct fastrpc_map **ppmap)
{
  void *__mptr;
  void *__mptr_0;
  

  struct fastrpc_map *map = (struct fastrpc_map *)0;
  

  mutex_lock_nested(& fl->mutex,0U);
  

  __mptr = (void *)fl->maps.next;
  

  
  

  map = ((struct fastrpc_map *)__mptr);
  

  goto ldv_37002;
  ldv_37001: 

  ;
  

  if (map->fd == fd) {
    

    fastrpc_map_get(map);
    

    *ppmap = map;
    

    mutex_unlock(& fl->mutex);
    

    return 0;
  }
  

  __mptr_0 = (void *)map->node.next;
  

  
  

  map = ((struct fastrpc_map *)__mptr_0);
  ldv_37002: 

  ;
  

  if (& map->node != & fl->maps) 

                                 goto ldv_37001;
  ldv_37003: 

  ;
  

  mutex_unlock(& fl->mutex);
  

  return -2;
}



static void fastrpc_buf_free(struct fastrpc_buf *buf)
{
  

  dma_free_coherent(buf->dev,(unsigned long)buf->size,buf->virt,buf->phys & 4294967295ULL);
  

  cif_kfree((void const *)buf);
  

  return;
}



static int fastrpc_buf_alloc(struct fastrpc_user *fl, struct device *dev, u64 size, struct fastrpc_buf **obuf)
{
  struct fastrpc_buf *buf;
  

  buf = (struct fastrpc_buf *)kzalloc(224UL,3264U);
  

  if (buf == (struct fastrpc_buf *)0) 

                                      return -12;
  

  INIT_LIST_HEAD(& buf->attachments);
  {
    struct lock_class_key __key;
    

    __mutex_init(& buf->lock,"&buf->lock",& __key);
  }
  

  buf->fl = fl;
  

  buf->virt = (void *)0;
  

  buf->phys = 0ULL;
  

  buf->size = size;
  

  buf->dev = dev;
  

  buf->virt = dma_alloc_coherent(dev,(unsigned long)buf->size,& buf->phys,3264U);
  

  if (buf->virt == (void *)0) 

                              return -12;
  

  if (fl->sctx != (struct fastrpc_session_ctx *)0 && (fl->sctx)->sid != 0) 
    

    buf->phys += (unsigned long long)(fl->sctx)->sid << 32;
  

  *obuf = buf;
  

  return 0;
}



static void fastrpc_context_free(struct kref *ref)
{
  void *__mptr;
  struct fastrpc_invoke_ctx *ctx;
  struct fastrpc_channel_ctx *cctx;
  int i;
  

  __mptr = (void *)ref;
  

  
  

  ctx = ((struct fastrpc_invoke_ctx *)(__mptr + 18446744073709551568U));
  

  cctx = ctx->cctx;
  

  i = 0;
  

  goto ldv_37027;
  ldv_37026: 

  ;
  

  fastrpc_map_put(*(ctx->maps + i));
  

  i ++;
  ldv_37027: 

  ;
  

  if (ctx->nscalars > i) 

                         goto ldv_37026;
  ldv_37028: 

  ;
  

  if (ctx->buf != (struct fastrpc_buf *)0) 

                                           fastrpc_buf_free(ctx->buf);
  

  spin_lock(& cctx->lock);
  

  idr_remove(& cctx->ctx_idr,(unsigned long)(ctx->ctxid >> 4));
  

  spin_unlock(& cctx->lock);
  

  cif_kfree((void const *)ctx->maps);
  

  cif_kfree((void const *)ctx);
  

  return;
}



static void fastrpc_context_get(struct fastrpc_invoke_ctx *ctx)
{
  

  kref_get(& ctx->refcount);
  

  return;
}



static void fastrpc_context_put(struct fastrpc_invoke_ctx *ctx)
{
  

  kref_put(& ctx->refcount,& fastrpc_context_free);
  

  return;
}



static struct fastrpc_invoke_ctx *fastrpc_context_alloc(struct fastrpc_user *user, u32 kernel, u32 sc, struct fastrpc_invoke_args *args)
{
  int ret;
  

  struct fastrpc_channel_ctx *cctx = user->cctx;
  

  struct fastrpc_invoke_ctx *ctx = (struct fastrpc_invoke_ctx *)0;
  

  ctx = (struct fastrpc_invoke_ctx *)kzalloc(256UL,3264U);
  

  if (ctx == (struct fastrpc_invoke_ctx *)0) {
    

    
    

    return (struct fastrpc_invoke_ctx *)ERR_PTR(-12L);
  }
  

  INIT_LIST_HEAD(& ctx->node);
  

  ctx->fl = user;
  

  ctx->nscalars = (int)(((((sc >> 16) & 255U) + ((sc >> 8) & 255U)) + ((sc >> 4) & 15U)) + (sc & 15U));
  

  ctx->nbufs = (int)(((sc >> 16) & 255U) + ((sc >> 8) & 255U));
  

  if (ctx->nscalars != 0) {
    

    ctx->maps = (struct fastrpc_map **)kcalloc((unsigned long)ctx->nscalars,8UL,3264U);
    

    if (ctx->maps == (struct fastrpc_map **)0) {
      

      cif_kfree((void const *)ctx);
      

      
      

      return (struct fastrpc_invoke_ctx *)ERR_PTR(-12L);
    }
    

    ctx->args = args;
  }
  

  ctx->sc = sc;
  

  ctx->retval = -1;
  

  
  

  ctx->pid = get_current()->pid;
  

  ctx->tgid = user->tgid;
  

  ctx->cctx = cctx;
  

  __init_completion(& ctx->work);
  

  spin_lock(& user->lock);
  

  list_add_tail(& ctx->node,& user->pending);
  

  spin_unlock(& user->lock);
  

  spin_lock(& cctx->lock);
  

  ret = idr_alloc_cyclic(& cctx->ctx_idr,(void *)ctx,1,256,2592U);
  

  if (ret < 0) {
    

    spin_unlock(& cctx->lock);
    

    goto err_idr;
  }
  

  ctx->ctxid = (unsigned long long)(ret << 4);
  

  spin_unlock(& cctx->lock);
  

  kref_init(& ctx->refcount);
  

  return ctx;
  err_idr: 

  ;
  

  spin_lock(& user->lock);
  

  list_del(& ctx->node);
  

  spin_unlock(& user->lock);
  

  cif_kfree((void const *)ctx->maps);
  

  cif_kfree((void const *)ctx);
  

  
  

  return (struct fastrpc_invoke_ctx *)ERR_PTR((long)ret);
}



static struct sg_table *fastrpc_map_dma_buf(struct dma_buf_attachment *attachment, enum dma_data_direction dir)
{
  struct sg_table *table;
  

  struct fastrpc_dma_buf_attachment *a = (struct fastrpc_dma_buf_attachment *)attachment->priv;
  

  table = & a->sgt;
  

  
  

  if (dma_map_sg_attrs(attachment->dev,table->sgl,(int)table->nents,dir,
                         0UL) == 0) {
    

    
    

    return (struct sg_table *)ERR_PTR(-12L);
  }
  

  return table;
}



static void fastrpc_unmap_dma_buf(struct dma_buf_attachment *attach, struct sg_table *table, enum dma_data_direction dir)
{
  

  dma_unmap_sg_attrs(attach->dev,table->sgl,(int)table->nents,dir,0UL);
  

  return;
}



static void fastrpc_release(struct dma_buf *dmabuf)
{
  

  struct fastrpc_buf *buffer = (struct fastrpc_buf *)dmabuf->priv;
  

  fastrpc_buf_free(buffer);
  

  return;
}



static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf, struct dma_buf_attachment *attachment)
{
  struct fastrpc_dma_buf_attachment *a;
  int ret;
  

  struct fastrpc_buf *buffer = (struct fastrpc_buf *)dmabuf->priv;
  

  a = (struct fastrpc_dma_buf_attachment *)kzalloc(40UL,3264U);
  

  if (a == (struct fastrpc_dma_buf_attachment *)0) 

                                                   return -12;
  

  ret = dma_get_sgtable_attrs(buffer->dev,& a->sgt,buffer->virt,buffer->phys & 4294967295ULL,(unsigned long)buffer->size,0UL);
  

  if (ret < 0) {
    

    _dev_err((struct device const *)buffer->dev,"failed to get scatterlist from DMA API\n");
    

    return -22;
  }
  

  a->dev = attachment->dev;
  

  INIT_LIST_HEAD(& a->node);
  

  attachment->priv = (void *)a;
  

  mutex_lock_nested(& buffer->lock,0U);
  

  list_add(& a->node,& buffer->attachments);
  

  mutex_unlock(& buffer->lock);
  

  return 0;
}



static void fastrpc_dma_buf_detatch(struct dma_buf *dmabuf, struct dma_buf_attachment *attachment)
{
  

  struct fastrpc_dma_buf_attachment *a = (struct fastrpc_dma_buf_attachment *)attachment->priv;
  

  struct fastrpc_buf *buffer = (struct fastrpc_buf *)dmabuf->priv;
  

  mutex_lock_nested(& buffer->lock,0U);
  

  list_del(& a->node);
  

  mutex_unlock(& buffer->lock);
  

  cif_kfree((void const *)a);
  

  return;
}



static void *fastrpc_kmap(struct dma_buf *dmabuf, unsigned long pgnum)
{
  void *tmp;
  

  struct fastrpc_buf *buf = (struct fastrpc_buf *)dmabuf->priv;
  

  if (buf->virt != (void *)0) 

                              tmp = buf->virt + pgnum * 4096UL; else 
                                                                  

                                                                  tmp = (void *)0;
  

  return tmp;
}



static void *fastrpc_vmap(struct dma_buf *dmabuf)
{
  

  struct fastrpc_buf *buf = (struct fastrpc_buf *)dmabuf->priv;
  

  return buf->virt;
}



static int fastrpc_mmap(struct dma_buf *dmabuf, struct vm_area_struct *vma)
{
  

  struct fastrpc_buf *buf = (struct fastrpc_buf *)dmabuf->priv;
  

  size_t size = vma->vm_end - vma->vm_start;
  

  
  

  return dma_mmap_attrs(buf->dev,vma,buf->virt,buf->phys & 4294967295ULL,size,
                     0UL);
}



static struct dma_buf_ops const fastrpc_dma_buf_ops = {.attach = & fastrpc_dma_buf_attach, .detach = & fastrpc_dma_buf_detatch, .map_dma_buf = & fastrpc_map_dma_buf, .unmap_dma_buf = & fastrpc_unmap_dma_buf, .release = & fastrpc_release, .map = & fastrpc_kmap, .mmap = & fastrpc_mmap, .vmap = & fastrpc_vmap};


static int fastrpc_map_create(struct fastrpc_user *fl, int fd, u64 len, struct fastrpc_map **ppmap)
{
  

  struct fastrpc_session_ctx *sess = fl->sctx;
  

  struct fastrpc_map *map = (struct fastrpc_map *)0;
  

  int err = 0;
  

  
  

  if (fastrpc_map_find(fl,fd,ppmap) == 0) 

                                          return 0;
  

  map = (struct fastrpc_map *)kzalloc(96UL,3264U);
  

  if (map == (struct fastrpc_map *)0) 

                                      return -12;
  

  INIT_LIST_HEAD(& map->node);
  

  map->fl = fl;
  

  map->fd = fd;
  

  map->buf = dma_buf_get(fd);
  

  
  

  if ((int)IS_ERR((void const *)map->buf) != 0) {
    

    
    

    err = (int)PTR_ERR((void const *)map->buf);
    

    goto get_err;
  }
  

  map->attach = dma_buf_attach(map->buf,sess->dev);
  

  
  

  if ((int)IS_ERR((void const *)map->attach) != 0) {
    

    _dev_err((struct device const *)sess->dev,"Failed to attach dmabuf\n");
    

    
    

    err = (int)PTR_ERR((void const *)map->attach);
    

    goto attach_err;
  }
  

  map->table = dma_buf_map_attachment(map->attach,(enum dma_data_direction)DMA_BIDIRECTIONAL);
  

  
  

  if ((int)IS_ERR((void const *)map->table) != 0) {
    

    
    

    err = (int)PTR_ERR((void const *)map->table);
    

    goto map_err;
  }
  

  map->phys = ((map->table)->sgl)->dma_address;
  

  map->phys += (unsigned long long)(fl->sctx)->sid << 32;
  

  map->size = len;
  

  map->va = sg_virt((map->table)->sgl);
  

  map->len = len;
  

  kref_init(& map->refcount);
  

  spin_lock(& fl->lock);
  

  list_add_tail(& map->node,& fl->maps);
  

  spin_unlock(& fl->lock);
  

  *ppmap = map;
  

  return 0;
  map_err: 

  ;
  

  dma_buf_detach(map->buf,map->attach);
  attach_err: 

  ;
  

  dma_buf_put(map->buf);
  get_err: 

  ;
  

  cif_kfree((void const *)map);
  

  return err;
}



static int fastrpc_get_meta_size(struct fastrpc_invoke_ctx *ctx)
{
  

  int size = 0;
  

  size = (int)((unsigned long)ctx->nscalars * (unsigned long)40U + (unsigned long)384U);
  

  return size;
}



static u64 fastrpc_get_payload_size(struct fastrpc_invoke_ctx *ctx, int metalen)
{
  int i;
  

  u64 size = 0ULL;
  

  size = (unsigned long long)((metalen + 127) & -128);
  

  i = 0;
  

  goto ldv_37112;
  ldv_37111: 

  ;
  

  if ((unsigned int)(ctx->args + i)->fd + 1U <= 1U) {
    

    size = (size + 127ULL) & 18446744073709551488ULL;
    

    size = (ctx->args + i)->length + size;
  }
  

  i ++;
  ldv_37112: 

  ;
  

  if (ctx->nscalars > i) 

                         goto ldv_37111;
  ldv_37113: 

  ;
  

  return size;
}



static int fastrpc_create_maps(struct fastrpc_invoke_ctx *ctx)
{
  int i;
  int err;
  

  struct device *dev = ((ctx->fl)->sctx)->dev;
  

  i = 0;
  

  goto ldv_37122;
  ldv_37121: 

  ;
  

  if ((ctx->args + i)->reserved != 0U) 

                                       return -22;
  

  if ((unsigned int)(ctx->args + i)->fd + 1U <= 1U || (ctx->args + i)->length == 0ULL) 
    

    goto ldv_37120;
  

  err = fastrpc_map_create(ctx->fl,(ctx->args + i)->fd,(ctx->args + i)->length,ctx->maps + i);
  

  if (err != 0) {
    

    _dev_err((struct device const *)dev,"Error Creating map %d\n",err);
    

    return -22;
  }
  ldv_37120: 

  ;
  

  i ++;
  ldv_37122: 

  ;
  

  if (ctx->nscalars > i) 

                         goto ldv_37121;
  ldv_37123: 

  ;
  

  return 0;
}



static int fastrpc_get_args(u32 kernel, struct fastrpc_invoke_ctx *ctx)
{
  struct fastrpc_remote_arg *rpra;
  struct fastrpc_invoke_buf *list;
  struct fastrpc_phy_page *pages;
  int inbufs;
  int i;
  u64 rlen;
  u64 pkt_size;
  uintptr_t args;
  int metalen;
  

  struct device *dev = ((ctx->fl)->sctx)->dev;
  

  int err = 0;
  

  inbufs = (int)(ctx->sc >> 16) & 255;
  

  metalen = fastrpc_get_meta_size(ctx);
  

  pkt_size = fastrpc_get_payload_size(ctx,metalen);
  

  err = fastrpc_create_maps(ctx);
  

  if (err != 0) 

                return err;
  

  ctx->msg_sz = pkt_size;
  

  err = fastrpc_buf_alloc(ctx->fl,dev,pkt_size,& ctx->buf);
  

  if (err != 0) 

                return err;
  

  rpra = (struct fastrpc_remote_arg *)(ctx->buf)->virt;
  

  list = (struct fastrpc_invoke_buf *)((ctx->buf)->virt + (unsigned long)ctx->nscalars * 16UL);
  

  pages = (struct fastrpc_phy_page *)((ctx->buf)->virt + (unsigned long)ctx->nscalars * 24UL);
  

  args = (unsigned long)(ctx->buf)->virt + (unsigned long)metalen;
  

  rlen = pkt_size - (unsigned long long)metalen;
  

  ctx->rpra = rpra;
  

  i = 0;
  

  goto ldv_37147;
  ldv_37146: 

  ;
  {
    unsigned long __y;
    

    u64 len = (ctx->args + i)->length;
    

    (rpra + i)->pv = 0ULL;
    

    (rpra + i)->len = len;
    

    (list + i)->num = (unsigned int)(len != 0ULL);
    

    (list + i)->pgidx = (unsigned int)i;
    

    if (len == 0ULL) 

                     goto ldv_37140;
    

    __y = 4096UL;
    

    
    

    (pages + i)->size = (((((unsigned long long)__y + len) + 18446744073709551615ULL) / (unsigned long long)__y) * (unsigned long long)__y);
    

    if (*(ctx->maps + i) != (struct fastrpc_map *)0) {
      

      (rpra + i)->pv = (ctx->args + i)->ptr;
      

      (pages + i)->addr = (*(ctx->maps + i))->phys;
    }
    else {
      

      rlen = (unsigned long long)(args - ((args + 127UL) & 18446744073709551488UL)) + rlen;
      

      args = (args + 127UL) & 18446744073709551488UL;
      

      if (rlen < len) 

                      goto bail;
      

      (rpra + i)->pv = (unsigned long long)args;
      

      (pages + i)->addr = (ctx->buf)->phys + (pkt_size - rlen);
      

      (pages + i)->addr &= 18446744073709547520ULL;
      

      args = (unsigned long)((unsigned long long)args + len);
      

      rlen -= len;
    }
    

    if (i < inbufs && *(ctx->maps + i) == (struct fastrpc_map *)0) {
      

      void *dst = (void *)(rpra + i)->pv;
      

      void *src = (void *)(ctx->args + i)->ptr;
      

      if (kernel == 0U) {
        

        
        

        if (copy_from_user(dst,(void const *)src,(unsigned long)len) != 0UL) {
          

          err = -14;
          

          goto bail;
        }
      }
      else 

           memcpy(dst,(void const *)src,(unsigned long)len);
    }
  }
  ldv_37140: 

  ;
  

  i ++;
  ldv_37147: 

  ;
  

  if (ctx->nbufs > i) 

                      goto ldv_37146;
  ldv_37148: 

  ;
  

  i = ctx->nbufs;
  

  goto ldv_37150;
  ldv_37149: 

  ;
  

  (rpra + i)->pv = (ctx->args + i)->ptr;
  

  (rpra + i)->len = (ctx->args + i)->length;
  

  (list + i)->num = (unsigned int)((ctx->args + i)->length != 0ULL);
  

  (list + i)->pgidx = (unsigned int)i;
  

  (pages + i)->addr = (*(ctx->maps + i))->phys;
  

  (pages + i)->size = (*(ctx->maps + i))->size;
  

  i ++;
  ldv_37150: 

  ;
  

  if (ctx->nscalars > i) 

                         goto ldv_37149;
  ldv_37151: 

  ;
  bail: 

  ;
  

  if (err != 0) 

                _dev_err((struct device const *)dev,"Error: get invoke args failed:%d\n",err);
  

  return err;
}



static int fastrpc_put_args(struct fastrpc_invoke_ctx *ctx, u32 kernel)
{
  int i;
  int inbufs;
  

  struct fastrpc_remote_arg *rpra = ctx->rpra;
  

  inbufs = (int)(ctx->sc >> 16) & 255;
  

  i = inbufs;
  

  goto ldv_37163;
  ldv_37162: 

  ;
  {
    

    void *src = (void *)(rpra + i)->pv;
    

    void *dst = (void *)(ctx->args + i)->ptr;
    

    u64 len = (rpra + i)->len;
    

    if (kernel == 0U) {
      

      
      

      if (copy_to_user(dst,(void const *)src,(unsigned long)len) != 0UL) 
        

        return -14;
    }
    else 

         memcpy(dst,(void const *)src,(unsigned long)len);
  }
  

  i ++;
  ldv_37163: 

  ;
  

  if (ctx->nbufs > i) 

                      goto ldv_37162;
  ldv_37164: 

  ;
  

  return 0;
}



static int fastrpc_invoke_send(struct fastrpc_session_ctx *sctx, struct fastrpc_invoke_ctx *ctx, u32 kernel, uint32_t handle)
{
  unsigned long __y;
  struct fastrpc_channel_ctx *cctx;
  

  struct fastrpc_user *fl = ctx->fl;
  

  struct fastrpc_msg *msg = & ctx->msg;
  

  cctx = fl->cctx;
  

  msg->pid = fl->tgid;
  

  
  

  msg->tid = get_current()->pid;
  

  if (kernel != 0U) 

                    msg->pid = 0;
  

  msg->ctx = ctx->ctxid | (unsigned long long)fl->pd;
  

  msg->handle = handle;
  

  msg->sc = ctx->sc;
  

  if (ctx->buf != (struct fastrpc_buf *)0) 

                                           msg->addr = (ctx->buf)->phys; else 
                                                                    

                                                                    msg->addr = 0ULL;
  

  __y = 4096UL;
  

  
  

  msg->size = ((((ctx->msg_sz + (unsigned long long)__y) + 18446744073709551615ULL) / (unsigned long long)__y) * (unsigned long long)__y);
  

  fastrpc_context_get(ctx);
  

  
  

  return rpmsg_send((cctx->rpdev)->ept,(void *)msg,40);
}



static int fastrpc_internal_invoke(struct fastrpc_user *fl, u32 kernel, u32 handle, u32 sc, struct fastrpc_invoke_args *args)
{
  

  struct fastrpc_invoke_ctx *ctx = (struct fastrpc_invoke_ctx *)0;
  

  int err = 0;
  

  if (fl->sctx == (struct fastrpc_session_ctx *)0) 

                                                   return -22;
  

  ctx = fastrpc_context_alloc(fl,kernel,sc,args);
  

  
  

  if ((int)IS_ERR((void const *)ctx) != 0) {
    

    
    

    return (int)PTR_ERR((void const *)ctx);
  }
  

  if (ctx->nscalars != 0) {
    

    err = fastrpc_get_args(kernel,ctx);
    

    if (err != 0) 

                  goto bail;
  }
  

  err = fastrpc_invoke_send(fl->sctx,ctx,kernel,handle);
  

  if (err != 0) 

                goto bail;
  

  err = wait_for_completion_interruptible(& ctx->work);
  

  if (err != 0) 

                goto bail;
  

  err = ctx->retval;
  

  if (err != 0) 

                goto bail;
  

  if (ctx->nscalars != 0) {
    

    err = fastrpc_put_args(ctx,kernel);
    

    if (err != 0) 

                  goto bail;
  }
  bail: 

  ;
  

  spin_lock(& fl->lock);
  

  list_del(& ctx->node);
  

  spin_unlock(& fl->lock);
  

  fastrpc_context_put(ctx);
  

  if (err != 0) {
    bool branch;
    

    struct _ddebug __UNIQUE_ID_ddebug392 = {.modname = "fastrpc", .function = "fastrpc_internal_invoke", .filename = "/home/debian/klever-inst/klever-work/native-scheduler/scheduler/jobs/a343d8d0-1f27-463a-bb34-4a208534dbf2/klever-core-work-dir/job/build base/Storage/home/druidos/development/clean/linux-stable/drivers/misc/fastrpc.c", .format = "Error: Invoke Failed %d\n", .lineno = (unsigned int)815U};
    

    branch = arch_static_branch(& __UNIQUE_ID_ddebug392.key.dd_key_false.key,(_Bool)0);
    

    
    

    if ((long)((long)((int)branch != 0)) != 0L) 

                                                __dynamic_dev_dbg(& __UNIQUE_ID_ddebug392,(struct device const *)(fl->sctx)->dev,"Error: Invoke Failed %d\n",err);
  }
  

  return err;
}



static int fastrpc_init_create_process(struct fastrpc_user *fl, char *argp)
{
  int __UNIQUE_ID___x393;
  int tmp_3;
  struct fastrpc_init_create init;
  struct fastrpc_invoke_args *args;
  struct fastrpc_phy_page pages[1U];
  int memlen;
  int err;
  struct __anonstruct_inbuf_463 inbuf;
  u32 sc;
  

  struct fastrpc_map *map = (struct fastrpc_map *)0;
  

  struct fastrpc_buf *imem = (struct fastrpc_buf *)0;
  

  args = (struct fastrpc_invoke_args *)kcalloc(6UL,24UL,3264U);
  

  if (args == (struct fastrpc_invoke_args *)0) 

                                               return -12;
  

  
  

  if (copy_from_user((void *)(& init),(void const *)argp,24UL) != 0UL) {
    

    err = -14;
    

    goto bail;
  }
  

  if (init.filelen > 2097152U) {
    

    err = -22;
    

    goto bail;
  }
  

  inbuf.pgid = fl->tgid;
  

  
  

  
  

  inbuf.namelen = (unsigned int)strlen((char const *)(& get_current()->comm)) + 1U;
  

  inbuf.filelen = init.filelen;
  

  inbuf.pageslen = 1U;
  

  inbuf.attrs = init.attrs;
  

  inbuf.siglen = init.siglen;
  

  fl->pd = 1;
  

  if (init.filelen != 0U && init.filefd != 0) {
    

    err = fastrpc_map_create(fl,init.filefd,(unsigned long long)init.filelen,& map);
    

    if (err != 0) 

                  goto bail;
  }
  {
    

    __UNIQUE_ID___x393 = 2097152;
    

    int __UNIQUE_ID___y394 = (int)init.filelen * 4;
    

    if (__UNIQUE_ID___x393 > __UNIQUE_ID___y394) 

                                                 tmp_3 = __UNIQUE_ID___x393; else 
                                                                    

                                                                    tmp_3 = __UNIQUE_ID___y394;
    

    
  }
  

  memlen = (tmp_3 + 1048575) & -1048576;
  

  err = fastrpc_buf_alloc(fl,(fl->sctx)->dev,(unsigned long long)memlen,& imem);
  

  if (err != 0) {
    

    fastrpc_map_put(map);
    

    goto bail;
  }
  

  fl->init_mem = imem;
  

  args->ptr = (unsigned long long)(& inbuf);
  

  args->length = 24ULL;
  

  args->fd = -1;
  

  
  

  (args + 1U)->ptr = (unsigned long long)(& get_current()->comm);
  

  (args + 1U)->length = (unsigned long long)inbuf.namelen;
  

  (args + 1U)->fd = -1;
  

  (args + 2U)->ptr = init.file;
  

  (args + 2U)->length = (unsigned long long)inbuf.filelen;
  

  (args + 2U)->fd = init.filefd;
  

  pages[0].addr = imem->phys;
  

  pages[0].size = imem->size;
  

  (args + 3U)->ptr = (unsigned long long)(& pages);
  

  (args + 3U)->length = 16ULL;
  

  (args + 3U)->fd = -1;
  

  (args + 4U)->ptr = (unsigned long long)(& inbuf.attrs);
  

  (args + 4U)->length = 4ULL;
  

  (args + 4U)->fd = -1;
  

  (args + 5U)->ptr = (unsigned long long)(& inbuf.siglen);
  

  (args + 5U)->length = 4ULL;
  

  (args + 5U)->fd = -1;
  

  sc = 100925440U;
  

  if (init.attrs != 0U) 

                        sc = 117833728U;
  

  err = fastrpc_internal_invoke(fl,1U,1U,sc,args);
  

  if (err != 0) {
    

    fastrpc_map_put(map);
    

    fastrpc_buf_free(imem);
  }
  bail: 

  ;
  

  cif_kfree((void const *)args);
  

  return err;
}



static struct fastrpc_session_ctx *fastrpc_session_alloc(struct fastrpc_channel_ctx *cctx)
{
  int i;
  

  struct fastrpc_session_ctx *session = (struct fastrpc_session_ctx *)0;
  

  spin_lock(& cctx->lock);
  

  i = 0;
  

  goto ldv_37228;
  ldv_37227: 

  ;
  

  if (! cctx->session[i].used && (int)cctx->session[i].valid != 0) {
    

    cctx->session[i].used = (_Bool)1;
    

    session = & cctx->session[i];
    

    goto ldv_37226;
  }
  

  i ++;
  ldv_37228: 

  ;
  

  if (cctx->sesscount > i) 

                           goto ldv_37227;
  ldv_37226: 

  ;
  

  spin_unlock(& cctx->lock);
  

  return session;
}



static void fastrpc_session_free(struct fastrpc_channel_ctx *cctx, struct fastrpc_session_ctx *session)
{
  

  spin_lock(& cctx->lock);
  

  session->used = (_Bool)0;
  

  spin_unlock(& cctx->lock);
  

  return;
}



static int fastrpc_release_current_dsp_process(struct fastrpc_user *fl)
{
  struct fastrpc_invoke_args args[1U];
  u32 sc;
  

  int tgid = 0;
  

  tgid = fl->tgid;
  

  args[0].ptr = (unsigned long long)(& tgid);
  

  args[0].length = 4ULL;
  

  args[0].fd = -1;
  

  args[0].reserved = 0U;
  

  sc = 16842752U;
  

  
  

  return fastrpc_internal_invoke(fl,1U,1U,sc,args);
}



static int fastrpc_device_release(struct inode *inode, struct file *file)
{
  void *__mptr_4;
  void *__mptr_1;
  void *__mptr_2;
  void *__mptr;
  void *__mptr_3;
  void *__mptr_0;
  struct fastrpc_invoke_ctx *ctx;
  struct fastrpc_invoke_ctx *n;
  struct fastrpc_map *map;
  struct fastrpc_map *m;
  

  struct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;
  

  struct fastrpc_channel_ctx *cctx = fl->cctx;
  

  fastrpc_release_current_dsp_process(fl);
  

  spin_lock(& cctx->lock);
  

  list_del(& fl->user);
  

  spin_unlock(& cctx->lock);
  

  if (fl->init_mem != (struct fastrpc_buf *)0) 

                                               fastrpc_buf_free(fl->init_mem);
  

  __mptr = (void *)fl->pending.next;
  

  
  

  ctx = ((struct fastrpc_invoke_ctx *)(__mptr + 18446744073709551560U));
  

  __mptr_0 = (void *)ctx->node.next;
  

  
  

  n = ((struct fastrpc_invoke_ctx *)(__mptr_0 + 18446744073709551560U));
  

  goto ldv_37265;
  ldv_37264: 

  ;
  

  list_del(& ctx->node);
  

  fastrpc_context_put(ctx);
  

  ctx = n;
  

  __mptr_1 = (void *)n->node.next;
  

  
  

  n = ((struct fastrpc_invoke_ctx *)(__mptr_1 + 18446744073709551560U));
  ldv_37265: 

  ;
  

  if (& ctx->node != & fl->pending) 

                                    goto ldv_37264;
  ldv_37266: 

  ;
  

  __mptr_2 = (void *)fl->maps.next;
  

  
  

  map = ((struct fastrpc_map *)__mptr_2);
  

  __mptr_3 = (void *)map->node.next;
  

  
  

  m = ((struct fastrpc_map *)__mptr_3);
  

  goto ldv_37283;
  ldv_37282: 

  ;
  

  list_del(& map->node);
  

  fastrpc_map_put(map);
  

  map = m;
  

  __mptr_4 = (void *)m->node.next;
  

  
  

  m = ((struct fastrpc_map *)__mptr_4);
  ldv_37283: 

  ;
  

  if (& map->node != & fl->maps) 

                                 goto ldv_37282;
  ldv_37284: 

  ;
  

  fastrpc_session_free(cctx,fl->sctx);
  

  mutex_destroy(& fl->mutex);
  

  cif_kfree((void const *)fl);
  

  file->private_data = (void *)0;
  

  return 0;
}



static int fastrpc_device_open(struct inode *inode, struct file *filp)
{
  void *__mptr;
  

  __mptr = filp->private_data;
  

  
  

  struct fastrpc_channel_ctx *cctx = ((struct fastrpc_channel_ctx *)(__mptr + 18446744073709551272U));
  

  struct fastrpc_user *fl = (struct fastrpc_user *)0;
  

  fl = (struct fastrpc_user *)kzalloc(312UL,3264U);
  

  if (fl == (struct fastrpc_user *)0) 

                                      return -12;
  

  filp->private_data = (void *)fl;
  

  spinlock_check(& fl->lock);
  {
    struct lock_class_key __key;
    

    __raw_spin_lock_init(& fl->lock.__anonCompField_spinlock_25.rlock,"&(&fl->lock)->rlock",& __key);
  }
  {
    struct lock_class_key __key_0;
    

    __mutex_init(& fl->mutex,"&fl->mutex",& __key_0);
  }
  

  INIT_LIST_HEAD(& fl->pending);
  

  INIT_LIST_HEAD(& fl->maps);
  

  INIT_LIST_HEAD(& fl->user);
  

  
  

  fl->tgid = get_current()->tgid;
  

  fl->cctx = cctx;
  

  fl->sctx = fastrpc_session_alloc(cctx);
  

  if (fl->sctx == (struct fastrpc_session_ctx *)0) {
    

    _dev_err((struct device const *)(& (cctx->rpdev)->dev),"No session available\n");
    

    mutex_destroy(& fl->mutex);
    

    cif_kfree((void const *)fl);
    

    return -16;
  }
  

  spin_lock(& cctx->lock);
  

  list_add_tail(& fl->user,& cctx->users);
  

  spin_unlock(& cctx->lock);
  

  return 0;
}



static int fastrpc_dmabuf_free(struct fastrpc_user *fl, char *argp)
{
  struct dma_buf *buf;
  int info;
  

  
  

  if (copy_from_user((void *)(& info),(void const *)argp,4UL) != 0UL) 
    

    return -14;
  

  buf = dma_buf_get(info);
  

  
  

  if ((int)IS_ERR_OR_NULL((void const *)buf) != 0) 

                                                   return -22;
  

  dma_buf_put(buf);
  

  dma_buf_put(buf);
  

  return 0;
}



static int fastrpc_dmabuf_alloc(struct fastrpc_user *fl, char *argp)
{
  struct fastrpc_alloc_dma_buf bp;
  int err;
  

  struct dma_buf_export_info exp_info = {.exp_name = "fastrpc", .owner = & __this_module};
  

  struct fastrpc_buf *buf = (struct fastrpc_buf *)0;
  

  
  

  if (copy_from_user((void *)(& bp),(void const *)argp,16UL) != 0UL) 
    

    return -14;
  

  err = fastrpc_buf_alloc(fl,(fl->sctx)->dev,bp.size,& buf);
  

  if (err != 0) 

                return err;
  

  exp_info.ops = & fastrpc_dma_buf_ops;
  

  exp_info.size = (unsigned long)bp.size;
  

  exp_info.flags = 2;
  

  exp_info.priv = (void *)buf;
  

  buf->dmabuf = dma_buf_export((struct dma_buf_export_info const *)(& exp_info));
  

  
  

  if ((int)IS_ERR((void const *)buf->dmabuf) != 0) {
    

    
    

    err = (int)PTR_ERR((void const *)buf->dmabuf);
    

    fastrpc_buf_free(buf);
    

    return err;
  }
  

  bp.fd = dma_buf_fd(buf->dmabuf,3);
  

  if (bp.fd < 0) {
    

    dma_buf_put(buf->dmabuf);
    

    return -22;
  }
  

  
  

  if (copy_to_user((void *)argp,(void const *)(& bp),16UL) != 0UL) {
    

    dma_buf_put(buf->dmabuf);
    

    return -14;
  }
  

  get_dma_buf(buf->dmabuf);
  

  return 0;
}



static int fastrpc_init_attach(struct fastrpc_user *fl)
{
  struct fastrpc_invoke_args args[1U];
  u32 sc;
  

  int tgid = fl->tgid;
  

  args[0].ptr = (unsigned long long)(& tgid);
  

  args[0].length = 4ULL;
  

  args[0].fd = -1;
  

  args[0].reserved = 0U;
  

  sc = 65536U;
  

  fl->pd = 0;
  

  
  

  return fastrpc_internal_invoke(fl,1U,1U,sc,args);
}



static int fastrpc_invoke(struct fastrpc_user *fl, char *argp)
{
  struct fastrpc_invoke inv;
  u32 nscalars;
  int err;
  

  struct fastrpc_invoke_args *args = (struct fastrpc_invoke_args *)0;
  

  
  

  if (copy_from_user((void *)(& inv),(void const *)argp,16UL) != 0UL) 
    

    return -14;
  

  nscalars = ((((inv.sc >> 16) & 255U) + ((inv.sc >> 8) & 255U)) + ((inv.sc >> 4) & 15U)) + (inv.sc & 15U);
  

  if (nscalars != 0U) {
    

    args = (struct fastrpc_invoke_args *)kcalloc((unsigned long)nscalars,24UL,3264U);
    

    if (args == (struct fastrpc_invoke_args *)0) 

                                                 return -12;
    

    
    

    if (copy_from_user((void *)args,(void const *)inv.args,
                       (unsigned long)nscalars * 24UL) != 0UL) {
      

      cif_kfree((void const *)args);
      

      return -14;
    }
  }
  

  err = fastrpc_internal_invoke(fl,0U,inv.handle,inv.sc,args);
  

  cif_kfree((void const *)args);
  

  return err;
}



static long fastrpc_device_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
{
  int err;
  

  struct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;
  

  char *argp = (char *)arg;
  

  switch (cmd) {
    case (unsigned int)(-1072672253): 

    ;
    

    err = fastrpc_invoke(fl,argp);
    

    goto ldv_37335;
    case (unsigned int)20996: 

    ;
    

    err = fastrpc_init_attach(fl);
    

    goto ldv_37335;
    case (unsigned int)(-1072147963): 

    ;
    

    err = fastrpc_init_create_process(fl,argp);
    

    goto ldv_37335;
    case (unsigned int)(-1073458686): 

    ;
    

    err = fastrpc_dmabuf_free(fl,argp);
    

    goto ldv_37335;
    case (unsigned int)(-1072672255): 

    ;
    

    err = fastrpc_dmabuf_alloc(fl,argp);
    

    goto ldv_37335;
    default: 

    ;
    

    err = -25;
    

    goto ldv_37335;
  }
  ldv_37335: 

  ;
  

  return (long)err;
}



static struct file_operations const fastrpc_fops = {.unlocked_ioctl = & fastrpc_device_ioctl, .compat_ioctl = & fastrpc_device_ioctl, .open = & fastrpc_device_open, .release = & fastrpc_device_release};


static int fastrpc_cb_probe(struct platform_device *pdev)
{
  struct fastrpc_channel_ctx *cctx;
  struct fastrpc_session_ctx *sess;
  int i;
  int rc;
  

  struct device *dev = & pdev->dev;
  

  int sessions = 0;
  

  cctx = (struct fastrpc_channel_ctx *)dev_get_drvdata((struct device const *)dev->parent);
  

  if (cctx == (struct fastrpc_channel_ctx *)0) 

                                               return -22;
  

  of_property_read_u32((struct device_node const *)dev->of_node,"qcom,nsessions",(u32 *)(& sessions));
  

  spin_lock(& cctx->lock);
  

  sess = & cctx->session[cctx->sesscount];
  

  sess->used = (_Bool)0;
  

  sess->valid = (_Bool)1;
  

  sess->dev = dev;
  

  dev_set_drvdata(dev,(void *)sess);
  

  
  

  if (of_property_read_u32((struct device_node const *)dev->of_node,"reg",
                             (u32 *)(& sess->sid)) != 0) 
    

    _dev_info((struct device const *)dev,"FastRPC Session ID not specified in DT\n");
  

  if (sessions > 0) {
    struct fastrpc_session_ctx *dup_sess;
    int tmp_1;
    

    i = 1;
    

    goto ldv_37354;
    ldv_37353: 

    ;
    

    tmp_1 = cctx->sesscount;
    

    (cctx->sesscount) ++;
    

    ;
    

    if (tmp_1 > 8) 

                   goto ldv_37352;
    

    dup_sess = & cctx->session[cctx->sesscount];
    

    memcpy((void *)dup_sess,(void const *)sess,16UL);
    

    i ++;
    ldv_37354: 

    ;
    

    if (i < sessions) 

                      goto ldv_37353;
    ldv_37352: 

    ;
  }
  

  (cctx->sesscount) ++;
  

  spin_unlock(& cctx->lock);
  

  rc = dma_set_mask(dev,4294967295ULL);
  

  if (rc != 0) {
    

    _dev_err((struct device const *)dev,"32-bit DMA enable failed\n");
    

    return rc;
  }
  

  return 0;
}



static int fastrpc_cb_remove(struct platform_device *pdev)
{
  int i;
  

  struct fastrpc_channel_ctx *cctx = dev_get_drvdata((struct device const *)pdev->dev.parent);
  

  struct fastrpc_session_ctx *sess = dev_get_drvdata((struct device const *)(& pdev->dev));
  

  spin_lock(& cctx->lock);
  

  i = 1;
  

  goto ldv_37362;
  ldv_37361: 

  ;
  

  if (cctx->session[i].sid == sess->sid) {
    

    cctx->session[i].valid = (_Bool)0;
    

    (cctx->sesscount) --;
  }
  

  i ++;
  ldv_37362: 

  ;
  

  if (i <= 8) 

              goto ldv_37361;
  ldv_37363: 

  ;
  

  spin_unlock(& cctx->lock);
  

  return 0;
}



static struct of_device_id const fastrpc_match_table[2U] = {{.compatible = {(char)'q', (char)'c', (char)'o', (char)'m', (char)',', (char)'f', (char)'a', (char)'s', (char)'t', (char)'r', (char)'p', (char)'c', (char)'-', (char)'c', (char)'o', (char)'m', (char)'p', (char)'u', (char)'t', (char)'e', (char)'-', (char)'c', (char)'b'}}};


static struct platform_driver fastrpc_cb_driver = {.probe = & fastrpc_cb_probe, .remove = & fastrpc_cb_remove, .driver = {.name = "qcom,fastrpc-cb", .suppress_bind_attrs = (_Bool)1, .of_match_table = (struct of_device_id const *)(& fastrpc_match_table)}};


static int fastrpc_rpmsg_probe(struct rpmsg_device *rpdev)
{
  struct fastrpc_channel_ctx *data;
  int i;
  int err;
  char const *domain;
  

  struct device *rdev = & rpdev->dev;
  

  int domain_id = -1;
  

  data = (struct fastrpc_channel_ctx *)cif_devm_kzalloc(rdev,424UL,3264U);
  

  if (data == (struct fastrpc_channel_ctx *)0) 

                                               return -12;
  

  err = of_property_read_string((struct device_node const *)rdev->of_node,"label",& domain);
  

  if (err != 0) {
    

    _dev_info((struct device const *)rdev,"FastRPC Domain not specified in DT\n");
    

    return err;
  }
  

  i = 0;
  

  goto ldv_37377;
  ldv_37376: 

  ;
  

  
  

  if (strcmp(domains[i],domain) == 0) {
    

    domain_id = i;
    

    goto ldv_37375;
  }
  

  i ++;
  ldv_37377: 

  ;
  

  if (i <= 3) 

              goto ldv_37376;
  ldv_37375: 

  ;
  

  if (domain_id < 0) {
    

    _dev_info((struct device const *)rdev,"FastRPC Invalid Domain ID %d\n",domain_id);
    

    return -22;
  }
  

  data->miscdev.minor = 255;
  

  data->miscdev.name = (char const *)cif_kasprintf(3264U,"fastrpc-%s",domains[domain_id]);
  

  data->miscdev.fops = & fastrpc_fops;
  

  err = misc_register(& data->miscdev);
  

  if (err != 0) 

                return err;
  

  dev_set_drvdata(& rpdev->dev,(void *)data);
  

  dma_set_mask_and_coherent(rdev,4294967295ULL);
  

  INIT_LIST_HEAD(& data->users);
  

  spinlock_check(& data->lock);
  {
    struct lock_class_key __key;
    

    __raw_spin_lock_init(& data->lock.__anonCompField_spinlock_25.rlock,"&(&data->lock)->rlock",& __key);
  }
  

  idr_init(& data->ctx_idr);
  

  data->domain_id = domain_id;
  

  data->rpdev = rpdev;
  

  
  

  return of_platform_populate(rdev->of_node,(struct of_device_id const *)0,
                             (struct of_dev_auxdata const *)0,rdev);
}



static void fastrpc_notify_users(struct fastrpc_user *user)
{
  void *__mptr_0;
  void *__mptr;
  struct fastrpc_invoke_ctx *ctx;
  

  spin_lock(& user->lock);
  

  __mptr = (void *)user->pending.next;
  

  
  

  ctx = ((struct fastrpc_invoke_ctx *)(__mptr + 18446744073709551560U));
  

  goto ldv_37394;
  ldv_37393: 

  ;
  

  complete(& ctx->work);
  

  __mptr_0 = (void *)ctx->node.next;
  

  
  

  ctx = ((struct fastrpc_invoke_ctx *)(__mptr_0 + 18446744073709551560U));
  ldv_37394: 

  ;
  

  if (& ctx->node != & user->pending) 

                                      goto ldv_37393;
  ldv_37395: 

  ;
  

  spin_unlock(& user->lock);
  

  return;
}



static void fastrpc_rpmsg_remove(struct rpmsg_device *rpdev)
{
  void *__mptr;
  void *__mptr_0;
  struct fastrpc_user *user;
  

  struct fastrpc_channel_ctx *cctx = dev_get_drvdata((struct device const *)(& rpdev->dev));
  

  spin_lock(& cctx->lock);
  

  __mptr = (void *)cctx->users.next;
  

  
  

  user = ((struct fastrpc_user *)__mptr);
  

  goto ldv_37412;
  ldv_37411: 

  ;
  

  fastrpc_notify_users(user);
  

  __mptr_0 = (void *)user->user.next;
  

  
  

  user = ((struct fastrpc_user *)__mptr_0);
  ldv_37412: 

  ;
  

  if (& user->user != & cctx->users) 

                                     goto ldv_37411;
  ldv_37413: 

  ;
  

  spin_unlock(& cctx->lock);
  

  misc_deregister(& cctx->miscdev);
  

  of_platform_depopulate(& rpdev->dev);
  

  cif_kfree((void const *)cctx);
  

  return;
}



static int fastrpc_rpmsg_callback(struct rpmsg_device *rpdev, void *data, int len, void *priv, u32 addr)
{
  struct fastrpc_invoke_ctx *ctx;
  unsigned long flags;
  unsigned long ctxid;
  

  struct fastrpc_channel_ctx *cctx = dev_get_drvdata((struct device const *)(& rpdev->dev));
  

  struct fastrpc_invoke_rsp *rsp = (struct fastrpc_invoke_rsp *)data;
  

  if ((unsigned int)len <= 15U) 

                                return -22;
  

  ctxid = (unsigned long)(rsp->ctx >> 4) & 255UL;
  {
    unsigned long __dummy;
    unsigned long __dummy2;
    
  }
  

  
  

  flags = _raw_spin_lock_irqsave(spinlock_check(& cctx->lock));
  

  ctx = (struct fastrpc_invoke_ctx *)idr_find((struct idr const *)(& cctx->ctx_idr),ctxid);
  

  spin_unlock_irqrestore(& cctx->lock,flags);
  

  if (ctx == (struct fastrpc_invoke_ctx *)0) {
    

    _dev_err((struct device const *)(& rpdev->dev),"No context ID matches response\n");
    

    return -2;
  }
  

  ctx->retval = rsp->retval;
  

  complete(& ctx->work);
  

  fastrpc_context_put(ctx);
  

  return 0;
}



static struct of_device_id const fastrpc_rpmsg_of_match[2U] = {{.compatible = {(char)'q', (char)'c', (char)'o', (char)'m', (char)',', (char)'f', (char)'a', (char)'s', (char)'t', (char)'r', (char)'p', (char)'c'}}};


struct of_device_id const __mod_of__fastrpc_rpmsg_of_match_device_table[2U];


static struct rpmsg_driver fastrpc_driver = {.drv = {.name = "qcom,fastrpc", .of_match_table = (struct of_device_id const *)(& fastrpc_rpmsg_of_match)}, .probe = & fastrpc_rpmsg_probe, .remove = & fastrpc_rpmsg_remove, .callback = & fastrpc_rpmsg_callback};


static int fastrpc_init(void)
{
  int ret;
  

  ret = __platform_driver_register(& fastrpc_cb_driver,& __this_module);
  

  if (ret < 0) {
    

    printk("\001");
    

    return ret;
  }
  

  ret = __register_rpmsg_driver(& fastrpc_driver,& __this_module);
  

  if (ret < 0) {
    

    printk("\001");
    

    platform_driver_unregister(& fastrpc_cb_driver);
    

    return ret;
  }
  

  return 0;
}



static void fastrpc_exit(void)
{
  

  platform_driver_unregister(& fastrpc_cb_driver);
  

  unregister_rpmsg_driver(& fastrpc_driver);
  

  return;
}



void emg_fastrpc_exit(void)
{
  

  fastrpc_exit();
  

  return;
}



int emg_fastrpc_init(void)
{
  

  
  

  return fastrpc_init();
}



static void *ERR_PTR(long error)
{
  

  
  

  return ldv_err_ptr(error);
}



static long PTR_ERR(void const *ptr)
{
  

  
  

  return ldv_ptr_err(ptr);
}



static bool IS_ERR(void const *ptr)
{
  long ret;
  

  ret = ldv_is_err(ptr);
  

  return (_Bool)(ret != 0L);
}



static bool IS_ERR_OR_NULL(void const *ptr)
{
  long ret;
  

  ret = ldv_is_err_or_null(ptr);
  

  return (_Bool)(ret != 0L);
}



static void *dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flags)
{
  

  ldv_check_alloc_flags(flags);
  

  
  

  return ldv_malloc_unknown_size();
}



static void *kcalloc(size_t n, size_t size, gfp_t flags)
{
  

  
  

  return ldv_kcalloc(n,size,flags);
}



static void *kzalloc(size_t size, gfp_t flags)
{
  

  
  

  return ldv_kzalloc(size,flags);
}



static void cif_kfree(void const *ldv_func_arg1)
{
  

  ldv_free((void *)ldv_func_arg1);
  

  return;
}



static void *cif_devm_kzalloc(struct device *dev, size_t size, gfp_t gfp)
{
  

  void *res = ldv_calloc_unknown_size();
  

  return res;
}



static char *cif_kasprintf(gfp_t ldv_func_arg1, char const *ldv_func_arg2 , ...)
{
  __builtin_va_list ldv_func_arg3;
  

  void *res = ldv_malloc_unknown_size();
  

  

  __builtin_va_start(ldv_func_arg3,ldv_func_arg2);
  

  ldv_after_alloc(res);
  

  return (char *)res;
}



void ldv_atomic_add(int i, atomic_t *v)
{
  

  v->counter += i;
  

  return;
}



void ldv_atomic_sub(int i, atomic_t *v)
{
  

  v->counter -= i;
  

  return;
}



int ldv_atomic_sub_and_test(int i, atomic_t *v)
{
  

  v->counter -= i;
  

  if (v->counter != 0) 

                       return 0;
  

  return 1;
}



void ldv_atomic_inc(atomic_t *v)
{
  

  (v->counter) ++;
  

  return;
}



void ldv_atomic_dec(atomic_t *v)
{
  

  (v->counter) --;
  

  return;
}



int ldv_atomic_dec_and_test(atomic_t *v)
{
  

  (v->counter) --;
  

  if (v->counter != 0) 

                       return 0;
  

  return 1;
}



int ldv_atomic_inc_and_test(atomic_t *v)
{
  

  (v->counter) ++;
  

  if (v->counter != 0) 

                       return 0;
  

  return 1;
}



int ldv_atomic_add_return(int i, atomic_t *v)
{
  

  v->counter += i;
  

  return v->counter;
}



int ldv_atomic_add_negative(int i, atomic_t *v)
{
  

  v->counter += i;
  

  return v->counter < 0;
}



int ldv_atomic_inc_short(short *v)
{
  

  *v = (short)((unsigned int)*v + 1U);
  

  return (int)*v;
}



void *ldv_dev_get_drvdata(struct device const *dev);



int ldv_dev_set_drvdata(struct device *dev, void *data);



void *ldv_xmalloc(size_t size);



void *ldv_xzalloc(size_t size);



struct ldv_list_element global_list = {.data = (void *)0, .next = (struct ldv_list_element *)0};


__inline static ldv_list_ptr ldv_list_create(void *data)
{
  

  ldv_list_ptr list = (struct ldv_list_element *)0;
  

  list = (ldv_list_ptr)ldv_xmalloc(16UL);
  

  list->data = data;
  

  list->next = (struct ldv_list_element *)0;
  

  return list;
}



__inline static void ldv_save_pointer(void *data)
{
  ldv_list_ptr element;
  ldv_list_ptr cached;
  

  if (global_list.data == (void *)0) {
    

    element = & global_list;
    

    element->data = data;
  }
  else {
    

    element = ldv_list_create(data);
    

    cached = global_list.next;
    

    global_list.next = element;
    

    element->next = cached;
  }
  

  return;
}



void *ldv_dev_get_drvdata(struct device const *dev)
{
  

  if (dev != (struct device const *)0 && dev->p != (struct device_private *)0) 
    

    return (dev->p)->driver_data;
  

  return (void *)0;
}



int ldv_dev_set_drvdata(struct device *dev, void *data)
{
  

  dev->p = (struct device_private *)ldv_xzalloc(8UL);
  

  ldv_save_pointer((void *)dev->p);
  

  (dev->p)->driver_data = data;
  

  return 0;
}



void *ldv_zalloc(size_t size);



struct spi_controller *ldv_spi_alloc_master(struct device *host, unsigned int size)
{
  struct spi_controller *master;
  

  master = (struct spi_controller *)ldv_zalloc((unsigned long)size + 2688UL);
  

  if (master == (struct spi_controller *)0) 

                                            return (struct spi_controller *)0;
  

  ldv_dev_set_drvdata(& master->dev,(void *)(master + 1U));
  

  return master;
}



void __VERIFIER_assume(int);



long ldv_is_err(void const *ptr)
{
  

  return (long)((unsigned long)ptr > 4294967295UL);
}



void *ldv_err_ptr(long error)
{
  

  __VERIFIER_assume(error < 0L);
  

  return (void *)(4294967295L - error);
}



long ldv_ptr_err(void const *ptr)
{
  

  __VERIFIER_assume((unsigned long)ptr > 4294967295UL);
  

  return (long)(4294967295UL - (unsigned long)ptr);
}



long ldv_is_err_or_null(void const *ptr)
{
  int tmp_0;
  

  if (ptr == (void const *)0) 

                              tmp_0 = 1;
  else {
    

    
    

    if (ldv_is_err(ptr) != 0L) 

                               tmp_0 = 1; else 

                                               tmp_0 = 0;
  }
  

  return (long)tmp_0;
}



void ldv_panic(void);



void ldv_panic(void)
{
  

  __VERIFIER_assume(0);
  

  return;
}



void ldv_switch_to_interrupt_context(void);



void ldv_switch_to_process_context(void);



bool ldv_in_interrupt_context(void);



int ldv_post_init(int init_ret_val);



int ldv_post_probe(int probe_ret_val);



void ldv_check_return_value_probe(int);



int ldv_filter_err_code(int ret_val);



static bool __ldv_in_interrupt_context = (_Bool)0;


void ldv_switch_to_interrupt_context(void)
{
  

  __ldv_in_interrupt_context = (_Bool)1;
  

  return;
}



void ldv_switch_to_process_context(void)
{
  

  __ldv_in_interrupt_context = (_Bool)0;
  

  return;
}



bool ldv_in_interrupt_context(void)
{
  

  return __ldv_in_interrupt_context;
}



static int ldv_filter_positive_int(int val)
{
  

  __VERIFIER_assume(val <= 0);
  

  return val;
}



int ldv_post_init(int init_ret_val)
{
  

  
  

  return ldv_filter_positive_int(init_ret_val);
}



int ldv_post_probe(int probe_ret_val)
{
  

  ldv_check_return_value_probe(probe_ret_val);
  

  
  

  return ldv_filter_positive_int(probe_ret_val);
}



int ldv_filter_err_code(int ret_val)
{
  

  
  

  return ldv_filter_positive_int(ret_val);
}



void ldv_after_alloc(void *res)
{
  

  return;
}



struct fb_info *ldv_framebuffer_alloc(size_t size, struct device *dev)
{
  

  void *res = ldv_zalloc(size + 1568UL);
  

  struct fb_info *info = (struct fb_info *)res;
  

  ldv_after_alloc(res);
  

  if (res == (void *)0) 

                        return (struct fb_info *)0;
  

  if (size != 0UL) 

                   info->par = res + 1568U;
  

  return info;
}



void *ldv_kmalloc(size_t size, gfp_t flags);



void *ldv_kmalloc_array(size_t n, size_t size, gfp_t flags);



void *ldv_malloc(size_t size);



void *ldv_calloc(size_t nmemb, size_t size);



void *ldv_kmalloc(size_t size, gfp_t flags)
{
  void *res;
  

  ldv_check_alloc_flags(flags);
  

  res = ldv_malloc(size);
  

  ldv_after_alloc(res);
  

  return res;
}



void *ldv_kcalloc(size_t n, size_t size, gfp_t flags)
{
  void *res;
  

  ldv_check_alloc_flags(flags);
  

  res = ldv_calloc(n,size);
  

  ldv_after_alloc(res);
  

  return res;
}



void *ldv_kzalloc(size_t size, gfp_t flags)
{
  void *res;
  

  ldv_check_alloc_flags(flags);
  

  res = ldv_zalloc(size);
  

  ldv_after_alloc(res);
  

  return res;
}



void *ldv_kmalloc_array(size_t n, size_t size, gfp_t flags)
{
  void *res;
  

  ldv_check_alloc_flags(flags);
  

  res = ldv_malloc(n * size);
  

  ldv_after_alloc(res);
  

  return res;
}



void *ldv_zalloc_unknown_size(void);



void *ldv_reference_malloc(size_t size);



void *ldv_reference_calloc(size_t nmemb, size_t size);



void *ldv_reference_zalloc(size_t size);



void ldv_reference_free(void *s);



void *ldv_reference_xmalloc(size_t size);



void *ldv_reference_xzalloc(size_t size);



void *ldv_reference_malloc_unknown_size(void);



void *ldv_reference_calloc_unknown_size(void);



void *ldv_reference_zalloc_unknown_size(void);



void *ldv_xmalloc_unknown_size(size_t size);



void *ldv_reference_xmalloc_unknown_size(size_t size);



void *ldv_malloc(size_t size)
{
  void *res;
  

  res = ldv_reference_malloc(size);
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void *ldv_calloc(size_t nmemb, size_t size)
{
  void *res;
  

  res = ldv_reference_calloc(nmemb,size);
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void *ldv_zalloc(size_t size)
{
  void *res;
  

  res = ldv_reference_zalloc(size);
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void ldv_free(void *s)
{
  

  ldv_reference_free(s);
  

  return;
}



void *ldv_xmalloc(size_t size)
{
  void *res;
  

  res = ldv_reference_xmalloc(size);
  

  
  

  __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  

  return res;
}



void *ldv_xzalloc(size_t size)
{
  void *res;
  

  res = ldv_reference_xzalloc(size);
  

  
  

  __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  

  return res;
}



void *ldv_malloc_unknown_size(void)
{
  void *res;
  

  res = ldv_reference_malloc_unknown_size();
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void *ldv_calloc_unknown_size(void)
{
  void *res;
  

  res = ldv_reference_calloc_unknown_size();
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void *ldv_zalloc_unknown_size(void)
{
  void *res;
  

  res = ldv_reference_zalloc_unknown_size();
  

  if (res != (void *)0) {
    

    
    

    __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  }
  

  return res;
}



void *ldv_xmalloc_unknown_size(size_t size)
{
  void *res;
  

  res = ldv_reference_xmalloc_unknown_size(size);
  

  
  

  __VERIFIER_assume(ldv_is_err((void const *)res) == 0L);
  

  return res;
}



void __VERIFIER_error(void);



void ldv_assert(int expr);



void ldv_error(void);



void ldv_assert(int expr)
{
  

  if (expr == 0) 

                 __VERIFIER_error();
  

  return;
}



void ldv_error(void)
{
  

  __VERIFIER_error();
  

  return;
}

/* compiler builtin: 
   long __builtin_expect(long exp, long c);   */


long __builtin_expect(long exp, long c)
{
  

  return exp;
}



void __builtin_trap(void)
{
  

  __VERIFIER_error();
  

  return;
}



int ldv_undef_int(void);



int ldv_undef_long(void);



unsigned int ldv_undef_uint(void);



unsigned long ldv_undef_ulong(void);



unsigned long long ldv_undef_ulonglong(void);



void *ldv_undef_ptr(void);



int ldv_undef_int_positive(void);



int ldv_undef_int_negative(void);



int ldv_undef_int_nonpositive(void);



void *ldv_undef_ptr_non_null(void);



int __VERIFIER_nondet_int(void);



long __VERIFIER_nondet_long(void);



unsigned int __VERIFIER_nondet_uint(void);



unsigned long __VERIFIER_nondet_ulong(void);



unsigned long long __VERIFIER_nondet_ulonglong(void);



void *__VERIFIER_nondet_pointer(void);



int ldv_undef_int(void)
{
  

  
  

  return __VERIFIER_nondet_int();
}



int ldv_undef_long(void)
{
  

  
  

  return (int)__VERIFIER_nondet_long();
}



unsigned int ldv_undef_uint(void)
{
  

  
  

  return __VERIFIER_nondet_uint();
}



void *ldv_undef_ptr(void)
{
  

  
  

  return __VERIFIER_nondet_pointer();
}



unsigned long ldv_undef_ulong(void)
{
  

  
  

  return __VERIFIER_nondet_ulong();
}



unsigned long long ldv_undef_ulonglong(void)
{
  

  
  

  return __VERIFIER_nondet_ulonglong();
}



int ldv_undef_int_positive(void)
{
  

  int ret = ldv_undef_int();
  

  __VERIFIER_assume(ret > 0);
  

  return ret;
}



int ldv_undef_int_negative(void)
{
  

  int ret = ldv_undef_int();
  

  __VERIFIER_assume(ret < 0);
  

  return ret;
}



int ldv_undef_int_nonpositive(void)
{
  

  int ret = ldv_undef_int();
  

  __VERIFIER_assume(ret <= 0);
  

  return ret;
}



void *ldv_undef_ptr_non_null(void)
{
  

  void *ret = ldv_undef_ptr();
  

  __VERIFIER_assume(ret != (void *)0);
  

  return ret;
}



void *external_allocated_data(void);



void *ldv_reference_realloc(void *ptr, size_t size);



void *malloc(size_t);



void *calloc(size_t, size_t);



void free(void *);



void *ldv_reference_malloc(size_t size)
{
  void *res;
  

  
  

  if (ldv_undef_int() != 0) {
    

    res = malloc(size);
    

    __VERIFIER_assume(res != (void *)0);
    

    return res;
  }
  else 

       return (void *)0;
}



void *ldv_reference_calloc(size_t nmemb, size_t size)
{
  

  
  

  return calloc(nmemb,size);
}



void *ldv_reference_zalloc(size_t size)
{
  

  
  

  return calloc(1UL,size);
}



void ldv_reference_free(void *s)
{
  

  free(s);
  

  return;
}



void *ldv_reference_realloc(void *ptr, size_t size)
{
  void *res;
  

  if (ptr != (void *)0 && size == 0UL) {
    

    free(ptr);
    

    return (void *)0;
  }
  

  if (ptr == (void *)0) {
    

    res = malloc(size);
    

    return res;
  }
  

  
  

  if (ldv_undef_int() != 0) {
    

    res = malloc(size);
    

    __VERIFIER_assume(res != (void *)0);
    

    memcpy(res,(void const *)ptr,size);
    

    free(ptr);
    

    return res;
  }
  else 

       return (void *)0;
}



void *ldv_reference_xmalloc(size_t size)
{
  void *res;
  

  res = malloc(size);
  

  __VERIFIER_assume(res != (void *)0);
  

  return res;
}



void *ldv_reference_xzalloc(size_t size)
{
  void *res;
  

  res = calloc(1UL,size);
  

  __VERIFIER_assume(res != (void *)0);
  

  return res;
}



void *ldv_reference_malloc_unknown_size(void)
{
  void *res;
  

  
  

  if (ldv_undef_int() != 0) {
    

    res = external_allocated_data();
    

    __VERIFIER_assume(res != (void *)0);
    

    return res;
  }
  else 

       return (void *)0;
}



void *ldv_reference_calloc_unknown_size(void)
{
  void *res;
  

  
  

  if (ldv_undef_int() != 0) {
    

    res = external_allocated_data();
    

    memset(res,0,8UL);
    

    __VERIFIER_assume(res != (void *)0);
    

    return res;
  }
  else 

       return (void *)0;
}



void *ldv_reference_zalloc_unknown_size(void)
{
  

  
  

  return ldv_reference_calloc_unknown_size();
}



void *ldv_reference_xmalloc_unknown_size(size_t size)
{
  void *res;
  

  res = external_allocated_data();
  

  __VERIFIER_assume(res != (void *)0);
  

  return res;
}



void ldv_initialize(void);



void ldv_check_final_state(void);



void emg_insmod_1(void *arg0);



int main(void);
void emg_insmod_3(void *arg0)
{
  int emg_3_ret;
  struct rpmsg_device *rpdev;
  rpdev = ldv_xmalloc_unknown_size(0);
  

  emg_3_ret = fastrpc_rpmsg_probe(rpdev);
  

  emg_3_ret = ldv_post_init(emg_3_ret);
  

  
  

  if (ldv_undef_int() != 0) 

                            __VERIFIER_assume(emg_3_ret != 0);
  else {


    __VERIFIER_assume(emg_3_ret == 0);
    while(ldv_undef_int() != 0) {
	void *data = ldv_xmalloc_unknown_size(0);
	int len = ldv_undef_int();
	void *priv = ldv_xmalloc_unknown_size(0);
	u32 addr = ldv_undef_uint();
	fastrpc_rpmsg_callback(rpdev, data, len, priv, addr);
    }

    

    fastrpc_rpmsg_remove(rpdev);
  }
  

  return;
}

void emg_insmod_2(void *arg0)
{
  int emg_2_ret;
  struct platform_device *pdev;
  pdev = ldv_xmalloc_unknown_size(0);
  

  emg_2_ret = fastrpc_cb_probe(pdev);
  

  emg_2_ret = ldv_post_init(emg_2_ret);
  

  
  

  if (ldv_undef_int() != 0) 

                            __VERIFIER_assume(emg_2_ret != 0);
  else {
    

    __VERIFIER_assume(emg_2_ret == 0);
    emg_insmod_3((void *)0);
    

    fastrpc_cb_remove(pdev);
  }
  

  return;
}


void emg_insmod_1(void *arg0)
{
  int emg_1_ret;
  

  emg_1_ret = emg_fastrpc_init();
  

  emg_1_ret = ldv_post_init(emg_1_ret);
  

  
  

  if (ldv_undef_int() != 0) 

                            __VERIFIER_assume(emg_1_ret != 0);
  else {
    

    __VERIFIER_assume(emg_1_ret == 0);
emg_insmod_2((void *)0);
    

    emg_fastrpc_exit();
  }
  

  return;
}



int main(void)
{
  

  ldv_initialize();
  

  emg_insmod_1((void *)0);
  

  ldv_check_final_state();
  

  return 0;
}


